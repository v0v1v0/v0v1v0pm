<div class="container">

<table style="width: 100%;"><tr>
<td>rqda</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Robust (quadratic) discriminant analysis
</h2>

<h3>Description</h3>

<p>Robust (quadratic) discriminant analysis implements a discriminant analysis method which is robust to label noise. This function implements the method described in Lawrence and Scholkopf (2003, ISBN:1-55860-778-1).
</p>


<h3>Usage</h3>

<pre><code class="language-R">rqda(X,lbl,Y,maxit=50,disp=FALSE,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>

<p>a data frame containing the learning observations.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lbl</code></td>
<td>

<p>the class labels of the learning observations.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Y</code></td>
<td>

<p>a data frame containing the new observations to classify.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>maxit</code></td>
<td>

<p>the maximum number of iterations.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>disp</code></td>
<td>

<p>logical, if <code>TRUE</code>, several plots are displayed.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>

<p>additional arguments to provide to subfunctions.
</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>A list is returned with the following elements:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>nu</code></td>
<td>
<p>the estimated class proportions.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mu</code></td>
<td>
<p>the estimated class means.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>S</code></td>
<td>
<p>the estimated covariance matrices.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>gamma</code></td>
<td>
<p>the estimated purity level of the labels.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Ti</code></td>
<td>
<p>the posterior probabilties of the labels knowing the observed labels for the learning observations.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Pi</code></td>
<td>
<p>the class posterior probabilities of the observations to classify.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cls</code></td>
<td>
<p>the class assignments of the observations to classify.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ll</code></td>
<td>
<p>the log-likelihood value.</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>C. Bouveyron
</p>


<h3>References</h3>

<p>Lawrence, N., and Scholkopf, B., Estimating a kernel Fisher discriminant in the presence of label noise, Pages 306–313 of: Proceedings of the Eighteenth International Conference on Machine Learning. ICML’01. San Francisco, CA, USA, 2001 (ISBN:1-55860-778-1).
</p>


<h3>Examples</h3>

<pre><code class="language-R">n = 50
m1 = c(0,0); m2 = 1.5*c(1,-1)
S1 = 0.1*diag(2); S2 = 0.25 * diag(2)
X = rbind(mvrnorm(n,m1,S1),mvrnorm(2*n,m2,S2))
cls = rep(1:2,c(n,2*n))

# Label perturbation
ind = rbinom(3*n,1,0.4); lb = cls
lb[ind==1 &amp; cls==1] = 2
lb[ind==1 &amp; cls==2] = 1

# Classification with RQDA
res = rqda(X,lb,X)
table(cls,res$cls)
</code></pre>


</div>