<div class="container">

<table style="width: 100%;"><tr>
<td>MDPtoolbox-package</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Markov Decision Processes Toolbox
</h2>

<h3>Description</h3>

<p>The Markov Decision Processes (MDP) toolbox proposes functions related to the resolution of discrete-time Markov Decision Processes: finite horizon, value iteration, policy iteration, linear programming algorithms with some variants  and also proposes some functions related to Reinforcement Learning.
</p>


<h3>Details</h3>


<table>
<tr>
<td style="text-align: left;">
Package: </td>
<td style="text-align: left;"> MDPtoolbox</td>
</tr>
<tr>
<td style="text-align: left;">
Type: </td>
<td style="text-align: left;"> Package</td>
</tr>
<tr>
<td style="text-align: left;">
Version: </td>
<td style="text-align: left;"> 4.0.3</td>
</tr>
<tr>
<td style="text-align: left;">
Date: </td>
<td style="text-align: left;"> 2017-03-02</td>
</tr>
<tr>
<td style="text-align: left;">
License: </td>
<td style="text-align: left;"> BSD (4.4)</td>
</tr>
<tr>
<td style="text-align: left;">
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Iadine Chadès &lt;Iadine.Chades@csiro.au&gt;<br>
Guillaume Chapron &lt;gchapron@carnivoreconservation.org&gt;<br>
Marie-Josée Cros &lt;Marie-Josee.Cros@toulouse.inra.fr&gt;<br>
Fredérick Garcia &lt;fgarcia@toulouse.inra.fr&gt;<br>
Régis Sabbadin &lt;Regis.Sabbadin@toulouse.inra.fr&gt; <br></p>


<h3>References</h3>

<p>Chadès, I., Chapron, G., Cros, M.-J., Garcia, F. &amp; Sabbadin, R. 2014. MDPtoolbox: a multi-platform toolbox to solve stochastic dynamic programming problems. Ecography DOI:10.1111/ecog.00888 <br>
Puterman, M. L. 1994. Markov Decision Processes. John Wiley &amp; Sons, New-York.
</p>


<h3>Examples</h3>

<pre><code class="language-R"># Generates a random MDP problem
set.seed(0)
mdp_example_rand(2, 2)
mdp_example_rand(2, 2, FALSE)
mdp_example_rand(2, 2, TRUE)
mdp_example_rand(2, 2, FALSE, matrix(c(1,0,1,1),2,2))

# Generates a MDP for a simple forest management problem
MDP &lt;- mdp_example_forest()

# Find an optimal policy
results &lt;- mdp_policy_iteration(MDP$P, MDP$R, 0.9)

# Visualise the policy
results$policy

</code></pre>


</div>