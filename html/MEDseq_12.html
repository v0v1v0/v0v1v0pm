<div class="container">

<table style="width: 100%;"><tr>
<td>MEDseq_entropy</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Entropy of a fitted MEDseq model</h2>

<h3>Description</h3>

<p>Calculates the normalised entropy of a fitted MEDseq model.
</p>


<h3>Usage</h3>

<pre><code class="language-R">MEDseq_entropy(x,
               group = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>An object of class <code>"MEDseq"</code> generated by <code>MEDseq_fit</code> or an object of class <code>"MEDseqCompare"</code> generated by <code>MEDseq_compare</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>group</code></td>
<td>
<p>A logical (defaults to <code>FALSE</code>) indicating whether component-specific average entropies should be returned instead.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>When <code>group</code> is <code>FALSE</code>, this function calculates the normalised entropy via </p>
<p style="text-align: center;"><code class="reqn">H=-\frac{1}{n\log(G)}\sum_{i=1}^n\sum_{g=1}^G\hat{z}_{ig}\log(\hat{z}_{ig})</code>
</p>
<p>,
where <code class="reqn">n</code> and <code class="reqn">G</code> are the sample size and number of components, respectively, and <code class="reqn">\hat{z}_{ig}</code> is the estimated posterior probability at convergence that observation <code class="reqn">i</code> belongs to component <code class="reqn">g</code>.
</p>
<p>When <code>group</code> is <code>TRUE</code>, </p>
<p style="text-align: center;"><code class="reqn">H_i=-\frac{1}{\log(G)}\sum_{g=1}^G\hat{z}_{ig}\log(\hat{z}_{ig})</code>
</p>
<p> is computed for each observation and averaged according to the MAP classification.
</p>


<h3>Value</h3>

<p>When <code>group</code> is <code>FALSE</code>, a single number, given by <code class="reqn">1-H</code>, in the range [0,1], such that <em>larger</em> values indicate clearer separation of the clusters. Otherwise, a vector of length <code>G</code> containing the per-component averages of the observation-specific entropies is returned.
</p>


<h3>Note</h3>

<p>This function will always return a normalised entropy of <code>1</code> for models fitted using the <code>"CEM"</code> algorithm (see <code>MEDseq_control</code>), or models with only one component.
</p>


<h3>Author(s)</h3>

<p>Keefe Murphy - &lt;<a href="mailto:keefe.murphy@mu.ie">keefe.murphy@mu.ie</a>&gt;
</p>


<h3>References</h3>

<p>Murphy, K., Murphy, T. B., Piccarreta, R., and Gormley, I. C. (2021). Clustering longitudinal life-course sequences using mixtures of exponential-distance models. <em>Journal of the Royal Statistical Society: Series A (Statistics in Society)</em>, 184(4): 1414-1451. &lt;<a href="https://doi.org/10.1111/rssa.12712">doi:10.1111/rssa.12712</a>&gt;.
</p>


<h3>See Also</h3>

<p><code>MEDseq_fit</code>, <code>MEDseq_control</code>, <code>MEDseq_AvePP</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R"># Load the MVAD data
data(mvad)
mvad$Location &lt;- factor(apply(mvad[,5:9], 1L, function(x) 
                 which(x == "yes")), labels = colnames(mvad[,5:9]))
mvad          &lt;- list(covariates = mvad[c(3:4,10:14,87)],
                      sequences = mvad[,15:86], 
                      weights = mvad[,2])
mvad.cov      &lt;- mvad$covariates

# Create a state sequence object with the first two (summer) time points removed
states        &lt;- c("EM", "FE", "HE", "JL", "SC", "TR")
labels        &lt;- c("Employment", "Further Education", "Higher Education", 
                   "Joblessness", "School", "Training")
mvad.seq      &lt;- seqdef(mvad$sequences[-c(1,2)], states=states, labels=labels)

# Fit a model with weights and a gating covariate
# Have the probability of noise-component membership be constant
mod           &lt;- MEDseq_fit(mvad.seq, G=11, modtype="UUN", weights=mvad$weights, 
                            gating=~ gcse5eq, covars=mvad.cov, noise.gate=FALSE)

# Calculate the normalised entropy
MEDseq_entropy(mod)

# Calculate the normalised entropy per cluster
MEDseq_entropy(mod, group=TRUE)
</code></pre>


</div>