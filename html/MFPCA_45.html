<div class="container">

<table style="width: 100%;"><tr>
<td>UMPCA</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>UMPCA: Uncorrelated Multilinear Principle Component Analysis</h2>

<h3>Description</h3>

<p>This function implements the uncorrelated multilinear principal component
analysis for tensors of dimension 2, 3 or 4. The code is basically the same
as in the  MATLAB toolbox UMPCA by Haiping Lu (Link:
<a href="https://www.mathworks.com/matlabcentral/fileexchange/35432-uncorrelated-multilinear-principal-component-analysis-umpca">https://www.mathworks.com/matlabcentral/fileexchange/35432-uncorrelated-multilinear-principal-component-analysis-umpca</a>,
see also references).
</p>


<h3>Usage</h3>

<pre><code class="language-R">UMPCA(TX, numP)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>TX</code></td>
<td>
<p>The input training data in tensorial representation, the last mode
is the sample mode. For <code>N</code>th-order tensor data, <code>TX</code> is of
<code>(N+1)</code>th-order with the <code>(N+1)</code>-mode to be the sample mode.
E.g., 30x20x10x100 for 100 samples of size 30x20x10.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>numP</code></td>
<td>
<p>The dimension of the projected vector, denoted as <code class="reqn">P</code> in the
paper. It is the number of elementary multilinear projections (EMPs) in
tensor-to-vector projection.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<table>
<tr style="vertical-align: top;">
<td><code>Us</code></td>
<td>
<p>The multilinear projection, consisting of <code>numP</code>
(<code class="reqn">P</code> in the paper) elementary multilinear projections (EMPs), each EMP
is consisted of <code>N</code> vectors, one in each mode.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>TXmean</code></td>
<td>
<p>The mean
of the input training samples <code>TX</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>odrIdx</code></td>
<td>
<p>The ordering index
of projected features in decreasing variance.</p>
</td>
</tr>
</table>
<h3>Warning</h3>

<p>As this algorithm aims more at uncorrelated features than
at an optimal reconstruction of the data, hence it might give poor results
when used for the univariate decomposition of images in MFPCA.
</p>


<h3>References</h3>

<p>Haiping Lu, K.N. Plataniotis, and A.N. Venetsanopoulos,
"Uncorrelated Multilinear Principal Component Analysis for Unsupervised
Multilinear Subspace Learning", IEEE Transactions on Neural Networks, Vol.
20, No. 11, Page: 1820-1836, Nov. 2009.
</p>


<h3>Examples</h3>

<pre><code class="language-R">set.seed(12345)

 # define "true" components
 a &lt;- sin(seq(-pi, pi, length.out = 100))
 b &lt;- exp(seq(-0.5, 1, length.out = 150))

 # simulate tensor data
 X &lt;- a %o% b %o% rnorm(80, sd = 0.5)

 # estimate one component
 UMPCAres &lt;- UMPCA(X, numP = 1)

 # plot the results and compare to true values
 plot(UMPCAres$Us[[1]][,1])
 points(a/sqrt(sum(a^2)), pch = 20) # eigenvectors are defined only up to a sign change!
 legend("topright", legend = c("True", "Estimated"), pch = c(20, 1))

 plot(UMPCAres$Us[[2]][,1])
 points(b/sqrt(sum(b^2)), pch = 20)
 legend("topleft", legend = c("True", "Estimated"), pch = c(20, 1))
</code></pre>


</div>