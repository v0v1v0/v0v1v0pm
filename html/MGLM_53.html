<div class="container">

<table style="width: 100%;"><tr>
<td>MGLMsparsereg</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Fit multivariate GLM sparse regression</h2>

<h3>Description</h3>

<p>Fit sparse regression in multivariate generalized linear models.
</p>


<h3>Usage</h3>

<pre><code class="language-R">MGLMsparsereg(
  formula,
  data,
  dist,
  lambda,
  penalty,
  weight,
  init,
  penidx,
  maxiters = 150,
  ridgedelta,
  epsilon = 1e-05,
  regBeta = FALSE,
  overdisp
)

MGLMsparsereg.fit(
  Y,
  X,
  dist,
  lambda,
  penalty,
  weight,
  init,
  penidx,
  maxiters = 150,
  ridgedelta,
  epsilon = 1e-05,
  regBeta = FALSE,
  overdisp
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>formula</code></td>
<td>
<p>an object of class <code>formula</code> (or one that can be coerced
to that class): a symbolic description of the model to be fitted.
The response has to be on the left hand side of ~.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>an optional data frame, list or environment (or object coercible by 
<code>as.data.frame</code> to a data frame) containing the variables in the model.
If not found in <code>data</code> when using function <code>MGLMsparsereg</code>, the variables 
are taken from <code>environment(formula)</code>, typically the environment from
which <code>MGLMsparsereg</code> is called.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>dist</code></td>
<td>
<p>a description of the error distribution to fit. See <code>dist</code> for details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda</code></td>
<td>
<p>penalty parameter.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>penalty</code></td>
<td>
<p>penalty type for the regularization term. Can be chosen from <code>"sweep"</code>, 
<code>"group"</code>, or <code>"nuclear"</code>. See Details for the description of each penalty type.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>weight</code></td>
<td>
<p>an optional vector of weights assigned to each row of the data. 
Should be <code>NULL</code> or a numeric vector. Could be a variable from <code>data</code>, 
or a variable from <code>environment(formula)</code> with the length equal to
the number of rows of the data.
If <code>weight=NULL</code>, equal weights of ones will be assigned.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>init</code></td>
<td>
<p>an optional matrix of initial value of the parameter estimates.
Should have the compatible dimension with the data. See <code>dist</code> for
details of the dimensions in each distribution.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>penidx</code></td>
<td>
<p>a logical vector indicating the variables to be penalized. The default value is <code>rep(TRUE, p)</code>, which means all predictors are subject to regularization. If <code>X</code> contains intercept, use <code>penidx=c(FALSE,rep(TRUE,p-1))</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>maxiters</code></td>
<td>
<p>an optional numeric controlling the maximum number of iterations. The default
value is maxiters=150.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ridgedelta</code></td>
<td>
<p>an optional numeric controlling the behavior of the Nesterov's accelerated proximal gradient method. The default value is <code class="reqn">\frac{1}{pd}</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>epsilon</code></td>
<td>
<p>an optional numeric controlling the stopping criterion. The algorithm terminates when the relative change in the objective values of two successive iterates is less then <code>epsilon</code>.
The default value is <code>epsilon=1e-5</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>regBeta</code></td>
<td>
<p>an optional logical variable used when running negative multinomial regression (<code>dist="NegMN"</code>).
<code>regBeta</code> controls whether to run regression on the over-dispersion parameter.
The default is <code>regBeta=FALSE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>overdisp</code></td>
<td>
<p>an optional numerical variable used only when fitting sparse negative multinomial 
model <code>dist="NegMN"</code> and <code>regBeta=FALSE</code>.  <code>overdisp</code> gives the over dispersion value
for all the observations.  The default value is estimated using negative-multinomial regression.  When <code>dist="MN", "DM", "GDM"</code> or <code>regBeta=TRUE</code>, the value of <code>overdisp</code> is ignored.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Y</code></td>
<td>
<p>a matrix containing the multivariate categorical response data. 
Rows of the matrix represent observations, while columns are the different
categories.  Rows and columns of all zeros are automatically removed when
<code>dist="MN"</code>, <code>"DM"</code>, or <code>"GDM"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>design matrix (including intercept).
Number of rows of the matrix should match that of <code>Y</code>.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>In general, we consider regularization problem
</p>
<p style="text-align: center;"><code class="reqn">
\min_B h(B) = -l(B)+ J(B),
</code>
</p>

<p>where <code class="reqn">l(B)</code> is the loglikelihood function and <code class="reqn">J(B)</code> is the 
regularization function.  
</p>
<p>Sparsity in the individual elements of the parameter matrix <code class="reqn">B</code> is achieved 
by the lasso penalty (<code>dist="sweep"</code>)
</p>
<p style="text-align: center;"><code class="reqn">
J(B) = \lambda \sum_{k\in penidx} \sum_{j=1}^d \|B_{kj}\|
</code>
</p>

<p>Sparsity in the rows of the regression parameter matrix <code class="reqn">B</code> is achieved
by the group penalty (<code>dist="group"</code>)
</p>
<p style="text-align: center;"><code class="reqn">
J(B) = \lambda \sum_{k \in penidx} \|B_{k \cdot}\|_2,
</code>
</p>

<p>where <code class="reqn">\|v\|_2</code> is the <code class="reqn">l_2</code> norm of a vector <code class="reqn">v</code>. In other words, 
<code class="reqn">\|B_{k\cdot}\|_2</code> is the <code class="reqn">l_2</code> norm of the <code class="reqn">k</code>-th row of the 
parameter matrix <code class="reqn">B</code>.
</p>
<p>Sparsity in the rank of the parameter matrix <code class="reqn">B</code> is achieved by the nuclear norm penalty (<code>dist="nuclear"</code>)
</p>
<p style="text-align: center;"><code class="reqn">
J(B) = \lambda \|B\|_*= \lambda \sum_{i=1}^{min(p, d)} \sigma_i(B),
</code>
</p>

<p>where <code class="reqn">\sigma_i(B)</code> are the singular values of the parameter matrix <code class="reqn">B</code>. 
The nuclear norm <code class="reqn">\|B\|_*</code> is a convex relaxation of <code class="reqn">rank(B)=\|\sigma(B)\|_0</code>.
</p>
<p>See <code>dist</code> for details about distributions.
</p>


<h3>Value</h3>

<p>Returns an object of class <code>"MGLMsparsereg"</code>. An object of class <code>"MGLMsparsereg"</code> is a list containing at least the following components:  </p>

<ul>
<li>
<p><code>coefficients</code> the estimated matrix of regression coefficients.
</p>
</li>
<li>
<p><code>logL</code> the final loglikelihood value.
</p>
</li>
<li>
<p><code>AIC</code> Akaike information criterion.
</p>
</li>
<li>
<p><code>BIC</code> Bayesian information criterion.
</p>
</li>
<li>
<p><code>Dof</code> degrees of freedom of the estimated parameter.
</p>
</li>
<li>
<p><code>iter</code> number of iterations used. 
</p>
</li>
<li>
<p><code>maxlambda</code> the maxmum tuning parameter such that 
the estimated coefficients are not all zero.  This value is returned only
when the tuning parameter <code>lambda</code> given to the function is large enough 
such that all the parameter estimates are zero; otherwise, <code>maxlambda</code>
is not computed.
</p>
</li>
<li>
<p><code>call</code> a matched call.
</p>
</li>
<li>
<p><code>data</code> the data used to fit the model: a list of the predictor matrix
and the response matrix.
</p>
</li>
<li>
<p><code>penalty</code> the penalty chosen when running the penalized regression.
</p>
</li>
</ul>
<h3>Author(s)</h3>

<p>Yiwen Zhang and Hua Zhou
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Generate Dirichlet Multinomial data
dist &lt;- "DM"
n &lt;- 100
p &lt;- 15
d &lt;- 5
m &lt;- runif(n, min=0, max=25) + 25
set.seed(134)
X &lt;- matrix(rnorm(n*p),n, p)
alpha &lt;- matrix(0, p, d)
alpha[c(1,3, 5), ] &lt;- 1
Alpha &lt;- exp(X%*%alpha)
Y &lt;- rdirmn(size=m, alpha=Alpha)

## Tuning
ngridpt &lt;- 10
p &lt;- ncol(X)
d &lt;- ncol(Y)
pen &lt;- 'nuclear'
spfit &lt;- MGLMsparsereg(formula=Y~0+X, dist=dist, lambda=Inf, penalty=pen)

</code></pre>


</div>