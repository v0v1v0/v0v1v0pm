<div class="container">

<table style="width: 100%;"><tr>
<td>import_mhealth_csv_chunked</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Import large raw multi-channel accelerometer data stored in mHealth Specification
in chunks.</h2>

<h3>Description</h3>

<p><code>import_mhealth_csv_chunked</code> imports the raw multi-channel accelerometer
data stored in mHealth Specification in chunks.
</p>


<h3>Usage</h3>

<pre><code class="language-R">import_mhealth_csv_chunked(filepath, chunk_samples = 180000)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>filepath</code></td>
<td>
<p>string. The filepath of the input data.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>chunk_samples</code></td>
<td>
<p>number. The number of samples in each chunk. Default is
180000, which is half hour data for 100 Hz sampling rate.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>list. The list contains two items. The first item is a generator
function that each time it is called, it will
return a dataframe with at most <code>chunk_samples</code> samples of imported data.
The third item is a <code>close_connection</code> function which you can call at
any moment to close the file loading.
</p>


<h3>How is it used in MIMS-unit algorithm?</h3>

<p>This function is a File IO
function that is used to import data stored in mHealth Specification during
algorithm validation.
</p>


<h3>See Also</h3>

<p>Other File I/O functions: 
<code>export_to_actilife()</code>,
<code>import_actigraph_count_csv()</code>,
<code>import_actigraph_csv_chunked()</code>,
<code>import_actigraph_csv()</code>,
<code>import_actigraph_meta()</code>,
<code>import_activpal3_csv()</code>,
<code>import_enmo_csv()</code>,
<code>import_mhealth_csv()</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">  default_ops = options()
  options(digits.secs=3)

  # Use the mhealth csv file shipped with the package
  filepath = system.file('extdata', 'mhealth.csv', package='MIMSunit')

  # Example 1
  # Load chunks every 1000 samples
  results = import_mhealth_csv_chunked(filepath, chunk_samples=100)
  next_chunk = results[[1]]
  close_connection = results[[2]]
  # Check data as chunks, you can see chunk time is shifting forward at each iteration.
  n = 1
  repeat {
    df = next_chunk()
    if (nrow(df) &gt; 0) {
      print(paste('chunk', n))
      print(paste("df:", df[1, 1], '-', df[nrow(df),1]))
      n = n + 1
    } else {
      break
    }
  }

  # Close connection after reading all the data
  close_connection()

  # Example 2: close loading early
  results = import_mhealth_csv_chunked(filepath, chunk_samples=1000)
  next_chunk = results[[1]]
  close_connection = results[[2]]
  # Check data as chunks, you can see chunk time is shifting forward at each iteration.
  n = 1
  repeat {
    df = next_chunk()
    if (nrow(df) &gt; 0) {
      print(paste('chunk', n))
      print(paste("df:", df[1, 1], '-', df[nrow(df),1]))
      n = n + 1
      close_connection()
    }
    else {
      break
    }
  }

 # Restore default options
 options(default_ops)
</code></pre>


</div>