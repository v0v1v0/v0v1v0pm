<div class="container">

<table style="width: 100%;"><tr>
<td>MM4LMM-package</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Min-Max algorithms for Variance Component Mixed Model Inference.
</h2>

<h3>Description</h3>

<p>This package provides a function to perform either ML or ReML estimation in a Variance Component Mixed Model. The optimization of the (possibly Restricted) log-likelihood is perfomed using the Min-Max algorithm described in Hunter et al. (2004). Depending on the number of variance components, different computational tricks are used to speed up inference. Additionally, the <code>AnovaTest</code> function provides  Type I, Type III and Type III Kenward Roger approximation test series for fixed effects. The nullity of a specific linear combination can also be tested.  
</p>


<h3>Details</h3>

<p>Variance Component Mixed Models are mixed models of the form
</p>
<p style="text-align: center;"><code class="reqn">Y = X \beta +  \sum_{k=1}^K Z_k u_k</code>
</p>

<p>where Y is the response vector, X and <code class="reqn">\beta</code> are respectively the incidence matrix and the coefficient vector associated with the fixed effects, <code class="reqn">u_k</code> is the kth vector of random effects and corresponds to its associated incidence matrix. All random effect are assumed to be Gaussian with mean 0 and covariance <code class="reqn">\sigma_k^2 R_k </code>, where <code class="reqn">R_k</code> is a known correlation matrix and  <code class="reqn">\sigma_k^2</code> is an unknown variance parameter. All random effects are assumed to be independent. In many applications the last random component corresponds to the error and therefore both <code class="reqn">Z_k</code> and <code class="reqn">R_k</code> correspond to the identity matrix. 
</p>
<p>In such models the inference of both the unknown variance components <code class="reqn">\sigma_k^2</code>,...,<code class="reqn">\sigma_K^2</code> and the fixed effect <code class="reqn">\beta</code> can be achieved through Maximum Likelihood (ML) or Restricted Maximum Likelihood (ReML) estimation. Neither ML nor ReML yield close form expressions of the estimates, consequently the maximization of the (restricted) log-likelihood has to be performed numerically. This package provides the user with Min-Max algorithms for the optimization.  Efficient tricks such as profiling, MME trick and MM acceleration are implemented for computational efficiency (see Johnson et al. (1995), Varadhan et al. (2008) for details). The main function <code>MMEst</code> handles parallel inference of multiple models sharing the same set of correlation matrices - but possibly different fixed effects, an usual situation in GWAS analysis for instance.
</p>


<h3>Author(s)</h3>

<p>Fabien Laporte and Tristan Mary-Huard
</p>
<p>Maintainer: Fabien Laporte &lt;fabien.laporte@pasteur.fr&gt;
</p>


<h3>References</h3>

<p>Laporte, F., Charcosset, A., &amp; Mary-Huard, T. (2022). Efficient ReML inference in variance component mixed models using a Min-Max algorithm. PLOS Computational Biology, 18(1), e1009659.
</p>
<p>Johnson, D. L., &amp; Thompson, R. (1995). Restricted maximum likelihood estimation of variance components for univariate animal models using sparse matrix techniques and average information. Journal of dairy science, 78(2), 449-456.
</p>
<p>Hunter, D. R., &amp; Lange, K. (2004). A tutorial on MM algorithms. The American Statistician, 58(1), 30-37.
</p>
<p>Kenward, M. G., &amp; Roger, J. H. (1997). Small sample inference for fixed effects from restricted maximum likelihood. Biometrics, 983-997.
</p>
<p>Varadhan, R., &amp; Roland, C. (2008). Simple and globally convergent methods for accelerating the convergence of any EM algorithm. Scandinavian Journal of Statistics, 35(2), 335-353.
</p>
<p>Zhou, H., Hu, L., Zhou, J., &amp; Lange, K. (2015). MM algorithms for variance components models. arXiv preprint arXiv:1509.07426.
</p>


</div>