<div class="container">

<table style="width: 100%;"><tr>
<td>select.mpt</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Model Selection with MPTinR
</h2>

<h3>Description</h3>

<p>This function performs model selection for results produced by MPTinR's <code>fit.mpt</code>. It takes multiple results from <code>fit.mpt</code> as a list and returns a <code>data.frame</code> comparing the models using various model selection criteria (e.g., FIA) and AIC and BIC weights. For model selection of multi-dataset fits <code>select.mpt</code> will additionally count how often each model provided the best fit.
</p>


<h3>Usage</h3>

<pre><code class="language-R">select.mpt(mpt.results, output = c("standard", "full"), round.digit = 6, dataset)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>mpt.results</code></td>
<td>

<p>A <code>list</code> containing results from <code>fit.mpt</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>output</code></td>
<td>

<p><code>"standard"</code> or <code>"full"</code>. If <code>"full"</code> additionally returns original FIA, AIC, and BIC values, and, for multi-individual fits, compares the model-selection criteria for the aggregated data.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>round.digit</code></td>
<td>

<p>Integer specifying to which decimal place the results should be rounded. Default is 6. Is also used for rounding FIA, AIC, and BIC values before counting the best fitting values per individual datasets.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>dataset</code></td>
<td>

<p>Integer vector specifying whether or not to restrict the individual comparison top certain dataset(s). Aggregated results will not be displayed if this argument is present. 
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p><code>select.mpt</code> is the second major function of MPTinR, next to <code>fit.mpt</code>. It takes a list of results produced by <code>fit.mpt</code> and returns a <code>data.frame</code> comparing the models using the information criteria obtained by <code>fit.mpt</code>. That is, if FIA was not obtained for the models, <code>select.mpt</code> only uses AIC and BIC. We strongly recommend using FIA for model selection (see e.g., Gruenwald, 2000).
</p>
<p>The outputs follows the same principle for all information criteria. The lowest value is taken as the reference value and the differences to this value (i.e., the <code>delta</code>) are reported for all models (e.g., <code>delta.FIA</code>). If one additionally wants the original values, <code>output</code> needs to be set to <code>"full"</code>.
</p>
<p>For AIC and BIC, AIC and BIC weights are reported as <code>wAIC</code> and <code>wBIC</code> (Wagenmakers &amp; Farrell, 2004).
</p>
<p>For multi-individual fit, <code>select.mpt</code> will additionally return how often each model provided the best fit (e.g., <code>FIA.best</code>). Values are rounded before determining which is the best fitting model. Note that there can be ties so that two models provide the best fit. Furthermore, if <code>output</code> is <code>"standard"</code>, only results for the summed information criteria are returned (indicated by the postfix <code>.sum</code>). To obtain model selection results for the aggregated data (indicated by postfix <code>.aggregated</code>), <code>output</code> needs to be set to <code>"full"</code>.
</p>
<p>select.mpt will check if the data of the results returned from <code>fit.mpt</code> are equal. (If they are not equal model selection can not be done.)
</p>
<p>Note that the values in the returned <code>data.frame</code> are rounded to the <code>round.digit</code>th decimal place.
</p>


<h3>Value</h3>

<p>A <code>data.frame</code> containing the model selection values:<br><code>model</code>: Name or number of model (names are either taken from <code>mpt.results</code> or obtained via <code>match.call</code>).<br><code>n.parameters</code>: Number of parameters for each model.<br><code>G.Squared</code>: G.Squared values of the model (from summed fits for multiple datasets).<br><code>df</code>: df values of the model (from summed fits for multiple datasets).<br><code>p.value</code>: p values of the model (from summed fits for multiple datasets).<br><code>p.smaller.05</code>: How many of the individual data sets have p &lt; .05 (for multiple datasets only).<br> 
For the information criteria (i.e., FIA, AIC, BIC) <code>X</code>, <code>delta.X</code>, <code>X.best</code>, <code>X</code>, <code>wX</code> represent: The difference from the reference model, how often each model provided the best fit (only for multi-individual fit), the absolute value, the weights (only AIC and BIC).<br>
For multi-indivudal fit the postfix indicates whether the results refer to the summed information criteria from individual fit <code>.sum</code> or the information criteria from the aggregated data <code>.aggregated</code>.
</p>


<h3>Note</h3>

<p>As of March 2015 BIC and FIA are calculated anew if the results are displayed for multiple data sets as BIC and FIA cannot directly be summed across participants due to the <code class="reqn">log(n)</code> terms in their formula (while AIC can be summed). Instead one first needs to sum the <code class="reqn">G^2</code> values, <code class="reqn">n</code>, and the number of parameters, and only then can BIC and FIA be calculated for those summed values.
</p>
<p>If any of the models is fitted with <code>fit.aggregated = FALSE</code> no aggregated results are presented.
</p>


<h3>Author(s)</h3>

<p>Henrik Singmann
</p>


<h3>References</h3>

<p>Gruenwald, P.D. (2000). Model selection based on minimum description length. <em>Journal of Mathematical Psychology</em>, 44, 133-152.
</p>
<p>Wagenmakers, E.J. &amp; Farrell, S. (2004). AIC model selection using Akaike weights. <em>Psychonomic Bulletin &amp; Review</em>, 11, 192-196.
</p>


<h3>See Also</h3>

<p><code>fit.mpt</code> for obtaining the results needed here and an example using multi-individual fit and FIA.
</p>


<h3>Examples</h3>

<pre><code class="language-R">
# This example compares the three versions of the model in 
# Riefer and Batchelder (1988, Figure 2)

data(rb.fig2.data)
model2 &lt;- system.file("extdata", "rb.fig2.model", package = "MPTinR")
model2r.r.eq &lt;- system.file("extdata", "rb.fig2.r.equal", package = "MPTinR")
model2r.c.eq &lt;- system.file("extdata", "rb.fig2.c.equal", package = "MPTinR")

# The full (i.e., unconstrained) model
ref.model &lt;- fit.mpt(rb.fig2.data, model2)
# All r equal
r.equal &lt;- fit.mpt(rb.fig2.data, model2, model2r.r.eq)
# All c equal
c.equal &lt;- fit.mpt(rb.fig2.data, model2, model2r.c.eq)

select.mpt(list(ref.model, r.equal, c.equal))



## Not run: 

# Example from Broder &amp; Schutz (2009)

data(d.broeder, package = "MPTinR")
m.2htm &lt;- system.file("extdata", "5points.2htm.model", package = "MPTinR")
r.2htm &lt;- system.file("extdata", "broeder.2htm.restr", package = "MPTinR")
r.1htm &lt;- system.file("extdata", "broeder.1htm.restr", package = "MPTinR")

br.2htm.fia &lt;- fit.mpt(d.broeder, m.2htm, fia = 50000, fit.aggregated = FALSE)
br.2htm.res.fia &lt;- fit.mpt(d.broeder, m.2htm, r.2htm, fia = 50000, fit.aggregated = FALSE)
br.1htm.fia &lt;- fit.mpt(d.broeder, m.2htm, r.1htm, fia = 50000, fit.aggregated = FALSE)

select.mpt(list(br.2htm.fia, br.2htm.res.fia, br.1htm.fia))
# This table shows that the n (number of trials) is too small to correctly compute 
# FIA for the 1HT model (as the penalty for the 1HTM is larger than for the 2HTM, 
# although the former is nested in the latter).
# This problem with FIA can only be overcome by collecting more trials per participant,
# but NOT by collecting more participants (as the penalties are simply summed).

# using the dataset argument we see the same
select.mpt(list(br.2htm.fia, br.2htm.res.fia, br.1htm.fia), dataset = 4, output = "full")

select.mpt(list(br.2htm.fia, br.2htm.res.fia, br.1htm.fia),	dataset = 1:10)

## End(Not run)


</code></pre>


</div>