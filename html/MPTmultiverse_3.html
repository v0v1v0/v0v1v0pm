<div class="container">

<table style="width: 100%;"><tr>
<td>fit_mpt</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Multiverse Analysis for MPT Models</h2>

<h3>Description</h3>

<p>Performs a multiverse analysis for multinomial processing tree (MPT) models
across different levels of pooling (i.e., data aggregation) and across
maximum-likelihood/frequentist and Bayesian estimation approaches. For the
frequentist approaches, no pooling (with and without parametric or
nonparametric bootstrap) and complete pooling  are implemented using
<span class="pkg">MPTinR</span>. For the Bayesian approaches, no pooling, complete pooling, and
three different variants of partial pooling are implemented using
<span class="pkg">TreeBUGS</span>. Requires <code>data</code> on a by-participant level with each row
corresponding to data from one participant (i.e., different response
categories correspond to different columns) and the data can contain a single
between-subjects condition. Model equations need to be passed as a
<code>.eqn</code> model file and category labels (first column in <code>.eqn</code> file)
need to match the column names in <code>data</code>. Results are returned in one
<code>tibble</code> with one row per estimation method.
</p>


<h3>Usage</h3>

<pre><code class="language-R">fit_mpt(model, dataset, data, id = NULL, condition = NULL, core = NULL, method)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>model</code></td>
<td>
<p>A model definition, typically the path to an <code>.eqn</code> model
file containing the model equations. Category names need to match column
names in <code>data</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>dataset</code></td>
<td>
<p>scalar <code>character</code> vector. Name of the data set that will
be copied to the results <code>tibble</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>A <code>data.frame</code> containing the data. Column
names need to match category names in <code>model</code> (i.e., different from
<span class="pkg">MPTinR</span> behavior, order of categories is not important, matching is
done via name).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>id</code></td>
<td>
<p>scalar <code>character</code> vector. Name of the column that contains
the subject identifier. If not specified, it is assumed that each row
represents observations from one participant.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>condition</code></td>
<td>
<p>scalar <code>character</code> vector. Name of the column
specifying a between-subjects factor. If not specified, no between-subjects
comparisons are performed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>core</code></td>
<td>
<p><code>character</code> vector defining the core parameters of interest,
e.g., <code>core = c("Dn", "Do")</code>. All other parameters are treated as
auxiliary parameters.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p><code>character</code> vector specifying which analysis approaches
should be performed (see Description below). Defaults to all available
methods.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>This functions is a fancy wrapper for packages <span class="pkg">MPTinR</span> and
<span class="pkg">TreeBUGS</span> applying various frequentist and Bayesian estimation methods
to the same data set with different levels of pooling/aggregation using a
single MPT model and collecting the results in one <code>tibble</code> where each
row corresponds to one estimation method. Note that parameter restrictions
(e.g., equating different parameters or fixing them to a constant) need to
be part of the model (i.e., the <code>.eqn</code> file) and cannot be passed as
an argument.
</p>
<p>The settings for the various methods are specified via function
<code>mpt_options</code>. The default settings use all available cores for
calculating the boostrap distribution as well as independent MCMC chains
and should be appropriate for most situations.
</p>
<p>The data can have a single between-subjects condition (specified via
<code>condition</code>). This condition can have more than two levels. If
specified, the pairwise differences between each level, the standard error
of the differences, and confidence-intervals of the differences are
calculated for each parameter. Please note that <code>condition</code> is
silently converted to <code>character</code> in the output. Thus, a specific
ordering of the <code>factor</code> levels in the output cannot be guaranteed. If
the data has more than one between-subjects condition, these need to be
combined into one condition for this function.
</p>
<p>To include multiple within-subjects conditions, include separate trees and
separate sets of parameters for each within-subjects condition in your
.eqn file.
</p>


<h4>Pooling</h4>

<p>The following pooling levels are provided (not all by all estimation approaches, see below).
</p>

<ul>
<li>
<p><em>Complete pooling:</em> The traditional analysis approach in the MPT
literature in which data is aggregated across participants within each
between-subjects condition. This approach assumes that there are no
individual-dfferences. Produces one set of model parameters per condition.
</p>
</li>
<li>
<p><em>No pooling:</em> The model is fitted to the individual-level data in
an independent manner (i.e., no data aggregation). This approach
assumes that there is no similarity across participants and usually
requires considerable amounts of data on the individual-level. Produces
one set of model parameters per participant. Group-level estimates are
based on averaging the individual-level estimates.
</p>
</li>
<li>
<p><em>Partial pooling:</em> Data is fitted simultaneously to the
individual-level data assuming that the individual-level parameters come
from a group-level distribution. Individual-level parameters are often
treated as random-effects which are nested in the group-level parameters,
which is why this approach is also called hierarchical modeling. This
approach assumes both individual-level differences and similarities.
Produces one set of model parameters per participant plus one set of
group-level parameters. Thus, although partial pooling models usually
have more parameters than the no-pooling approaches, they are usually
less flexible as the hierarchical-structure provides regularization of
the individual-level parameters. 
</p>
</li>
</ul>
<h4>Implemented Estimation Methods</h4>

<p>Maximum-likelihood estimation with <span class="pkg">MPTinR</span> via
<code>fit.mpt</code>:
</p>

<ul>
<li>
<p><code>"asymptotic_complete"</code>: Asymptotic ML theory, complete
pooling
</p>
</li>
<li>
<p><code>"asymptotic_no"</code>:  Asymptotic ML theory, no pooling
</p>
</li>
<li>
<p><code>"pb_no"</code>: Parametric bootstrap, no pooling
</p>
</li>
<li>
<p><code>"npb_no"</code>: Nonparametric bootstrap, no pooling
</p>
</li>
</ul>
<p>Bayesian estimation with <span class="pkg">TreeBUGS</span>
</p>

<ul>
<li>
<p><code>"simple"</code>: Bayesian estimation, no pooling (C++,
simpleMPT)
</p>
</li>
<li>
<p><code>"simple_pooling"</code>: Bayesian estimation, complete pooling
(C++, simpleMPT)
</p>
</li>
<li>
<p><code>"trait"</code>: latent-trait model, partial pooling (JAGS,
traitMPT)
</p>
</li>
<li>
<p><code>"trait_uncorrelated"</code>: latent-trait model without
correlation parameters, partial pooling (JAGS,
traitMPT)
</p>
</li>
<li>
<p><code>"beta"</code>: beta-MPT model, partial pooling (JAGS,
betaMPT)
</p>
</li>
<li>
<p><code>"betacpp"</code>: beta-MPT model, partial pooling (C++,
betaMPTcpp)
</p>
</li>
</ul>
<h4>Frequentist/Maximum-Likelihood Methods</h4>

<p>For the <em>complete pooling asymptotic approach</em>, the group-level parameter
estimates and goodness-of-fit statistics are the maximum-likelihood and
G-squared values returned by <code>MPTinR</code>. The parameter differences are
based on these values. for between-subjects comparisons, the standard
errors of the differences are simply the pooled standard error of the
individual parameters; for within-subjects comparisons, the standard errors
of the differences are based on the respective linear transform of the estimated
variance-covariance matrix calculated from the Hessian matrix. The overall fit
(column <code>gof</code>) is based on an additional fit to the completely
aggregated data.
</p>
<p>For the <em>no pooling asymptotic approach</em>, the individual-level
maximum-likelihood estimates are reported in column <code>est_indiv</code> and
<code>gof_indiv</code> and provide the basis for the other results. Whether or
not an individual-level parameter estimate is judged as identifiable
(column <code>identifiable</code>) is based on separate fits with different
random starting values. If, in these separate, fits the same objective
criterion is reached several times (i.e., <code>Log.Likelihood</code> within
.01 of best fit), but the parameter estimate differs (i.e., different
estimates within .01 of each other), then an estimate is flagged as
non-identifiable. If they are the same (i.e., within .01 of each other)
they are marked as identifiable. The group-level parameters are simply
the means of the identifiable individual-level parameters, the SE is the
SE of the mean for these parameter (i.e., SD/sqrt(N), where N excludes
non-identifiable parameters and thise estimated as NA), and the CI is
based on mean and SE. The group-level and overall fit is the sum of the
individual G-squares, sum of individual-level df, and corresponding
chi-square df. The difference between the conditions and corresponding
statistics are based on a t-test comparing the individual-level estimates
(again, after excluding non-identifiable estimates). The CIs of the
difference are based on the SEs (which are derived from a linear model
equivalent to the t-test). Within-subjects comparisons are based on t-tests
for paired observations.
</p>
<p>The individual-level estimates of the <code>bootstrap based no-pooling</code>
approaches are identical to the asymptotic ones. However, the SE is the
SD of the bootstrapped distribution of parameter estimates, the CIs are
the corresponding quantiles of the bootstrapped distribution, and the
p-value is obtained from the bootstrapped G-square distribution.
Identifiability of individual-level parameter estimates is also based on
the bootstrap distribution of estimates. Specifically, we calculate the
range of the CI (i.e., maximum minus minimum CI value) and flag those
parameters as non-identifiable for which the range is larger than
<code>mpt_options()$max_ci_indiv</code>, which defaults to <code>0.99</code>. Thus,
in the default settings we say a parameter is non-identifiable if the
bootstrap based CI extends from 0 to 1. The group-level estimates are the
mean of the identifiable individual-level estimates. The difference
between conditions (as well as within conditions) is calculated in the same manner as for the asymptotic
case using the identifiable individual-level parameter estimates.
</p>



<h4>Bayesian Methods</h4>

<p>The <em>simple approaches</em> fit fixed-effects MPT models.
<code>"simple"</code> uses no pooling and thus assumes independent uniform priors
for the individual-level parameters. Group-level means are
obtained as generated quantities by averaging the posterior samples
across participants. <code>"simple_pooling"</code> aggregates observed
frequencies across participants and assumes a uniform prior for the
group-level parameters.
</p>
<p>The <em>latent-trait approaches</em> transform the individual-level
parameters to a latent probit scale using the inverse cumulative standard
normal distribution. For these probit values, a multivariate normal
distribution is assumed at the group level. Whereas <code>"trait"</code>
estimates the corresponding correlation matrix of the parameters
(reported in the column <code>est_rho</code>), <code>"trait_uncorrelated"</code> does
not estimate this correlation matrix (i.e., parameters can still be
correlated across individuals, but this is not accounted for in the
model).
</p>
<p>For all Bayesian methods, the posterior distribution of the parameters is
summarized by the posterior mean (in the column <code>est</code>), posterior
standard deviation (<code>se</code>), and credbility intervals (<code>ci_*</code>).
For parameter differences (<code>test_between</code> and <code>test_within</code>) and correlations
(<code>est_rho</code>), Bayesian p-values are computed (column <code>p</code>) by
counting the relative proportion of posterior samples that are smaller
than zero. Goodness of fit is tested with the T1 statistic
(observed vs. posterior-predicted average frequencies, <code>focus =
    "mean"</code>) and the T2 statistic (observed vs. posterior-predicted
covariance of frequencies, <code>focus = "cov"</code>).
</p>



<h3>Value</h3>

<p>A <code>tibble</code> with one row per estimation <code>method</code> and the
following columns:
</p>

<ol>
<li> <p><code>model</code>: Name of model file (copied from <code>model</code> argument),
<code>character</code>
</p>
</li>
<li> <p><code>dataset</code>: Name of data set (copied from <code>dataset</code>
argument), <code>character</code>
</p>
</li>
<li> <p><code>pooling</code>: <code>character</code> specifying the level of pooling with
three potential values: <code>c("complete", "no", "partial")</code>
</p>
</li>
<li> <p><code>package</code>: <code>character</code> specifying the package used for
estimation with two potential values: <code>c("MPTinR", "TreeBUGS")</code>
</p>
</li>
<li> <p><code>method</code>: <code>character</code> specifying the method used with the
following potential values: <code>c("asymptotic", "PB/MLE", "NPB/MLE",
  "simple", "trait", "trait_uncorrelated", "beta", "betacpp")</code>
</p>
</li>
<li> <p><code>est_group</code>: Group-level parameter estimates per condition/group.
</p>
</li>
<li> <p><code>est_indiv</code>: Individual-level parameter estimates (if provided
by method).
</p>
</li>
<li> <p><code>est_rho</code>: Estimated correlation of individual-level parameters
on the probit scale (only in <code>method="trait"</code>).
</p>
</li>
<li> <p><code>test_between</code>: Parameter differences between the levels of the
between-subjects condition (if specified).
</p>
</li>
<li> <p><code>test_within</code>: Within-subjects parameter differences.
</p>
</li>
<li> <p><code>gof</code>: Overall goodness of fit across all individuals.
</p>
</li>
<li> <p><code>gof_group</code>: Group-level goodness of fit.
</p>
</li>
<li> <p><code>gof_indiv</code>: Individual-level goodness of fit.
</p>
</li>
<li> <p><code>fungibility</code>:  Posterior correlation of the group-level means
<code>pnorm(mu)</code> (only in <code>method="trait"</code>).
</p>
</li>
<li> <p><code>test_homogeneity</code>: Chi-square based test of participant
homogeneity proposed by Smith and Batchelder (2008). This test is the same
for each estimation method.
</p>
</li>
<li> <p><code>convergence</code>: Convergence information provided by the
respective estimation method. For the asymptotic frequentist methods this
is a <code>tibble</code> with rank of the Fisher matrix, the number of parameters
(which should match the rank of the Fisgher matrix), and the convergence
code provided by the optimization algorithm (which is
<code>nlminb</code>). The boostrap methods contain an additional column,
<code>parameter</code>, that contains the information which (if any) parameters
are empirically non-identifiable based on the bootstrapped distribution of
parameter estimates (see above for exact description). For the Bayesian
methods this is a <code>tibble</code> containing information of the posterior
dsitribution (i.e., mean, quantiles, SD, SE, <code>n.eff</code>, and R-hat) for
each parameter.
</p>
</li>
<li> <p><code>estimation</code>: Time it took for each estimation method and group.
</p>
</li>
<li> <p><code>options</code>: Options used for estimation. Obtained by running
<code>mpt_options()</code>
</p>
</li>
</ol>
<p>With the exception of the first five columns (i.e., after <code>method</code>) all
columns are <code>list</code> columns typically holding one <code>tibble</code> per cell.
The simplest way to analyze the results is separately per column using
<code>unnest</code>. Examples for this are given below.
</p>


<h3>References</h3>

<p>Smith, J. B., &amp; Batchelder, W. H. (2008). Assessing individual differences
in categorical data. <em>Psychonomic Bulletin &amp; Review</em>, 15(4), 713-731.
<a href="https://doi.org/10.3758/PBR.15.4.713">https://doi.org/10.3758/PBR.15.4.713</a>
</p>


<h3>Examples</h3>

<pre><code class="language-R">
# ------------------------------------------------------------------------------
# MPT model definition &amp; Data

EQN_FILE &lt;- system.file("extdata", "prospective_memory.eqn", package = "MPTmultiverse")
DATA_FILE &lt;- system.file("extdata", "smith_et_al_2011.csv", package = "MPTmultiverse")

### if .csv format uses semicolons ";" (e.g., German format):
# data &lt;- read.csv2(DATA_FILE, fileEncoding = "UTF-8-BOM")
### if .csv format uses commata "," (international format):
data &lt;- read.csv(DATA_FILE, fileEncoding = "UTF-8-BOM")
data &lt;- data[c(1:10, 113:122),]  ## select only subset of data for example
head(data)

COL_CONDITION &lt;- "WM_EX"  # name of the variable encoding group membership

# experimental condition should be labeled meaningfully ----
unique(data[[COL_CONDITION]])

data[[COL_CONDITION]] &lt;- factor(
  data[[COL_CONDITION]]
  , levels = 1:2
  , labels = c("low_WM", "high_WM")
)

# define core parameters:
CORE &lt;- c("C1", "C2")

## Not run: 
op &lt;- mpt_options() 
## to reset default options (which you would want) use:
mpt_options("default")

mpt_options() # to see the settings 
## Note: settings are also saved in the results tibble
  
## without specifying method, all are used per default
fit_all &lt;- fit_mpt(
  model = EQN_FILE
  , dataset = DATA_FILE
  , data = data
  , condition = COL_CONDITION
  , core = CORE
)

mpt_options(op) ## reset options  

## End(Not run)

load(system.file("extdata", "prospective_memory_example.rda", package = "MPTmultiverse"))

# Although we requested all 10 methods, only 9 worked:
fit_all$method
# Jags variant of beta MPT is missing.

# the returned method has a plot method. For example, for the group-level estimates:
plot(fit_all, which = "est")

## Not run: 
### Full analysis of results requires dplyr and tidyr (or just 'tidyverse')
library("dplyr")
library("tidyr")

## first few columns identify model, data, and estimation approach/method
## remaining columns are list columns containing the results for each method
## use unnest to work with each of the results columns
glimpse(fit_all) 

## Let us inspect the group-level estimates
fit_all %&gt;% 
  select(method, pooling, est_group) %&gt;% 
  unnest() 

## which we can plot again
plot(fit_all, which = "est")

## Next we take a look at the GoF
fit_all %&gt;% 
  select(method, pooling, gof_group) %&gt;% 
  unnest() %&gt;% 
  as.data.frame()

# Again, we can plot it as well
plot(fit_all, which = "gof2")  ## use "gof1" for overall GoF

## Finally, we take a look at the differences between conditions
fit_all %&gt;% 
  select(method, pooling, test_between) %&gt;% 
  unnest() 

# and then we plot it
plot(fit_all, which = "test_between")


### Also possible to only use individual methods:
only_asymptotic &lt;- fit_mpt(
  model = EQN_FILE
  , dataset = DATA_FILE
  , data = data
  , condition = COL_CONDITION
  , core = CORE
  , method = "asymptotic_no"
)
only_asymptotic$est_group

bayes_complete &lt;- fit_mpt(
  model = EQN_FILE
  , dataset = DATA_FILE
  , data = data
  , condition = COL_CONDITION
  , core = CORE
  , method = "simple_pooling"
)
bayes_complete$est_group


## End(Not run)
</code></pre>


</div>