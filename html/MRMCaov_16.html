<div class="container">

<table style="width: 100%;"><tr>
<td>metrics</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Performance Metrics</h2>

<h3>Description</h3>

<p>Estimated performance metrics from ROC curves.
</p>


<h3>Usage</h3>

<pre><code class="language-R">binary_sens(truth, rating)

binary_spec(truth, rating)

binormal_auc(
  truth,
  rating,
  partial = FALSE,
  min = 0,
  max = 1,
  normalize = FALSE
)

binormal_eu(truth, rating, slope = 1)

binormal_sens(truth, rating, spec)

binormal_spec(truth, rating, sens)

binormalLR_auc(
  truth,
  rating,
  partial = FALSE,
  min = 0,
  max = 1,
  normalize = FALSE
)

binormalLR_eu(truth, rating, slope = 1)

binormalLR_sens(truth, rating, spec)

binormalLR_spec(truth, rating, sens)

empirical_auc(
  truth,
  rating,
  partial = FALSE,
  min = 0,
  max = 1,
  normalize = FALSE
)

empirical_eu(truth, rating, slope = 1)

empirical_sens(truth, rating, spec)

empirical_spec(truth, rating, sens)

trapezoidal_auc(
  truth,
  rating,
  partial = FALSE,
  min = 0,
  max = 1,
  normalize = FALSE
)

trapezoidal_sens(truth, rating, spec)

trapezoidal_spec(truth, rating, sens)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>truth</code></td>
<td>
<p>vector of true binary statuses.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>rating</code></td>
<td>
<p>vector of 0-1 binary ratings for the binary metrics and ranges
of numeric ratings for the others.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>partial</code></td>
<td>
<p>character string <code>"sensitivity"</code> or <code>"specificity"</code>
for calculation of partial AUC, or <code>FALSE</code> for full AUC.  Partial
matching of the character strings is allowed.  <code>"specificity"</code>
results in area under the ROC curve between the given <code>min</code> and
<code>max</code> specificity values, whereas <code>"sensitivity"</code> results in area to
the right of the curve between the given sensitivity values.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>min, max</code></td>
<td>
<p>minimum and maximum sensitivity or specificity values over
which to calculate partial AUC.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>normalize</code></td>
<td>
<p>logical indicating whether partial AUC is divided by the
interval width (<code>max - min</code>) over which it is calculated.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>slope</code></td>
<td>
<p>slope of the iso-utility line at which to compute expected
utility of the ROC curve.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sens, spec</code></td>
<td>
<p>numeric sensitivity/specificity at which to calculate
specificity/sensitivity.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Performance metrics measure the degree to which higher case ratings are
associated with positive case statuses, where positive status is taken to be
the highest level of <code>truth</code>.  Available metrics include area under the
ROC curve (auc), expected utility of the ROC curve (eu) at a given
iso-utility line (Abbey, 2013), sensitivity (sens) at a given specificity,
and specificity (spec) at a given sensitivity.
</p>


<h3>Value</h3>

<p>Returns a numeric value.
</p>


<h3>References</h3>

<p>Abbey CK, Samuelson FW and Gallas BD (2013). Statistical power considerations
for a utility endpoint in observer performance studies. Academic Radiology,
20: 798-806.
</p>


<h3>See Also</h3>

<p><code>mrmc</code>, <code>srmc</code>, <code>stmc</code>
</p>


</div>