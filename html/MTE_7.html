<div class="container">

<table style="width: 100%;"><tr>
<td>MTElasso</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>MTE-Lasso estimator</h2>

<h3>Description</h3>

<p>MTELasso is the penalized MTE for robust estimation and variable selection for linear regression.
It can deal with both fixed and high-dimensional settings.
</p>


<h3>Usage</h3>

<pre><code class="language-R">MTElasso(
  X,
  y,
  beta.ini,
  p = 2,
  lambda = NULL,
  adaptive = TRUE,
  t = 0.01,
  intercept = TRUE,
  penalty.factor = rep(1, ncol(X)),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>design matrix, standardization is recommended.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>response vector.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>beta.ini</code></td>
<td>
<p>initial estimates of beta. If not specified, LADLasso estimates from <code>rq.lasso.fit()</code> in <code>rqPen</code>
is used. Otherwise, robust estimators are strongly recommended.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>p</code></td>
<td>
<p>Taylor expansion order.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda</code></td>
<td>
<p>regularization parameter for LASSO, but not necessary if "adaptive=TRUE".</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>adaptive</code></td>
<td>
<p>logic argument to indicate if Adaptive-Lasso is used. Default is TRUE.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>t</code></td>
<td>
<p>the tuning parameter that controls for the tradeoff between robustness and efficiency. Default is t=0.01.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>intercept</code></td>
<td>
<p>logical input that indicates if intercept needs to be estimated. Default is FALSE.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>penalty.factor</code></td>
<td>
<p>can be used to force nonzero coefficients. Default is rep(1, ncol(X)) as in glmnet.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>other arguments that are used in <code>glmnet</code>.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>It returns a sparse vector of estimates of linear regression. It has two types of penalty, LASSO and AdaLasso.
Coordinate descent algorithm is used for iteratively updating coefficients.
</p>
<table>
<tr style="vertical-align: top;">
<td><code>beta</code></td>
<td>
<p>sparse regression coefficient</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fitted</code></td>
<td>
<p>predicted response</p>
</td>
</tr>
</table>
<h3>Examples</h3>

<pre><code class="language-R">set.seed(2017)
n=200; d=500
X=matrix(rnorm(n*d), nrow=n, ncol=d)
beta=c(rep(2,6), rep(0, d-6))
y=X%*%beta+c(rnorm(150), rnorm(30,10,10), rnorm(20,0,100))
output.MTELasso=MTElasso(X, y, p=2, t=0.01)
beta.est=output.MTELasso$beta

</code></pre>


</div>