<div class="container">

<table style="width: 100%;"><tr>
<td>Forward selection regression</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Variable selection in regression models with forward selection
</h2>

<h3>Description</h3>

<p>Variable selection in regression models with forward selection
</p>


<h3>Usage</h3>

<pre><code class="language-R">fs.reg(target, dataset, ini = NULL, threshold = 0.05, wei = NULL, test = NULL, 
user_test = NULL, stopping = "BIC", tol = 2, ncores = 1) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>target</code></td>
<td>

<p>The class variable. Provide either a string, an integer, a numeric value, a vector, a factor, an ordered factor or a Surv object. See also Details.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>dataset</code></td>
<td>

<p>The dataset; provide either a data frame or a matrix (columns = variables, rows = samples). In either case, only two cases are avaialble, either all data are continuous, or categorical. 
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ini</code></td>
<td>

<p>If you have a set of variables already start with this one. Otherwise leave it NULL. 
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>threshold</code></td>
<td>

<p>Threshold (suitable values in (0, 1)) for asmmmbsing p-values significance. Default value is 0.05.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>wei</code></td>
<td>

<p>A vector of weights to be used for weighted regression. The default value is NULL. An example where weights are used is surveys when stratified sampling has occured. 
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>test</code></td>
<td>

<p>The regression model to use. Available options are most of the tests for SES and MMPC. The ones NOT available are "gSquare", "censIndER", "testIndMVreg", "testIndClogit" and "testIndSpearman". 
If you have continuous predictor variables in matrix form, you can put "testIndFisher" and this is pretty fast. Instead of calcualting partial F-tests, which requires liear regression models to be fit, 
it calcualtes partial correlation coefficients and this is much more efficient. 
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>user_test</code></td>
<td>

<p>A user-defined conditional independence test (provide a closure type object). Default value is NULL. If this is defined, 
the "test" argument is ignored.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>stopping</code></td>
<td>

<p>The stopping rule. The BIC is always used for all methods. If you have linear regression though you can change this to "adjrsq" and in this case the adjusted R qaured is used.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tol</code></td>
<td>

<p>The difference bewtween two successive values of the stopping rule. By default this is is set to 2. If for example, the BIC difference between two succesive models is less than 2, the process stops and the last variable, even though significant does not enter the model.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ncores</code></td>
<td>

<p>How many cores to use. This plays an important role if you have tens of thousands of variables or really large sample sizes and tens of thousands of variables and a regression based test which requires numerical optimisation. In other cases it will not make a difference in the overall time (in fact it can be slower). The parallel computation is used in the first step of the algorithm, where univariate associations are examined, those take place in parallel. We have seen a reduction in time of 50% with 4 cores in comparison to 1 core. Note also, that the amount of reduction is not linear in the number of cores.
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>If the current 'test' argument is defined as NULL or "auto" and the user_test argument is NULL then the algorithm automatically selects the best test based on the type of the data. Particularly:
</p>

<ul>
<li>
<p> if target is a factor, the multinomial or the binary logistic regression is used. If the target has two values only,   binary logistic regression will be used.
</p>
</li>
<li>
<p> if target is a ordered factor, the ordered logit regression is used. Hence, if you want to use multinomial or ordinal logistic regression, make sure your target is factor. 
</p>
</li>
<li>
<p> if target is a numerical vector and the dataset is not a matrix, but a data.frame linear regression is used. If however, the dataset is a matrix, the correlation based forward selection is used. That is, instead of partial F-tests, we do partial correlation tests.
</p>
</li>
<li>
<p> if target is discrete numerical (counts), the poisson regression conditional independence test is used. If there are only two values, the binary logistic regression is to be used.
</p>
</li>
<li>
<p> if target is a Surv object, the Survival conditional independence test is used.
</p>
</li>
</ul>
<h3>Value</h3>

<p>In the case of test="testIndMMReg" and class(dataset) = matrix, just one matrix is returned with the index of the selected variable(s), the p-value, the test statistic and the BIC value of each model. For all other cases, the output of the algorithm is S3 object including:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>runtime</code></td>
<td>

<p>The run time of the algorithm. A numeric vector. The first element is the user time, the second element is the system time and the third element is the elapsed time.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mat</code></td>
<td>

<p>A matrix with the variables and their latest test statistics and <b>logged p-values</b>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>info</code></td>
<td>

<p>A matrix with the selected variables, their <b>logged p-values</b> and test statistics. Each row corresponds to a model which contains the variables up to that line. The BIC in the last column is the BIC of that model.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ci_test</code></td>
<td>

<p>The conditional independence test used. 
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>final</code></td>
<td>

<p>The final regression model.
</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>
</p>


<h3>See Also</h3>

<p><code>glm.fsreg, lm.fsreg, bic.fsreg, bic.glm.fsreg, CondIndTests, MMPC, SES</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">set.seed(123)

#simulate a dataset with continuous data
dataset &lt;- matrix( runif(500 * 20, 1, 100), ncol = 20 )

#define a simulated class variable 
target &lt;- rt(500, 10)

a0 &lt;- fs.reg(target, dataset, threshold = 0.05, stopping = "BIC", tol = 2) 

a1 &lt;- fs.reg(target, dataset, threshold = 0.05, test = "testIndRQ", stopping = "BIC", 
tol = 2) 

require(survival, quietly = TRUE)
y &lt;- survival::Surv(rexp(500), rep(1, 500) )
a2 &lt;- fs.reg(y, dataset, threshold = 0.05, test = "censIndWR", stopping = "BIC", tol = 2) 
a3 &lt;- MMPC(target, dataset)

target &lt;- factor( rbinom(500, 1, 0.6) )
b2 &lt;- fs.reg(target, dataset, threshold = 0.05, test = NULL, stopping = "BIC", tol = 2) 
</code></pre>


</div>