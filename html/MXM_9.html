<div class="container">

<table style="width: 100%;"><tr>
<td>Bootstrap bias correction for the performance of the cross-validation procedure</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Bootstrap bias correction for the performance of the cross-validation procedure
</h2>

<h3>Description</h3>

<p>Bootstrap bias correction for the performance of the cross-validation procedure.
</p>


<h3>Usage</h3>

<pre><code class="language-R">bbc(predictions, target, metric = "auc.mxm", conf = 0.95, B = 1000)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>predictions</code></td>
<td>

<p>A matrix with the predictived values.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>target</code></td>
<td>

<p>A vector with the target variable, survival object, factor (ordered or unordered) or a numerical vector.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>metric</code></td>
<td>

<p>The possible values are: 
</p>
<p>a) Binary target: "auc.mxm" (area under the curve), "fscore.mxm" (F-score), "prec.mxm" (precision), "euclid_sens.spec.mxm" (Euclidean distance of sensitivity and specificity), "spec.mxm" (specificity), "sens.mxm" (sensitivity), "acc.mxm" (accuracy, proportion of correct classification).
</p>
<p>b) Multinomial target: "acc_multinom.mxm" (accuracy, proportion of correct classification). 
</p>
<p>c) Ordinal target: "ord_mae.mxm" (mean absolute error).
</p>
<p>d) Continuous target: "mae.mxm" (MAE with continuous target), "mse.mxm" (mean squared error), "pve.mxm" (percentage of variance explained).
</p>
<p>e) Survival target "ci.mxm" (concordance index for Cox regression), "ciwr.mxm" (concordance index for Weibull regression). 
g) Count target "poisdev.mxm".
</p>
<p>h) Binomial target "binomdev.mxm" (deviance of binomial regression).
</p>
<p>The "nbdev.mxm" (negative binomial deviance) is missing. For more information on these see <code>cv.ses</code>. boldNote that they come with "".
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>conf</code></td>
<td>

<p>A number between 0 and 1, the confidence level.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>B</code></td>
<td>

<p>The number of bootstrap replicates. The default number is 1000.
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Upon completion of the cross-validation, the predicted values produced by all predictive models across all folds is collected in a matrix <code class="reqn">P</code> of dimensions <code class="reqn">n \times M</code>, where <code class="reqn">n</code> is the number of samples and <code class="reqn">M</code> the number of trained models or configurations. Sampled with replacement a fraction of rows (predictions) from <code class="reqn">P</code> are denoted as the in-sample values. On average, the newly created set will be comprised by 63.2% of the original individuals (The probability of sampling, with replacement, a sample of <code class="reqn">n</code> numbers from a set of <code class="reqn">n</code> numbers is <code class="reqn">1-\left(1-\frac{1}{n} \right)^n \simeq 1-\frac{1}{e}=0.632</code>), whereas the rest 36.8% will be random copies of them. The non re-sampled rows are denoted as out-of-sample values. The performance of each model in the in-sample rows is calculated and the model (or configuration) with the optimal performance is selected, followed by the calculation of performance in the out-of-sample values. This process is repeated B times and the average performance is returned. 
</p>
<p>Note, that the only computational overhead is with the repetitive re-sampling and calculation of the predictive performance, i.e. no model is fitted nor trained. The final estimated performance usually underestimates the true performance, but this negative bias is smaller than the optimistic uncorrected performance. 
</p>
<p>Note, that all metrics are for maximization. For this reason "mse.mxm", "mae.mxm", "ord_mae.mxm", "poisdev.mxm", "binomdev.mxm" are multiplied by -1.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>out.perf</code></td>
<td>

<p>The B out sampled performances. Their mean is the "bbc.perf" given above.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>bbc.perf</code></td>
<td>

<p>The bootstrap bias corrected performance of the chosen algorithm, model or configuration.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ci</code></td>
<td>

<p>The (1- conf)% confidence interval of the BBC performance. It is based on the empirical or percentile method for bootstrap samples. The lower and upper 2.5% of the "out.perf".
</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Ioannis Tsamardinos, Elissavet Greasidou and Giorgos Borboudakis (2018). Bootstrapping the out-of-sample predictions for efficient and accurate cross-validation. Machine Learning (To appear).  
</p>
<p><a href="https://link.springer.com/article/10.1007/s10994-018-5714-4">https://link.springer.com/article/10.1007/s10994-018-5714-4</a>
</p>


<h3>See Also</h3>

<p><code> cv.ses, cv.gomp </code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">predictions &lt;- matrix(rbinom(200 * 100, 1, 0.7), ncol = 100) 
target &lt;- rbinom(200, 1, 0.5)
bbc(predictions, target, metric = "auc.mxm")
</code></pre>


</div>