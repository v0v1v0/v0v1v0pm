<div class="container">

<table style="width: 100%;"><tr>
<td>step_kmeans</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>K-Means Clustering Variable Reduction</h2>

<h3>Description</h3>

<p>Creates a <em>specification</em> of a recipe step that will convert numeric
variables into one or more by averaging within k-means clusters.
</p>


<h3>Usage</h3>

<pre><code class="language-R">step_kmeans(
  recipe,
  ...,
  k = 5,
  center = TRUE,
  scale = TRUE,
  algorithm = c("Hartigan-Wong", "Lloyd", "Forgy", "MacQueen"),
  max_iter = 10,
  num_start = 1,
  replace = TRUE,
  prefix = "KMeans",
  role = "predictor",
  skip = FALSE,
  id = recipes::rand_id("kmeans")
)

## S3 method for class 'step_kmeans'
tidy(x, ...)

## S3 method for class 'step_kmeans'
tunable(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>recipe</code></td>
<td>
<p>recipe object to which the step will be added.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>one or more selector functions to choose which variables will be
used to compute the components.  See <code>selections</code> for
more details.  These are not currently used by the <code>tidy</code> method.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>k</code></td>
<td>
<p>number of k-means clusterings of the variables.  The value of
<code>k</code> is constrained to be between 1 and one less than the number of
original variables.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>center, scale</code></td>
<td>
<p>logicals indicating whether to mean center and standard
deviation scale the original variables prior to deriving components, or
functions or names of functions for the centering and scaling.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>algorithm</code></td>
<td>
<p>character string specifying the clustering algorithm to use.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>max_iter</code></td>
<td>
<p>maximum number of algorithm iterations allowed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>num_start</code></td>
<td>
<p>number of random cluster centers generated for starting the
Hartigan-Wong algorithm.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>replace</code></td>
<td>
<p>logical indicating whether to replace the original variables.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>prefix</code></td>
<td>
<p>character string prefix added to a sequence of zero-padded
integers to generate names for the resulting new variables.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>role</code></td>
<td>
<p>analysis role that added step variables should be assigned.  By
default, they are designated as model predictors.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>skip</code></td>
<td>
<p>logical indicating whether to skip the step when the recipe is
baked.  While all operations are baked when <code>prep</code> is
run, some operations may not be applicable to new data (e.g. processing
outcome variables).  Care should be taken when using <code>skip = TRUE</code> as
it may affect the computations for subsequent operations.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>id</code></td>
<td>
<p>unique character string to identify the step.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p><code>step_kmeans</code> object.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>K-means clustering partitions variables into k groups such that the sum of
squares between the variables and their assigned cluster means is minimized.
Variables within each cluster are then averaged to derive a new set of k
variables.
</p>


<h3>Value</h3>

<p>Function <code>step_kmeans</code> creates a new step whose class is of
the same name and inherits from <code>step_lincomp</code>, adds it to the
sequence of existing steps (if any) in the recipe, and returns the updated
recipe.  For the <code>tidy</code> method, a tibble with columns <code>terms</code>
(selectors or variables selected), <code>cluster</code> assignments, <code>sqdist</code>
(squared distance from cluster centers), and <code>name</code> of the new variable
names.
</p>


<h3>References</h3>

<p>Forgy, E. W. (1965). Cluster analysis of multivariate data: efficiency versus
interpretability of classifications. <em>Biometrics</em>, <em>21</em>, 768-769.
</p>
<p>Hartigan, J. A., &amp; Wong, M. A. (1979). A K-means clustering algorithm.
<em>Applied Statistics</em>, <em>28</em>, 100-108.
</p>
<p>Lloyd, S. P. (1982). Least squares quantization in PCM. <em>IEEE
Transactions on Information Theory</em>, <em>28</em>(2), 129-137.
</p>
<p>MacQueen, J. (1967). Some methods for classification and analysis of
multivariate observations. In L. M. Le Cam &amp; J. Neyman (Eds.),
<em>Proceedings of the fifth Berkeley Symposium on Mathematical Statistics
and Probability</em> (vol. 1, pp. 281-297). University of California Press.
</p>


<h3>See Also</h3>

<p><code>kmeans</code>, <code>recipe</code>,
<code>prep</code>, <code>bake</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">library(recipes)

rec &lt;- recipe(rating ~ ., data = attitude)
kmeans_rec &lt;- rec %&gt;%
  step_kmeans(all_predictors(), k = 3)
kmeans_prep &lt;- prep(kmeans_rec, training = attitude)
kmeans_data &lt;- bake(kmeans_prep, attitude)

pairs(kmeans_data, lower.panel = NULL)

tidy(kmeans_rec, number = 1)
tidy(kmeans_prep, number = 1)

</code></pre>


</div>