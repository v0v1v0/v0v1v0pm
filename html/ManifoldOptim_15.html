<div class="container">

<table style="width: 100%;"><tr>
<td>manifold.optim</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Manifold optimization</h2>

<h3>Description</h3>

<p>Optimize a function on a manifold.
</p>


<h3>Usage</h3>

<pre><code class="language-R">manifold.optim(
  prob,
  mani.defn,
  method = "LRBFGS",
  mani.params = get.manifold.params(),
  solver.params = get.solver.params(),
  deriv.params = get.deriv.params(),
  x0 = NULL,
  H0 = NULL,
  has.hhr = FALSE
)

moptim(
  prob,
  mani.defn,
  method = "LRBFGS",
  mani.params = get.manifold.params(),
  solver.params = get.solver.params(),
  deriv.params = get.deriv.params(),
  x0 = NULL,
  H0 = NULL,
  has.hhr = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>prob</code></td>
<td>
<p>Problem definition</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mani.defn</code></td>
<td>
<p>Either a Product manifold definition or one of the
Manifold definitions</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p>Name of optimization method. Currently supported methods are:
</p>

<ul>
<li>
<p><code>"LRBFGS"</code>: Limited-memory RBFGS
</p>
</li>
<li>
<p><code>"LRTRSR1"</code>: Limited-memory RTRSR1
</p>
</li>
<li>
<p><code>"RBFGS"</code>: Riemannian BFGS
</p>
</li>
<li>
<p><code>"RBroydenFamily"</code>: Riemannian Broyden family
</p>
</li>
<li>
<p><code>"RCG"</code>: Riemannian conjugate gradients
</p>
</li>
<li>
<p><code>"RNewton"</code>: Riemannian line-search Newton
</p>
</li>
<li>
<p><code>"RSD"</code>: Riemannian steepest descent
</p>
</li>
<li>
<p><code>"RTRNewton"</code>: Riemannian trust-region Newton
</p>
</li>
<li>
<p><code>"RTRSD"</code>: Riemannian trust-region steepest descent
</p>
</li>
<li>
<p><code>"RTRSR1"</code>: Riemannian trust-region symmetric rank-one update
</p>
</li>
<li>
<p><code>"RWRBFGS"</code>: Riemannian BFGS
</p>
</li>
</ul>
<p>See Huang et al (2016a, 2016b) for details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mani.params</code></td>
<td>
<p>Arguments to configure the manifold. Construct with
get.manifold.params</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>solver.params</code></td>
<td>
<p>Arguments to configure the solver. Construct with
get.solver.params</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>deriv.params</code></td>
<td>
<p>Arguments to configure numerical differentiation for
gradient and Hessian, which are used if those functions are not
specified. Construct with get.deriv.params</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x0</code></td>
<td>
<p>Starting point for optimization. A numeric vector whose dimension
matches the total dimension of the overall problem</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>H0</code></td>
<td>
<p>Initial value of Hessian. A <code class="reqn">d \times d</code> matrix, where <code class="reqn">d</code>
is the dimension of <code>x0</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>has.hhr</code></td>
<td>
<p>Indicates whether to apply the idea in Huang et al
(2015) section 4.1 (TRUE or FALSE)</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p><code>moptim</code> is an alias for  <code>manifold.optim</code>.
</p>


<h3>Value</h3>

<table>
<tr style="vertical-align: top;">
<td><code>xopt</code></td>
<td>
<p>Point returned by the solver</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fval</code></td>
<td>
<p>Value of the function evaluated at <code>xopt</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>normgf</code></td>
<td>
<p>Norm of the final gradient</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>normgfgf0</code></td>
<td>
<p>Norm of the gradient at final iterate divided by norm of
the gradient at initiate iterate</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>iter</code></td>
<td>
<p>Number of iterations taken by the solver</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>num.obj.eval</code></td>
<td>
<p>Number of function evaluations</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>num.grad.eval</code></td>
<td>
<p>Number of gradient evaluations</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nR</code></td>
<td>
<p>Number of retraction evaluations</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nV</code></td>
<td>
<p>Number of occasions in which vector transport is first computed</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nVp</code></td>
<td>
<p>Number of remaining computations of vector transport (excluding count in nV)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nH</code></td>
<td>
<p>Number of actions of Hessian</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>elapsed</code></td>
<td>
<p>Elapsed time for the solver (in seconds)</p>
</td>
</tr>
</table>
<h3>References</h3>

<p>Wen Huang, P.A. Absil, K.A. Gallivan, Paul Hand (2016a). "ROPTLIB: an
object-oriented C++ library for optimization on Riemannian manifolds."
Technical Report FSU16-14, Florida State University.
</p>
<p>Wen Huang, Kyle A. Gallivan, and P.A. Absil (2016b).
Riemannian Manifold Optimization Library.
URL <a href="https://www.math.fsu.edu/~whuang2/pdf/USER_MANUAL_for_2016-04-29.pdf">https://www.math.fsu.edu/~whuang2/pdf/USER_MANUAL_for_2016-04-29.pdf</a>
</p>
<p>Wen Huang, K.A. Gallivan, and P.A. Absil (2015). A Broyden Class of
Quasi-Newton Methods for Riemannian Optimization. SIAM  Journal on
Optimization, 25(3):1660-1685.
</p>
<p>S. Martin, A. Raim, W. Huang, and K. Adragni (2020). "ManifoldOptim: 
An R Interface to the ROPTLIB Library for Riemannian Manifold Optimization."
Journal of Statistical Software, 93(1):1-32.
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Not run: 
# ----- Example with objective and gradient written in R -----
set.seed(1234)

p &lt;- 5; n &lt;- 150
B &lt;- matrix(rnorm(n*n), nrow=n)
B &lt;- B + t(B)
D &lt;- diag(p:1, p)

tx &lt;- function(x) { matrix(x, n, p) }
f &lt;- function(x) { X &lt;- tx(x); Trace( t(X) %*% B %*% X %*% D ) }
g &lt;- function(x) { X &lt;- tx(x); 2 * B %*% X %*% D }

mod &lt;- Module("ManifoldOptim_module", PACKAGE = "ManifoldOptim")
prob &lt;- new(mod$RProblem, f, g)

x0 &lt;- as.numeric(orthonorm(matrix(rnorm(n*p), nrow=n, ncol=p)))
mani.params &lt;- get.manifold.params(IsCheckParams = TRUE)
solver.params &lt;- get.solver.params(IsCheckParams = TRUE)
mani.defn &lt;- get.stiefel.defn(n, p)

res &lt;- manifold.optim(prob, mani.defn, method = "RTRSR1",
	mani.params = mani.params, solver.params = solver.params, x0 = x0)
print(res)
head(tx(res$xopt))

## End(Not run)
## Not run: 
library(ManifoldOptim)
library(RcppArmadillo)

# ----- Example with objective and gradient written in C++ -----
set.seed(1234)

p &lt;- 5; n &lt;- 150
B &lt;- matrix(rnorm(n*n), nrow=n)
B &lt;- B + t(B) # force symmetric
D &lt;- diag(p:1, p)

# The Problem class is written in C++. Get a handle to it and set it up from R
Rcpp::sourceCpp(code = '
//[[Rcpp::depends(RcppArmadillo,ManifoldOptim)]]
#include &lt;RcppArmadillo.h&gt;
#include &lt;ManifoldOptim.h&gt;

using namespace Rcpp;
using namespace arma;

class BrockettProblem : public MatrixManifoldOptimProblem
{
public:
	BrockettProblem(const arma::mat&amp; B, const arma::mat&amp; D)
	: MatrixManifoldOptimProblem(false, true), m_B(B), m_D(D) { }

	virtual ~BrockettProblem() { }

	double objFun(const arma::mat&amp; X) const {
		return arma::trace(X.t() * m_B * X * m_D);
	}

	arma::mat gradFun(const arma::mat&amp; X) const {
		return 2 * m_B * X * m_D;
	}

	const arma::mat&amp; GetB() const { return m_B; }
	const arma::mat&amp; GetD() const { return m_D; }

private:
	arma::mat m_B;
	arma::mat m_D;
};

RCPP_MODULE(Brockett_module) {
	class_&lt;BrockettProblem&gt;("BrockettProblem")
	.constructor&lt;mat,mat&gt;()
	.method("objFun", &amp;BrockettProblem::objFun)
	.method("gradFun", &amp;BrockettProblem::gradFun)
	.method("GetB", &amp;BrockettProblem::GetB)
	.method("GetD", &amp;BrockettProblem::GetD)
	;
}
')

prob &lt;- new(BrockettProblem, B, D)
X0 &lt;- orthonorm(matrix(rnorm(n*p), nrow=n, ncol=p))
x0 &lt;- as.numeric(X0)
tx &lt;- function(x) { matrix(x, n, p) }
mani.params &lt;- get.manifold.params(IsCheckParams = TRUE)
solver.params &lt;- get.solver.params(DEBUG = 0, Tolerance = 1e-4,
	Max_Iteration = 1000, IsCheckParams = TRUE, IsCheckGradHess = FALSE)
mani.defn &lt;- get.stiefel.defn(n, p)

res &lt;- manifold.optim(prob, mani.defn, method = "RTRSR1",
	mani.params = mani.params, solver.params = solver.params, x0 = x0)
print(res)
head(tx(res$xopt))

## End(Not run)

</code></pre>


</div>