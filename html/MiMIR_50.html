<div class="container">

<table style="width: 100%;"><tr>
<td>plattCalibration</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>plattCalibration</h2>

<h3>Description</h3>

<p>Function that calculates the Platt Calibrations
</p>


<h3>Usage</h3>

<pre><code class="language-R">plattCalibration(r.calib, p.calib, nbins = 10, pl = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>r.calib</code></td>
<td>
<p>observed binary phenotype</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>p.calib</code></td>
<td>
<p>predicted probabilities</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nbins</code></td>
<td>
<p>number of bins to create the plots</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pl</code></td>
<td>
<p>logical indicating if the function should plot the Reliability diagram and histogram of the calibrations</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Many popular machine learning algorithms produce inaccurate predicted probabilities, especially when applied on a dataset different than the training set.
Platt (1999) proposed an adjustment, in which the original probabilities are used as a predictor in a single-variable logistic regression to produce more accurate adjusted predicted probabilities.
The function will also help the evaluation of the calibration, by plotting: reliability diagrams and distributions of the calibrated and non-calibrated probabilities.
The reliability diagrams plots the mean predicted value within a certain range of posterior probabilities, against the fraction of accurately predicted values.
Finally, we also report accuracy measures for the calibrations: the ECE, MCE and the Log-Loss of the probabilities before and after calibration.
</p>


<h3>Value</h3>

<p>list with samples, responses, calibrations, ECE, MCE and calibration plots if save==T
</p>


<h3>References</h3>

<p>This is a function originally created for the package in eRic, under the name prCalibrate and modified ad hoc for our purposes
(<a href="https://rdrr.io/github/etlundquist/eRic/man/prCalibrate.html">Github</a>)
</p>
<p>J. C. Platt, 'Probabilistic Outputs for Support Vector Machines and Comparisons to Regularized Likelihood Methods', in Advances in Large Margin Classifiers, 1999, pp. 61-74.
</p>


<h3>Examples</h3>

<pre><code class="language-R">library(stats)
library(plotly)

#load the dataset
met &lt;- synthetic_metabolic_dataset
phen &lt;- synthetic_phenotypic_dataset

#Calculating the binarized surrogates
b_phen&lt;-binarize_all_pheno(phen)
#Apply a surrogate models and plot the ROC curve
surr&lt;-calculate_surrogate_scores(met, phen,MiMIR::PARAM_surrogates, bin_names=colnames(b_phen))
#Calibration of the surrogate sex
real_data&lt;-as.numeric(b_phen$sex)
pred_data&lt;-surr$surrogates[,"s_sex"]
plattCalibration(r.calib=real_data, p.calib=pred_data, nbins = 10, pl=TRUE)

</code></pre>


</div>