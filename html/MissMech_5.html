<div class="container">

<table style="width: 100%;"><tr>
<td>TestMCARNormality</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Testing Homoscedasticity, Multivariate Normality, and Missing Completely at Random</h2>

<h3>Description</h3>

<p>The main purpose of this package is to test whether the missing data mechanism, for an incompletely observed data set, is one of 
missing completely at random (MCAR). As a by product, however, this package has the capabilities of imputing incomplete data, 
performing a test to determine whether data have a multivariate normal distribution, performing a test of
equality of covariances for groups, and obtaining normal-theory maximum likelihood estimates for mean and covariance when data are
incomplete. The test of MCAR follows the methodology proposed by Jamshidian and Jalal (2010). 
It is based on testing equality of covariances between groups having identical missing data patterns. The data are imputed, 
using two options of normality and distribution free, and the test of equality of covariances between 
groups with identical missing data patterns is performed also with options of assuming normality (Hawkins test) or non-parametrically.
Users can optionally use their own method of data imputation as well. Multiple imputation is an additional feature of
the program that can be used as a diagnostic tool to help identify cases or variables that contribute to rejection of 
MCAR, when the MCAR test is rejecetd (See Jamshidian and Jalal, 2010 for details). 
As explained in Jamshidian, Jalal, and Jansen (2014), this package can also be used 
for imputing missing data, test of multivariate normality, and test of equality of covariances between several 
groups when data are completly observed.
</p>


<h3>Usage</h3>

<pre><code class="language-R">TestMCARNormality(
  data,
  del.lesscases = 6,
  imputation.number = 1,
  method = "Auto",
  imputation.method = "Dist.Free",
  nrep = 10000,
  n.min = 30,
  seed = 110,
  alpha = 0.05,
  imputed.data = NA
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>A matrix or data frame consisting of at least two columns. Values must be numerical with missing data indicated by NA.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>del.lesscases</code></td>
<td>
<p>Missing data patterns consisting of del.lesscases number of cases or less will be removed from the data set.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>imputation.number</code></td>
<td>
<p>Number of imputations to be used, if data are to be multiply imputed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p>method is an option that allows the user to select one of the methods of Hawkins or nonparametric for the test. If the user is certain that data have multivariate normal distribution, the
method="Hawkins" should be selected. On the other hand if data are not normally distributed,
then method="Nonparametric" should be used. If the user is unsure, then the default value
of method="Auto" will be used, in which case both the Hawkins and the nonparametric tests
will be run, and the default output follows the recommendation by Jamshidian and Jalal
(2010) outlined in their flowchart given in Figure 7 of their paper.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>imputation.method</code></td>
<td>
<p>"Dist.Free": Missing data are imputed nonparametrically using the method of Sirvastava and Dolatabadi (2009); 
also see Jamshidian and Jalal (2010).
</p>
<p>"Normal": Missing data are imputed assuming that the data come from a multivariate normal distribution. The maximum 
likelihood estimate of the mean and covariance obtained from Mls is used for generating imputed values. 
The imputed values are based on the conditional distribution of the missing variables given the observed variables; 
see Jamshidian and Jalal (2010) for more details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nrep</code></td>
<td>
<p>Number of replications used to simulate the Neyman distribution to determine the cut off value for the Neyman test 
in the program SimNey. Larger values increase the accuracy of the Neyman test.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n.min</code></td>
<td>
<p>The minimum number of cases in a group that triggers the use of asymptotic Chi distribution in place of the emprical distribution in the Neyman test of uniformity.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>seed</code></td>
<td>
<p>An initial random number generator seed. The default is 110 that can be reset to a user selected number. If the value is set to NA, a system selected seed is used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alpha</code></td>
<td>
<p>The significance level at which tests are performed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>imputed.data</code></td>
<td>
<p>The user can optionally provide an imputed data set. In this case the program will not impute the data and will use 
the imputed data set for the tests performed. Note that the order of cases in the imputed data set should be the same as 
that of the incomplete data set.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Theoretical, technical and prcatical details about this program and its uses can be found in Jamshidian and Jalal (2010) 
and Jamshidian, Jalal, and Jansen (2014).
</p>


<h3>Value</h3>

<table>
<tr style="vertical-align: top;">
<td><code>analyzed.data</code></td>
<td>
<p>The data that were used in the analysis. If del.lesscases=0, this is the same as the orginal data inputted. 
If del.lesscases &gt; 0, then this is the data with cases removed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>imputed.data </code></td>
<td>
<p>The analyzed.data after imputation. If imputation.number &gt; 1, the first imputed data set is returned.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ordered.data </code></td>
<td>
<p>The analyzed.data ordered according to missing data pattern, usin the function OrderMissing.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>caseorder </code></td>
<td>
<p>A mapping of case number indices from ordered.data to the original data. More specifically, the j-th row 
of the ordered.data is the caseorder[j]-th (the j-th element of caseorder) row of the original data.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pnormality </code></td>
<td>
<p>p-value for the nonparametric test: When imputation.number &gt; 1, this is a vector with each element 
corresponding to each of the imputed data sets.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>adistar </code></td>
<td>
<p>A matrix consisting of the Anderson-Darling test statistic for each group (columns) and each imputation (rows).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>adstar </code></td>
<td>
<p>Sum of adistar:  When imputation.number &gt;1, this is a vector with each element corresponding to each 
of the imputed data sets.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pvalcomb </code></td>
<td>
<p>p-value for the Hawkins test:  When imputation.number &gt;1, this is a vector with each element 
corresponding to each of the imputed data sets.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pvalsn </code></td>
<td>
<p>A matrix consisting of Hawkins test statistics for each group (columns) and each imputation (rows).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>g </code></td>
<td>
<p>Number of patterns used in the analysis.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>combp </code></td>
<td>
<p>Hawkins test statistic: When imputation.number &gt; 1, this is a vector with each element corresponding 
to each of the imputed data sets.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alpha </code></td>
<td>
<p>The significance level at which the hypothesis tests are performed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>patcnt</code></td>
<td>
<p>A vector consisting the number of cases corresponding to each pattern in patused.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>patused </code></td>
<td>
<p>A matrix indicating the missing data patterns in the data set, using 1 and NA's.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>imputation.number </code></td>
<td>
<p>A value greater than or equal to 1. If a value larger than 1 is used, data will be 
imputed imputation.number times.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mu </code></td>
<td>
<p>The normal-theory maximum likelihood estimate of the variables means.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sigma </code></td>
<td>
<p>The normal-theory maximum likelihood estimate of the variables covariance matrix.</p>
</td>
</tr>
</table>
<h3>Note</h3>

<p>Note 1: In the above descriptions "original data" refers to the input data after deletion of the rows consisting of all NA's (if any) 
</p>
<p>Note 2: The normal theory maximum likelihood estimate of mean and covariance is obtained using the EM algorithm, as described in Jamshidian
and Bentler (1999). The standard errors for these estimates, based on the observed information matrix, can be obtained via the 
function Ddf, included in this package.
</p>


<h3>Author(s)</h3>

<p>Mortaza Jamshidian, Siavash Jalal, and Camden Jansen
</p>


<h3>References</h3>

<p>Jamshidian, M. and Bentler, P. M. (1999). “ML estimation of mean and covariance structures with missing data using complete data routines.” <em>Journal of Educational and Behavioral Statistics,</em> 24, 21-41, <a href="https://doi.org/10.2307/1165260">doi:10.2307/1165260</a>.
</p>
<p>Jamshidian, M. and Jalal, S. (2010). “Tests of homoscedasticity, normality, and missing at random for incomplete multivariate data,” <em>Psychometrika,</em> 75, 649-674, <a href="https://doi.org/10.1007/s11336-010-9175-3">doi:10.1007/s11336-010-9175-3</a>.
</p>
<p>Jamshidian, M. Jalal, S., and Jansen, C. (2014). “MissMech: An R Package for Testing Homoscedasticity, Multivariate Normality, and Missing Completely at Random (MCAR),” <em>Journal of Statistical Software,</em> 56(6), 1-31, <a href="https://doi.org/10.18637/jss.v056.i06">doi:10.18637/jss.v056.i06</a>.
</p>


<h3>Examples</h3>

<pre><code class="language-R">#-- Example 1: Data are MCAR and normally distributed

n &lt;- 300
p &lt;- 5
pctmiss &lt;- 0.2
set.seed(1010)
y &lt;- matrix(rnorm(n * p),nrow = n)
missing &lt;- matrix(runif(n * p), nrow = n) &lt; pctmiss
y[missing] &lt;- NA
out &lt;- TestMCARNormality(data=y)
print(out)

# --- Prints the p-value for both the Hawkins and the nonparametric test
summary(out)

# --- Uses more cases
out1 &lt;- TestMCARNormality(data=y, del.lesscases = 1)
print(out1)

#---- performs multiple imputation
Out &lt;- TestMCARNormality (data = y, imputation.number = 10)
summary(Out)
boxplot(Out)

#-- Example 2: Data are MCAR and non-normally distributed (t distributed with d.f. = 5)

n &lt;- 300
p &lt;- 5
pctmiss &lt;- 0.2
set.seed(1010)
y &lt;- matrix(rt(n * p, 5), nrow = n)
missing &lt;- matrix(runif(n * p), nrow = n) &lt; pctmiss
y[missing] &lt;- NA
out &lt;- TestMCARNormality(data=y)
print(out)

# Perform multiple imputation
Out_m &lt;- TestMCARNormality (data = y, imputation.number = 20)
boxplot(Out_m)

#-- Example 3: Data are MAR (not MCAR), but are normally distributed

n &lt;- 300
p &lt;- 5
r &lt;- 0.3
mu &lt;- rep(0, p)
sigma &lt;- r * (matrix(1, p, p) - diag(1, p))+ diag(1, p)
set.seed(110)
eig &lt;- eigen(sigma)
sig.sqrt &lt;- eig$vectors %*%  diag(sqrt(eig$values)) %*%  solve(eig$vectors)
sig.sqrt &lt;- (sig.sqrt + sig.sqrt) / 2
y &lt;- matrix(rnorm(n * p), nrow = n) %*%  sig.sqrt
tmp &lt;- y
for (j in 2:p){
  y[tmp[, j - 1] &gt; 0.8, j] &lt;- NA 
}
out &lt;- TestMCARNormality(data = y, alpha =0.1)
print(out)

#-- Example 4: Multiple imputation; data are MAR (not MCAR), but are normally distributed

n &lt;- 300
p &lt;- 5
pctmiss &lt;- 0.2
set.seed(1010)
y &lt;- matrix (rnorm(n * p), nrow = n)
missing &lt;- matrix(runif(n * p), nrow = n) &lt; pctmiss
y[missing] &lt;- NA
Out &lt;- OrderMissing(y)
y &lt;- Out$data
spatcnt &lt;- Out$spatcnt
g2 &lt;- seq(spatcnt[1] + 1, spatcnt[2])
g4 &lt;- seq(spatcnt[3] + 1, spatcnt[4])
y[c(g2, g4), ] &lt;- 2 * y[c(g2, g4), ]
out &lt;- TestMCARNormality(data = y, imputation.number = 20)
print(out)
boxplot(out)

# Removing Groups 2 and 4
y1= y[-seq(spatcnt[1]+1,spatcnt[2]),]
out &lt;- TestMCARNormality(data=y1,imputation.number = 20)
print(out)
boxplot(out)

#-- Example 5: Test of homoscedasticity for complete data

n &lt;- 50
p &lt;- 5
r &lt;- 0.4
sigma &lt;- r * (matrix(1, p, p) - diag(1, p)) + diag(1, p)
set.seed(1010)
eig &lt;- eigen(sigma)
sig.sqrt &lt;- eig$vectors %*%  diag(sqrt(eig$values)) %*%  solve(eig$vectors)
sig.sqrt &lt;- (sig.sqrt + sig.sqrt) / 2
y1 &lt;- matrix(rnorm(n * p), nrow = n) %*%  sig.sqrt
n &lt;- 75
p &lt;- 5
y2 &lt;- matrix(rnorm(n * p), nrow = n)
n &lt;- 25
p &lt;- 5
r &lt;- 0
sigma &lt;- r * (matrix(1, p, p) - diag(1, p)) + diag(2, p)
y3 &lt;- matrix(rnorm(n * p), nrow = n) %*%  sqrt(sigma)
ycomplete &lt;- rbind(y1 ,y2 ,y3)
y1 [ ,1] &lt;- NA
y2[,c(1 ,3)] &lt;- NA
y3 [ ,2] &lt;- NA
ygroup &lt;- rbind(y1, y2, y3)
out &lt;- TestMCARNormality(data = ygroup, method = "Hawkins", imputed.data = ycomplete)
print(out)

# ---- Example 6, real data

data(agingdata)
TestMCARNormality(agingdata, del.lesscases = 1)

</code></pre>


</div>