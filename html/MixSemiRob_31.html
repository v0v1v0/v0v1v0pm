<div class="container">

<table style="width: 100%;"><tr>
<td>semimrFull</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Semiparametric Mixture Regression Models with Single-index Proportion and Fully Iterative Backfitting</h2>

<h3>Description</h3>

<p>Assume that <code class="reqn">\boldsymbol{x} = (\boldsymbol{x}_1,\cdots,\boldsymbol{x}_n)</code> is an n by p matrix and
<code class="reqn">Y = (Y_1,\cdots,Y_n)</code> is an n-dimensional vector of response variable.
The conditional distribution of <code class="reqn">Y</code> given
<code class="reqn">\boldsymbol{x}</code> can be written as:
</p>
<p style="text-align: center;"><code class="reqn">f(y|\boldsymbol{x},\boldsymbol{\alpha},\pi,m,\sigma^2) =
\sum_{j=1}^C\pi_j(\boldsymbol{\alpha}^{\top}\boldsymbol{x})
\phi(y|m_j(\boldsymbol{\alpha}^{\top}\boldsymbol{x}),\sigma_j^2(\boldsymbol{\alpha}^{\top}\boldsymbol{x})).</code>
</p>

<p>‘semimrFull’ is used to estimate the mixture of single-index models described above,
where <code class="reqn">\phi(y|m_j(\boldsymbol{\alpha}^{\top}\boldsymbol{x}),\sigma_j^2(\boldsymbol{\alpha}^{\top}\boldsymbol{x}))</code>
represents the normal density with a mean of <code class="reqn">m_j(\boldsymbol{\alpha}^{\top}\boldsymbol{x})</code> and
a variance of <code class="reqn">\sigma_j^2(\boldsymbol{\alpha}^{\top}\boldsymbol{x})</code>, and
<code class="reqn">\pi_j(\cdot), \mu_j(\cdot), \sigma_j^2(\cdot)</code> are unknown smoothing single-index functions
capable of handling high-dimensional non-parametric problem.
This function employs kernel regression and a fully iterative backfitting (FIB) estimation procedure
(Xiang and Yao, 2020).
</p>


<h3>Usage</h3>

<pre><code class="language-R">semimrFull(x, y, h = NULL, coef = NULL, ini = NULL, grid = NULL, maxiter = 100)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>an n by p matrix of observations where n is the number of observations and
p is the number of explanatory variables.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>an n-dimensional vector of response values.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>h</code></td>
<td>
<p>bandwidth for the kernel regression. Default is NULL, and
the bandwidth is computed in the function by cross-validation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>coef</code></td>
<td>
<p>initial value of <code class="reqn">\boldsymbol{\alpha}^{\top}</code> in the model, which plays a role
of regression coefficient in a regression model. Default is NULL, and
the value is computed in the function by sliced inverse regression (Li, 1991).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ini</code></td>
<td>
<p>initial values for the parameters. Default is NULL, which obtains the initial values,
assuming a linear mixture model.
If specified, it can be a list with the form of <code>list(pi, mu, var)</code>, where
<code>pi</code> is a vector of mixing proportions,
<code>mu</code> is a vector of component means, and
<code>var</code> is a vector of component variances.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>grid</code></td>
<td>
<p>grid points at which nonparametric functions are estimated.
Default is NULL, which uses the estimated mixing proportions, component means, and
component variances as the grid points after the algorithm converges.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>maxiter</code></td>
<td>
<p>maximum number of iterations. Default is 100.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>A list containing the following elements:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>pi</code></td>
<td>
<p>matrix of estimated mixing proportions.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mu</code></td>
<td>
<p>estimated component means.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>var</code></td>
<td>
<p>estimated component variances.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>coef</code></td>
<td>
<p>estimated regression coefficients.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>run</code></td>
<td>
<p>total number of iterations after convergence.</p>
</td>
</tr>
</table>
<h3>References</h3>

<p>Xiang, S. and Yao, W. (2020). Semiparametric mixtures of regressions with single-index
for model based clustering. Advances in Data Analysis and Classification, 14(2), 261-292.
</p>
<p>Li, K. C. (1991). Sliced inverse regression for dimension reduction.
Journal of the American Statistical Association, 86(414), 316-327.
</p>


<h3>See Also</h3>

<p><code>semimrOne</code>, <code>sinvreg</code> for initial value calculation of
<code class="reqn">\boldsymbol{\alpha}^{\top}</code>.
</p>


<h3>Examples</h3>

<pre><code class="language-R">xx = NBA[, c(1, 2, 4)]
yy = NBA[, 3]
x = xx/t(matrix(rep(sqrt(diag(var(xx))), length(yy)), nrow = 3))
y = yy/sd(yy)
ini_bs = sinvreg(x, y)
ini_b = ini_bs$direction[, 1]
est = semimrFull(x[1:50, ], y[1:50], h = 0.3442, coef = ini_b)
</code></pre>


</div>