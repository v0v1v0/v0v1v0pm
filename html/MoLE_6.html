<div class="container">

<table style="width: 100%;"><tr>
<td>CANDIDATESCORE</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Score candidate expressions
</h2>

<h3>Description</h3>

<p>Provides each candidate expression for some meaning or function with a score in which (depending on the model settings) semantic match, lexeme activation, (relative) frequency of use, recency, collostruction frequency, semantic weight, and/or economy of expression are taken into consideration.
</p>


<h3>Usage</h3>

<pre><code class="language-R">CANDIDATESCORE(lexicon, type = "referringExpression")
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>lexicon</code></td>
<td>

<p>lexicon with candidate expresions
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>type</code></td>
<td>

<p>Type of function for which an expression has to be found (<code>referringExpression</code>, <code>nounMarker</code>, <code>verbMarker</code>, or <code>pronoun</code>).
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Collostruction frequencies are determined differently for different type of functions.
The lighter, the better; recency starts with 0.
</p>


<h3>Value</h3>

<p>Vector of scores, corresponding to the entries evaluated.
</p>


<h3>Note</h3>

<p>Match and collostruction frequency are calculated separately before <code>CANDIDATESCORE</code> can apply. In the example below, the latter is randomly set for illustration purposes.
</p>


<h3>Author(s)</h3>

<p>Sander Lestrade
</p>


<h3>See Also</h3>

<p><code>SELECTVERB</code>, <code>SELECTACTOR</code>, <code>SELECTUNDERGOER</code>, <code>REFCHECK</code>, <code>TOPICCOPY</code>, <code>GENERALIZE</code>, <code>CHECKSUCCESS</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">FOUND()
lexicon=head(population[[1]]$nouns)
lexicon$match=VMATCH(lexicon[1,1:9], lexicon)
lexicon$collostruction=sample(100, nrow(lexicon))	
lexicon$score=CANDIDATESCORE(lexicon)
</code></pre>


</div>