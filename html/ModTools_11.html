<div class="container">

<table style="width: 100%;"><tr>
<td>VarImp</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Variable Importance for Regression and Classification Models</h2>

<h3>Description</h3>

<p>Variable importance is an expression of the desire to know how important a variable is within a group of predictors for a particular model. But in general it is not a well defined concept, say there is no theoretically defined variable importance metric. Nevertheless, there are some approaches that have been established in practice for some regression and classification algorithms.
The present function provides an interface for calculating variable importance for some of the models produced by <code>FitMod</code>, comprising linear models, classification trees, random forests, C5 trees and neural networks. The intention here is to provide reasonably homogeneous output and plot routines.
</p>


<h3>Usage</h3>

<pre><code class="language-R">VarImp(x, scale = FALSE, sort = TRUE, ...)

## S3 method for class 'FitMod'
VarImp(x, scale = FALSE, sort = TRUE, type=NULL, ...)
## Default S3 method:
VarImp(x, scale = FALSE, sort = TRUE, ...)


## S3 method for class 'VarImp'
plot(x, sort = TRUE, maxrows = NULL,
           main = "Variable importance", ...)

## S3 method for class 'VarImp'
print(x, digits = 3, ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>the fitted model</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>scale</code></td>
<td>
<p>logical, should the importance values be scaled to 0 and 100?</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>parameters to pass to the specific <code>VarImp</code> methods</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sort</code></td>
<td>
<p>the name of the column, the importance table should be ordered after</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>maxrows</code></td>
<td>
<p>the maximum number of rows to be reported</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>main</code></td>
<td>
<p>the main title for the plot </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>type</code></td>
<td>
<p>some models have more than one type available to produce a variable importance. Linear models accept one of <code>"lmg"</code>, <code>"pmvd"</code>, <code>"first"</code>, <code>"last"</code>, <code>"betasq"</code>, <code>"pratt"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>digits</code></td>
<td>
<p> the number of digits for printing the "VarImp" table </p>
</td>
</tr>
</table>
<h3>Details</h3>

<p><b>Linear Models</b>:  <code style="white-space: pre;">⁠   ⁠</code> For linear models there's a fine package <span class="pkg">relaimpo</span> available on CRAN containing several interesting approaches for quantifying the variable importance. See the original documentation.
</p>
<p><b>rpart</b>, <b>Random Forest</b>:  <code style="white-space: pre;">⁠   ⁠</code> <code>VarImp.rpart</code> and <code>VarImp.randomForest</code> are wrappers around the importance functions from the <span class="pkg">rpart</span> or <span class="pkg">randomForest</span> packages, respectively.
</p>
<p><b>C5.0</b>:  <code style="white-space: pre;">⁠   ⁠</code> C5.0 measures predictor importance by determining the
percentage of training set samples that fall into all the terminal
nodes after the split. For example, the predictor in the first split
automatically has an importance measurement of 100 percent since all
samples are affected by this split. Other predictors may be used
frequently in splits, but if the terminal nodes cover only a handful
of training set samples, the importance scores may be close to
zero. The same strategy is applied to rule-based models and boosted
versions of the model. The underlying function can also return the
number of times each predictor was involved in a split by using the
option <code>metric="usage"</code>.
</p>
<p><b>Neural Networks</b>:  <code style="white-space: pre;">⁠   ⁠</code> The method used here is "Garson weights".
</p>
<p><b>SVM, GLM, Multinom</b>:  <code style="white-space: pre;">⁠   ⁠</code> There are no implementations for these models so far.
</p>


<h3>Value</h3>

<p>A data frame with class <code>c("VarImp.train", "data.frame")</code> for
<code>VarImp.train</code> or a matrix for other models.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;</p>


<h3>References</h3>

<p>Quinlan, J. (1992). Learning with continuous classes. Proceedings of
the 5th Australian Joint Conference On Artificial Intelligence,
343-348.</p>


</div>