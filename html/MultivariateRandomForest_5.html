<div class="container">

<table style="width: 100%;"><tr>
<td>Node_cost</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Information Gain</h2>

<h3>Description</h3>

<p>Compute the cost function of a tree node
</p>


<h3>Usage</h3>

<pre><code class="language-R">Node_cost(y, Inv_Cov_Y, Command)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>Output Features for the samples of the node</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Inv_Cov_Y</code></td>
<td>
<p>Inverse of Covariance matrix of Output Response matrix for MRF(Input [0 0;0 0] for RF)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Command</code></td>
<td>
<p>1 for univariate Regression Tree (corresponding to RF) and 2 for Multivariate Regression Tree (corresponding to MRF)</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>In multivariate trees (MRF) node cost is measured as the sum of squares of the Mahalanobis distance to capture the correlations in 
the data whereas in univariate trees node cost is measured as the sum of Euclidean distance square. Mahalanobis Distance captures 
the distance of the sample point from the mean of the node along the principal component axes.
</p>


<h3>Value</h3>

<p>cost or entropy of samples in a node of a tree
</p>


<h3>References</h3>

<p>Segal, Mark, and Yuanyuan Xiao. "Multivariate random forests." 
Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery 1.1 (2011): 80-87.
</p>


<h3>Examples</h3>

<pre><code class="language-R">library(MultivariateRandomForest)
y=matrix(runif(10*2),10,2)
Inv_Cov_Y=solve(cov(y))
Command=2
#Command=2 for MRF and 1 for RF
#This function calculates information gain of a node
Cost=Node_cost(y,Inv_Cov_Y,Command)
</code></pre>


</div>