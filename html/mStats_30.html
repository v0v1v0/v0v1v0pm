<div class="container">

<table style="width: 100%;"><tr>
<td>regress</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Linear Regression Model</h2>

<h3>Description</h3>

<p><code>regress()</code> produces summary of the model
with coefficients and 95% Confident Intervals.
</p>
<p><code>`predict.regress`</code> a S3 method for <code>predict</code> to generate
statistics related to the prediction of the linear model using the output
from the <code>regress</code> function of the <code>mStats</code>.
</p>
<p><code>`plot.regress`</code> is a S3 method for <code>plot()</code> to create
graphs for checking diagnostics of linear model using the output from
the <code>regress</code> function of the <code>mStats</code>.
</p>
<p><code>`ladder`</code> converts a variable into a normally
distributed one.
</p>
<p><code>`hettest`</code> performs the Breusch-Pagan test
for heteroskedasticity.
It presents evidence against the
null hypothesis that t=0 in Var(e)=sigma^2 exp(zt).
The formula are based on the <code>bptest</code> function
in <code>lmtest</code> package.
</p>
<p><code>`linkTest`</code> determines whether a model in R is
'well specified' using the <code>STATA</code>'s <code>linkTest</code>.
</p>


<h3>Usage</h3>

<pre><code class="language-R">regress(model, vce = FALSE, digits = 5)

## S3 method for class 'regress'
predict(object, ...)

## S3 method for class 'regress'
plot(x, ...)

ladder(data, var)

hettest(regress, studentize = FALSE)

linkTest(model, vce = FALSE, digits = 5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>model</code></td>
<td>
<p>glm or lm model</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>vce</code></td>
<td>
<p>if <code>TRUE</code>, robust standard errors are calculated.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>digits</code></td>
<td>
<p>specify rounding of numbers. See <code>round</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>object</code></td>
<td>
<p>a model object for which prediction is desired.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>additional arguments affecting the predictions produced.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>the coordinates of points in the plot. Alternatively, a
single plotting structure, function or <em>any <span style="font-family: Courier New, Courier; color: #666666;"><b>R</b></span> object with a
<code>plot</code> method</em> can be provided.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>dataset</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>var</code></td>
<td>
<p>variable name</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>regress</code></td>
<td>
<p>output from <code>regress</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>studentize</code></td>
<td>
<p>logical.
If set to <code>TRUE</code> Koenker's studentized version
of the test statistic will be used.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p><code>regress</code> is based on <code>lm</code>. All statistics presented
in the function's output are derivatives of <code>lm</code>,
except AIC value which is obtained from <code>AIC</code>.
It uses <code>lm()</code> function to run the model.
</p>
<p><strong>Outputs</strong>
</p>
<p>Outputs can be divided into three parts.
</p>

<ol>
<li> <p><code style="white-space: pre;">⁠Info of the model⁠</code>:
Here provides number of observations (Obs.), F value, p-value
from F test,
R Squared value, Adjusted R Squared value, square root of mean square
error
(Root MSE) and AIC value.
</p>
</li>
<li> <p><code>Errors</code>:
Outputs from <code>anova(model)</code> is tabulated here. SS, DF and MS indicate
sum of square of errors, degree of freedom and mean of square of errors.
</p>
</li>
<li> <p><code style="white-space: pre;">⁠Regression Output⁠</code>:
Coefficients from summary of model are tabulated here along with 95\
confidence interval.
</p>
</li>
</ol>
<p><strong>using Robust Standard Errors</strong>
</p>
<p>if heteroskedasticity is present in our data sample,
the ordinary least square (OLS) estimator will remain unbiased
and consistent,
but not efficient. The estimated OLS standard errors
will be biased and cannot be solved with a larger sample size.
To remedy this, robust standard errors can be used to adjusted
standard errors.
</p>
<p>The <code>regress</code> uses sandwich estimator to estimate Huber-White's standard
errors. The calculation is based on the tutorial by Kevin Goulding.
</p>
<p style="text-align: center;"><code class="reqn">Variance of Robust = (N / N - K) (X'X)^(-1)
 \sum{Xi X'i ei^2} (X'X)^(-1)</code>
</p>

<p>where N =  number of observations, and K =  the number of regressors
(including the intercept). This returns a Variance-covariance (VCV)
matrix
where the diagonal elements are the estimated heteroskedasticity-robust
coefficient
variances — the ones of interest. Estimated coefficient standard errors
are the square root of these diagonal elements.
</p>
<p><code>`predict.regress`</code> generates an original data with statistics for model
diagnostics:
</p>

<ol>
<li> <p><code>fitted</code> (Fitted values)
</p>
</li>
<li> <p><code>resid</code> (Residuals)
</p>
</li>
<li> <p><code>std.resid</code> (Studentized Residuals)
</p>
</li>
<li> <p><code>hat</code> (leverage)
</p>
</li>
<li> <p><code>sigma</code>
</p>
</li>
<li> <p><code>cooksd</code> (Cook's Distance)
</p>
</li>
</ol>
<p>The <code style="white-space: pre;">⁠Breusch-Pagan test⁠</code> fits a linear regression model
to the residuals of a linear regression model
(by default the same explanatory variables are taken as
in the main regression model) and rejects if too
much of the variance is explained by the additional
explanatory variables. Under <code class="reqn">H_0</code> the test statistic
of the Breusch-Pagan test follows a chi-squared distribution
with <code>parameter</code> (the number of regressors without
the constant in the model) degrees of freedom.
</p>
<p>The code for <code>`linkTest`</code> has been modified from Keith Chamberlain's linktext.
www.ChamberlainStatistics.com
https://gist.github.com/KeithChamberlain/8d9da515e73a27393effa3c9fe571c3f
</p>


<h3>Value</h3>

<p>a list containing
</p>

<ol>
<li> <p><code>info</code> - info and error tables
</p>
</li>
<li> <p><code>reg</code> - regression table
</p>
</li>
<li> <p><code>model</code> - raw model output from <code>lm()</code>
</p>
</li>
<li> <p><code>fit</code> - formula for fitting the model
</p>
</li>
<li> <p><code>lbl</code> - variable labels for further processing in <code>summary</code>.
</p>
</li>
</ol>
<h3>Note</h3>

<p>Credits to Kevin Goulding, The Tarzan Blog.
</p>


<h3>Author(s)</h3>

<p>Email: <a href="mailto:dr.myominnoo@gmail.com">dr.myominnoo@gmail.com</a>
</p>
<p>Website: <a href="https://myominnoo.github.io/">https://myominnoo.github.io/</a>
</p>


<h3>References</h3>

<p>T.S. Breusch &amp; A.R. Pagan (1979),
A Simple Test for Heteroscedasticity and Random
Coefficient Variation.
<em>Econometrica</em> <b>47</b>, 1287–1294
</p>
<p>R. Koenker (1981), A Note on Studentizing a Test for
Heteroscedasticity. <em>Journal of Econometrics</em>
<b>17</b>, 107–112.
</p>
<p>W. Krämer &amp; H. Sonnberger (1986),
<em>The Linear Regression Model under Test</em>.
Heidelberg: Physics
</p>


<h3>Examples</h3>

<pre><code class="language-R">
fit &lt;- lm(Ozone ~ Wind, data = airquality)
regress(fit)

## Not run: 
## labelling variables
airquality2 &lt;- label(airquality, Ozone = "Ozone level", Wind = "Wind Speed")
fit2 &lt;- lm(Ozone ~ Wind, data = airquality2)
reg &lt;- regress(fit2)
str(reg)

## End(Not run)


## Not run: 
predict(reg)

## End(Not run)


## Not run: 
plot(reg)

## End(Not run)


ladder(airquality, Ozone)


## Not run: 
hettest(reg)

## End(Not run)


## Not run: 
linkTest(fit)

## End(Not run)

</code></pre>


</div>