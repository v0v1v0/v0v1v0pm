<div class="container">

<table style="width: 100%;"><tr>
<td>f_fit_gradient_01</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Fit Multivariate Regression Model with mactivate Using Gradient Descent
</h2>

<h3>Description</h3>

<p>Use simple gradient descent to locate model parameters, i.e., primary effects, multiplicative effects, and activation parameters, <code>W</code>.
</p>


<h3>Usage</h3>

<pre><code class="language-R">f_fit_gradient_01(
X, 
y, 
m_tot, 
U = NULL, 
m_start = 1, 
mact_control = f_control_mactivate(), 
verbosity = 2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>

<p>Numerical matrix, <code>N</code> x <code>d</code> of model inputs.  Do not include intercept term.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>

<p>Numerical vector of length <code>N</code>.  Model response, or output.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>m_tot</code></td>
<td>

<p>Scalar non-negative integer.  Total number of columns of activation layer, <code>W</code>, over which to fit.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>U</code></td>
<td>

<p>Numerical matrix, <code>N</code> x <code>d_u</code> of model inputs to send to the activation layer, <code>W</code>.  The default, <code>NULL</code>, instructs this function to simply use arg <code>X</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>m_start</code></td>
<td>

<p>Currently not used.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mact_control</code></td>
<td>

<p>Named list of class <code>control_mactivate_obj</code> as created by fun <code>f_control_mactivate</code> — fitting hyperparameters.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbosity</code></td>
<td>

<p>Scalar integer.
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Please make sure to read Details in <code>f_dmss_dW</code> help page before using this function.
</p>


<h3>Value</h3>


<p>An unnamed list of class <code>mactivate_fit_gradient_01</code> of length <code>m_tot + 1</code>.  Each node is a named list containing fitted parameter estimates.  The first top-level node of this object contains parameter estimates when fitting ‘primary effects’ only (<code>W</code> has no columns), the second, parameter estimates for fitting with 1 column of <code>W</code>, and so on.
</p>


<h3>See Also</h3>

<p>Essentially equivalent to, but likely slower than: <code>f_fit_hybrid_01</code>.  See <code>f_fit_gradient_logistic_01</code> for logistic data (binomial response).
</p>


<h3>Examples</h3>

<pre><code class="language-R">
xxnow &lt;- Sys.time()

library(mactivate)

set.seed(777)


d &lt;- 4
N &lt;- 2000

X &lt;- matrix(rnorm(N*d, 0, 1), N, d) ####

colnames(X) &lt;- paste0("x", I(1:d))

############# primary effects
b &lt;- rep_len( c(-1/2, 1/2), d )



###########

xxA &lt;- (X[ , 1]+1/3) * (X[ , 2]-1/3)
#xxA &lt;- (X[ , 1]+0/3) * (X[ , 2]-0/3)


ystar &lt;-
X %*% b +
2 * xxA


m_tot &lt;- 4
#############





xs2 &lt;- "y ~ . "


xtrue_formula &lt;- eval(parse(text=xs2))

xnoint_formula &lt;- eval(parse(text="y ~ . - xxA"))



yerrs &lt;- rnorm(N, 0, 3)

y &lt;- ystar + yerrs

## y &lt;- (y - mean(y)) / sd(y)


########## standardize X
Xall &lt;- t( ( t(X) - apply(X, 2, mean) ) / apply(X, 2, sd) )
yall &lt;- y
Nall &lt;- N


####### fold index
xxfoldNumber &lt;- rep_len(1:2, N)

ufolds &lt;- sort(unique(xxfoldNumber)) ; ufolds


############### predict
############### predict


dfx &lt;- data.frame("y"=yall, Xall, xxA)

tail(dfx)



################### incorrectly fit LM: no interactions

xlm &lt;- lm(xnoint_formula , data=dfx)
summary(xlm)
yhat &lt;- predict(xlm, newdata=dfx)
sqrt( mean( (yall - yhat)^2 ) )



################### correctly fit LM
xlm &lt;- lm(xtrue_formula, data=dfx)
summary(xlm)
yhat &lt;- predict(xlm, newdata=dfx)
sqrt( mean( (yall - yhat)^2 ) )





################ fit using gradient m-activation
######

m_tot &lt;- 4


xcmact_gradient &lt;-
f_control_mactivate(
param_sensitivity = 10^11,
bool_free_w       = TRUE,
w0_seed           = 0.05,
w_col_search      = "alternate",
bool_headStart    = TRUE,
ss_stop           = 10^(-12), ###
escape_rate       = 1.02,  #### 1.0002,
Wadj              = 1/1,
force_tries       = 0,
lambda            = 0
)

#### Fit

Uall &lt;- Xall

head(Uall)

xthis_fold &lt;- ufolds[ 1 ]

xndx_test &lt;- which( xxfoldNumber %in% xthis_fold )
xndx_train &lt;- setdiff( 1:Nall, xndx_test )

X_train &lt;- Xall[ xndx_train, , drop=FALSE ]
y_train &lt;- yall[ xndx_train ]
U_train &lt;- Uall[ xndx_train, , drop=FALSE ]


xxls_out &lt;-
f_fit_gradient_01(
X = X_train,
y = y_train,
m_tot = m_tot,
U = U_train,
m_start = 1,
mact_control = xcmact_gradient,
verbosity = 0
)



######### check test error

U_test &lt;- Uall[ xndx_test, , drop=FALSE ]
X_test &lt;- Xall[ xndx_test, , drop=FALSE ]
y_test &lt;- yall[ xndx_test ]


yhatTT &lt;- matrix(NA, length(xndx_test), m_tot+1)

for(iimm in 0:m_tot) {
    yhat_fold &lt;- predict(object=xxls_out, X0=X_test, U0=U_test, mcols=iimm )
    yhatTT[ , iimm + 1 ] &lt;- yhat_fold
}

errs_by_m &lt;- NULL
for(iimm in 1:ncol(yhatTT)) {
    yhatX &lt;- yhatTT[ , iimm]
    errs_by_m[ iimm ] &lt;- sqrt(mean( (y_test - yhatX)^2 ))
    cat(iimm, "::", errs_by_m[ iimm ])
}


##### plot test RMSE vs m

plot(0:(length(errs_by_m)-1), errs_by_m, type="l", xlab="m", ylab="RMSE Cost")





##################
xtrue_formula_use &lt;- xtrue_formula


xlm &lt;- lm(xnoint_formula , data=dfx[ xndx_train, ])
yhat &lt;- predict(xlm, newdata=dfx[ xndx_test, ])
cat("\n\n", "No interaction model RMSE:", sqrt( mean( (y_test - yhat)^2 ) ), "\n")


xlm &lt;- lm(xtrue_formula_use , data=dfx[ xndx_train, ])
yhat &lt;- predict(xlm, newdata=dfx[ xndx_test, ])
cat("\n\n", "'true' model RMSE:", sqrt( mean( (y_test - yhat)^2 ) ), "\n")


cat( "Runtime:", difftime(Sys.time(), xxnow, units="secs"), "\n" )

</code></pre>


</div>