<div class="container">

<table style="width: 100%;"><tr>
<td>match.bca</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Block Coordinate Ascent Method
</h2>

<h3>Description</h3>

<p>This function solves the multidimensional assignment problem with decomposable costs (MDADC) by block coordinate ascent. The dissimilarity function is the squared Euclidean distance. 
</p>


<h3>Usage</h3>

<pre><code class="language-R">match.bca(x, unit = NULL, w = NULL, 
	method = c("cyclical", "random"), control = list())
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>data: matrix of dimensions <code class="reqn">(mn,p)</code> or 3D array of dimensions <code class="reqn">(p,m,n)</code> with <code class="reqn">m</code> = number of labels/classes, <code class="reqn">n</code> = number of sample units, and <code class="reqn">p</code> = number of variables)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>unit</code></td>
<td>
<p>integer (=number of units) or vector mapping rows of <code>x</code> to sample units (length <code class="reqn">mn</code>). Must be specified only if <code>x</code> is a matrix.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>w</code></td>
<td>
<p>weights for loss function: single positive number, 
<code class="reqn">p</code>-vector of length, or <code class="reqn">(p,p)</code> positive definite matrix</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p>sweeping method for block coordinate ascent: <code>cyclical</code> or <code>random</code> (simple random sampling without replacement)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>control</code></td>
<td>
<p>tuning parameters</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Given a set of <code class="reqn">n</code> statistical units, each having <code class="reqn">m</code> possibly mislabeled feature vectors, the one-to-one matching problem is to find a set of <code class="reqn">n</code> label permutations that produce the best match of feature vectors across units. The objective function to minimize is the sum of (weighted) squared Euclidean distances between all pairs of feature vectors having the same (new) label. This amounts to minimizing the sum of the within-label variances.  
The sample means and sample covariances of the matched feature vectors are calculated as a post-processing step.  
</p>
<p>The block-coordinate ascent (BCA) algorithm successively sweeps through the statistical units (=blocks), each time relabeling the <code class="reqn">m</code> feature vectors of a unit to best match those of the other <code class="reqn">n-1</code> units. 
</p>
<p>If <code>x</code> is a matrix, the rows should be sorted by increasing unit label and  <code>unit</code> should be a nondecreasing sequence of integers, for example <code class="reqn">(1,...,1,2,...,2,...,n,...,n)</code> with each integer <code class="reqn">1,...,n</code> replicated <code class="reqn">m</code> times. 
</p>
<p>The argument <code>w</code> can be specified as a vector of positive numbers (will be recycled to length <code class="reqn">p</code> if needed) or as a positive definite matrix of size <code class="reqn">(p,p)</code>.
</p>
<p>The optional argument <code>control</code> is a list with three fields: <code>sigma</code>, starting point for the optimization (<code class="reqn">(m,n)</code> matrix of permutations; <code>maxit</code>, maximum number of iterations; and <code>equal.variance</code>, logical value that specifies whether the returned sample covariance matrices <code>V</code> for matched features should be equal between labels/classes (TRUE) or label-specific (FALSE, default).  
</p>


<h3>Value</h3>

<p>A list of class <code>matchFeat</code> with components
</p>

<dl>
<dt><code>sigma</code></dt>
<dd>
<p>best set of permutations for feature vectors (<code class="reqn">(m,n)</code> matrix)</p>
</dd>
<dt><code>cluster</code></dt>
<dd>
<p>associated clusters (=inverse permutations)</p>
</dd>
<dt><code>objective</code></dt>
<dd>
<p>minimum objective value</p>
</dd>
<dt><code>mu</code></dt>
<dd>
<p>sample mean for each class/label (<code class="reqn">(p,m)</code> matrix)</p>
</dd>
<dt><code>V</code></dt>
<dd>
<p>sample covariance for each class/label (<code class="reqn">(p,m)</code> matrix</p>
</dd>
<dt><code>call</code></dt>
<dd>
<p>function call</p>
</dd>
</dl>
<h3>References</h3>

<p>Degras (2022) "Scalable feature matching across large data collections."  
<a href="https://doi.org/10.1080/10618600.2022.2074429">doi:10.1080/10618600.2022.2074429</a> <br>
Wright (2015). Coordinate descent algorithms. <a href="https://arxiv.org/abs/1502.04759">https://arxiv.org/abs/1502.04759</a>
</p>


<h3>See Also</h3>

<p><code>match.2x</code>,
<code>match.bca.gen</code>, <code>match.gaussmix</code>, 
<code>match.kmeans</code>, <code>match.rec</code>, <code>match.template</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">data(optdigits)
m &lt;- length(unique(optdigits$label)) # number of classes
n &lt;- nrow(optdigits$x) / m # number of units

## Use function with data in matrix form
fit1 &lt;- match.bca(optdigits$x, unit=n)

## Use function with data in array form
p &lt;- ncol(optdigits$x)
x &lt;- t(optdigits$x)
dim(x) &lt;- c(p,m,n)
fit2 &lt;- match.bca(x)

</code></pre>


</div>