<div class="container">

<table style="width: 100%;"><tr>
<td>match.gaussmix</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Gaussian Mixture Approach to One-To-One Feature Matching</h2>

<h3>Description</h3>

<p>This function performs maximum likelihood estimation (MLE) for the one-to-one feature matching problem represented as a multivariate Gaussian mixture model. MLE is carried out via the EM algorithm. 
</p>


<h3>Usage</h3>

<pre><code class="language-R">match.gaussmix(x, unit = NULL, mu = NULL, V = NULL, equal.variance = FALSE, 
	method = c("exact", "approx"), fixed = FALSE, control = list())
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>data: matrix of dimensions <code class="reqn">(mn,p)</code> or array of dimensions <code class="reqn">(p,m,n)</code> with <code class="reqn">m</code> = number of labels/classes, <code class="reqn">n</code> = number of sample units, and <code class="reqn">p</code> = number of variables)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>unit</code></td>
<td>
<p>integer (=number of units) or vector mapping rows of <code>x</code> to sample units (length <code class="reqn">mn</code>). Must be specified only if <code>x</code> is a matrix.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mu</code></td>
<td>
<p>matrix of initial estimates of mean vectors (dimension <code class="reqn">(p,m)</code>)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>V</code></td>
<td>
<p>array of initial estimates of covariance matrices (dimension <code class="reqn">(p,p,m)</code>)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>equal.variance</code></td>
<td>
<p>logical: if <code>TRUE</code>, all covariance matrices are assumed to be equal</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p>method for calculating class probabilities of feature vectors</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fixed</code></td>
<td>
<p>logical; if <code>TRUE</code>, the model parameters <code>mu</code> and <code>V</code> are fixed to their initial values</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>control</code></td>
<td>
<p>list of tuning parameters</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Given a sample of <code class="reqn">n</code> statistical units, each having <code class="reqn">m</code> possibly mislabeled feature vectors, the one-to-one matching problem is to find a set of <code class="reqn">n</code> label permutations that produce the best match of feature vectors across units. This problem is sometimes referred to as "data association ambiguity". 
</p>
<p>The feature vectors of all units are represented as independent realizations of <code class="reqn">m</code> multivariate normal distributions with unknown parameters. For each sample unit, exactly one vector from each distribution is observed and the <code class="reqn">m</code> corresponding labels are randomly permuted. The goal is to estimate the true class of each feature vector, as well as the mean vector and covariance matrix of each distribution. These quantities are evaluated by ML estimation via the Expectation-Maximization (EM) algorithm. 
</p>
<p>If <code>x</code> is a matrix, the rows should be sorted by increasing unit label and  <code>unit</code> should be a nondecreasing sequence of integers, for example <code class="reqn">(1,...,1,2,...,2,...,n,...,n)</code> with each integer <code class="reqn">1,...,n</code> replicated <code class="reqn">m</code> times. 
</p>
<p>The arguments <code>mu</code> and <code>V</code> should be specified only if a good guess is available for these parameters. Otherwise bad starting values may cause the EM algorithm to converge to a local maximum of the likelihood function quite far from the global maximum. 
</p>
<p>If <code>method</code> is set to <code>exact</code> (default), the class probabilities of the feature vectors (given the data) are calculated exactly at each iteration of the EM algorithm. This operation can be slow as it involves calculating the permanent of matrices. The argument <code>method</code> can be set to <code>approximate</code> to speed up calculations, but this option is not recommended in general as the approximations used are very crude and may produce "bad" EM solutions. 
</p>
<p>The optional argument <code>control</code> can be specified with these fields: 
<code>maxit</code>, maximum number of EM iterations (default=1e4); 
<code>eps</code>, relative tolerance for EM convergence (default=1e-8), 
the EM algorithm stops if the relative increase in log-likelihood between two iterations is less than this tolerance; <code>verbose</code>, set to TRUE to display
algorithm progress (default=FALSE). 
</p>


<h3>Value</h3>

<p>A list of class <code>matchFeat</code> with fields
</p>

<dl>
<dt><code>sigma</code></dt>
<dd>
<p>permutations that best match feature vectors across units (<code class="reqn">(m,n)</code> matrix)</p>
</dd>
<dt><code>cluster</code></dt>
<dd>
<p>associated clusters (=inverse permutations)</p>
</dd>
<dt><code>P</code></dt>
<dd>
<p>conditional probability that a feature vector is assigned to its 'true' label
(<code class="reqn">(m,n)</code> matrix)</p>
</dd>
<dt><code>mu</code></dt>
<dd>
<p>MLE of true mean vectors (<code class="reqn">(p,m)</code> matrix)</p>
</dd>
<dt><code>V</code></dt>
<dd>
<p>MLE of true covariance matrices (<code class="reqn">(p,p,m)</code> array or <code class="reqn">(p,p)</code>matrix if <code>equal.variance=TRUE</code>)</p>
</dd>
<dt><code>loglik</code></dt>
<dd>
<p>Maximum value of log-likelihood</p>
</dd>
</dl>
<h3>References</h3>

<p>Degras (2022) "Scalable feature matching across large data collections."  
<a href="https://doi.org/10.1080/10618600.2022.2074429">doi:10.1080/10618600.2022.2074429</a> <br>
'McLachlan and Krishnan (2008). The EM Algorithm and Extensions.'
</p>


<h3>See Also</h3>

<p><code>match.2x</code>,
<code>match.bca</code>, 
<code>match.bca.gen</code>,  
<code>match.kmeans</code>, 
<code>match.rec</code>, 
<code>match.template</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">
data(optdigits)
x &lt;- optdigits$x
label &lt;- optdigits$label
m &lt;- length(unique(label))
n &lt;- length(unique(optdigits$unit))

## Randomly permute labels to make problem harder
for (i in 1:n)
{
	idx &lt;- seq.int((i-1) * m + 1, i * m)
	sigma &lt;- sample.int(m)
	x[idx,] &lt;- x[idx[sigma],]
	label[idx] &lt;- label[idx[sigma]]
}

## Fit Gaussian mixture model
fit &lt;- match.gaussmix(x, unit = n)

## Calculate Rand index
Rand.index(fit$cluster,label)
	
</code></pre>


</div>