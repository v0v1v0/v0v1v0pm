<div class="container">

<table style="width: 100%;"><tr>
<td>slma</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Stable lexical marker analysis</h2>

<h3>Description</h3>

<p>This function conducts a stable lexical marker analysis.
</p>


<h3>Usage</h3>

<pre><code class="language-R">slma(
  x,
  y,
  file_encoding = "UTF-8",
  sig_cutoff = qchisq(0.95, df = 1),
  small_pos = 1e-05,
  keep_intermediate = FALSE,
  verbose = TRUE,
  min_rank = 1,
  max_rank = 5000,
  keeplist = NULL,
  stoplist = NULL,
  ngram_size = NULL,
  max_skip = 0,
  ngram_sep = "_",
  ngram_n_open = 0,
  ngram_open = "[]",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x, y</code></td>
<td>
<p>Character vector or <code>fnames</code> object with filenames for the two
sets of documents.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>file_encoding</code></td>
<td>
<p>Encoding of all the files to read.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sig_cutoff</code></td>
<td>
<p>Numeric value indicating the cutoff value for 'significance
in the stable lexical marker analysis. The default value is <code>qchist(.95, df = 1)</code>,
which is about 3.84.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>small_pos</code></td>
<td>
<p>Alternative (but sometimes inferior) approach to dealing with
zero frequencies, compared to <code>haldane</code>. The argument <code>small_pos</code>
only applies when <code>haldane</code> is set to <code>FALSE</code>.
(See the Details section.)
</p>
<p>If <code>haldane</code> is <code>FALSE</code>, and there is at least one zero frequency
in a contingency table, adding small positive values to the zero frequency
cells is done systematically for all measures calculated for that table,
not just for measures that need this to be done.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>keep_intermediate</code></td>
<td>
<p>Logical. If <code>TRUE</code>, results from intermediate
calculations are kept in the output as the "intermediate" element. This is
necessary if you want to inspect the object with the <code>details()</code> method.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>
<p>Logical. Whether progress should be printed to the console
during analysis.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>min_rank, max_rank</code></td>
<td>
<p>Minimum and maximum frequency rank in the first
corpus (<code>x</code>) of the items to take into consideration as candidate stable
markers. Only tokens or token n-grams with a frequency rank greater than or
equal to <code>min_rank</code> and lower than or equal to <code>max_rank</code> will be included.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>keeplist</code></td>
<td>
<p>List of types that must certainly be included in the list of
candidate markers regardless of their frequency rank and of <code>stoplist</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>stoplist</code></td>
<td>
<p>List of types that must not be included in the list of candidate
markers, although, if a type is included in <code>keeplist</code>, its inclusion in
<code>stoplist</code> is disregarded.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ngram_size</code></td>
<td>
<p>Argument in support of ngrams/skipgrams (see also <code>max_skip</code>).
</p>
<p>If one wants to identify individual tokens, the value of <code>ngram_size</code>
should be <code>NULL</code> or <code>1</code>. If one wants to retrieve
token ngrams/skipgrams, <code>ngram_size</code> should be an integer indicating
the size of the ngrams/skipgrams. E.g. <code>2</code> for bigrams, or <code>3</code> for
trigrams, etc.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>max_skip</code></td>
<td>
<p>Argument in support of skipgrams. This argument is ignored if
<code>ngram_size</code> is <code>NULL</code> or is <code>1</code>.
</p>
<p>If <code>ngram_size</code> is <code>2</code> or higher, and <code>max_skip</code>
is <code>0</code>, then regular ngrams are being retrieved (albeit that they
may contain open slots; see <code>ngram_n_open</code>).
</p>
<p>If <code>ngram_size</code> is <code>2</code> or higher, and <code>max_skip</code>
is <code>1</code> or higher, then skipgrams are being retrieved (which in the
current implementation cannot contain open slots; see <code>ngram_n_open</code>).
</p>
<p>For instance, if <code>ngram_size</code> is <code>3</code> and <code>max_skip</code> is
<code>2</code>, then 2-skip trigrams are being retrieved.
Or if <code>ngram_size</code> is <code>5</code> and <code>max_skip</code> is
<code>3</code>, then 3-skip 5-grams are being retrieved.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ngram_sep</code></td>
<td>
<p>Character vector of length 1 containing the string that is used to
separate/link tokens in the representation of ngrams/skipgrams
in the output of this function.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ngram_n_open</code></td>
<td>
<p>If <code>ngram_size</code> is <code>2</code> or higher, and moreover
<code>ngram_n_open</code> is a number higher than <code>0</code>, then
ngrams with 'open slots' in them are retrieved. These
ngrams with 'open slots' are generalizations of fully lexically specific
ngrams (with the generalization being that one or more of the items
in the ngram are replaced by a notation that stands for 'any arbitrary token').
</p>
<p>For instance, if <code>ngram_size</code> is <code>4</code> and <code>ngram_n_open</code> is
<code>1</code>, and if moreover the input contains a
4-gram <code>"it_is_widely_accepted"</code>, then the output will contain
all modifications of <code>"it_is_widely_accepted"</code> in which one (since
<code>ngram_n_open</code> is <code>1</code>) of the items in this n-gram is
replaced by an open slot. The first and the last item inside
an ngram are never turned into an open slot; only the items in between
are candidates for being turned into open slots. Therefore, in the
example, the output will contain <code>"it_[]_widely_accepted"</code> and
<code>"it_is_[]_accepted"</code>.
</p>
<p>As a second example, if <code>ngram_size</code> is <code>5</code> and
<code>ngram_n_open</code> is <code>2</code>, and if moreover the input contains a
5-gram <code>"it_is_widely_accepted_that"</code>, then the output will contain
<code>"it_[]_[]_accepted_that"</code>, <code>"it_[]_widely_[]_that"</code>, and
<code>"it_is_[]_[]_that"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ngram_open</code></td>
<td>
<p>Character string used to represent open slots in ngrams in the
output of this function.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Additional arguments.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>A stable lexical marker analysis of the <em>A</em>-documents in <code>x</code> versus the <em>B</em>-documents
in <code>y</code> starts from a separate keyword analysis for all possible document couples
<code class="reqn">(a,b)</code>, with <em>a</em> an <em>A</em>-document and <em>b</em> a <em>B</em>-document. If there are <em>n</em>
<em>A</em>-documents and <em>m</em> <em>B</em>-documents, then <code class="reqn">n*m</code> keyword analyses are
conducted. The 'stability' of a linguistic item <em>x</em>, as a marker for the
collection of <em>A</em>-documents (when compared to the <em>B</em>-documents) corresponds
to the frequency and consistency with which <em>x</em> is found to be a keyword for
the <em>A</em>-documents across all aforementioned keyword analyses.
</p>
<p>In any specific keyword analysis, <em>x</em> is considered a keyword for an <em>A</em>-document
if <code>G_signed</code> is positive and moreover <code>p_G</code> is less than <code>sig_cutoff</code>
(see <code>assoc_scores()</code> for more information on the measures). Item <em>x</em> is
considered a keyword for the <em>B</em>-document if <code>G_signed</code> is negative and moreover
<code>p_G</code> is less than <code>sig_cutoff</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>slma</code>, which is a named list with at least the following
elements:
</p>

<ul>
<li>
<p> A <code>scores</code> dataframe with information about the stability of the chosen
lexical items. (See below.)
</p>
</li>
<li>
<p> An <code>intermediate</code> list with a register of intermediate values if
<code>keep_intermediate</code> was <code>TRUE</code>.
</p>
</li>
<li>
<p> Named items registering the values of the arguments with the same name,
namely <code>sig_cutoff</code>, <code>small_pos</code>, <code>x</code>, and <code>y</code>.
</p>
</li>
</ul>
<p>The <code>slma</code> object has <code>as_data_frame()</code> and <code>print</code> methods
as well as an ad-hoc <code>details()</code> method. Note that the <code>print</code>
method simply prints the main dataframe.
</p>


<h4>Contents of the <code>scores</code> element</h4>

<p>The <code>scores</code> element is a dataframe of which the rows are linguistic items
for which a stable lexical marker analysis was conducted and the columns are
different 'stability measures' and related statistics. By default, the
linguistic items are sorted by decreasing 'stability' according to the <code>S_lor</code>
measure.</p>

<table>
<tr>
<td style="text-align: left;">
   Column </td>
<td style="text-align: left;"> Name </td>
<td style="text-align: left;"> Computation </td>
<td style="text-align: left;"> Range of values </td>
</tr>
<tr>
<td style="text-align: left;">
   <code>S_abs</code> </td>
<td style="text-align: left;"> Absolute stability </td>
<td style="text-align: left;"> <code>S_att</code> - <code>S_rep</code> </td>
<td style="text-align: left;"> <code class="reqn">-(n*m)</code> -- <code class="reqn">(n*m)</code> </td>
</tr>
<tr>
<td style="text-align: left;">
   <code>S_nrm</code> </td>
<td style="text-align: left;"> Normalized stability </td>
<td style="text-align: left;"> <code>S_abs</code> / <code class="reqn">n*m</code> </td>
<td style="text-align: left;"> -1 -- 1 </td>
</tr>
<tr>
<td style="text-align: left;">
   <code>S_att</code> </td>
<td style="text-align: left;"> Stability of attraction </td>
<td style="text-align: left;"> Number of <code class="reqn">(a,b)</code> couples in which the linguistic item is a keyword for the <em>A</em>-documents </td>
<td style="text-align: left;"> 0 -- <code class="reqn">n*m</code> </td>
</tr>
<tr>
<td style="text-align: left;">
   <code>S_rep</code> </td>
<td style="text-align: left;"> Stability of repulsion </td>
<td style="text-align: left;"> Number of <code class="reqn">(a,b)</code> couples in which the linguistic item is a keyword for the <em>B</em>-documents </td>
<td style="text-align: left;"> 0 -- <code class="reqn">n*m</code> </td>
</tr>
<tr>
<td style="text-align: left;">
   <code>S_lor</code> </td>
<td style="text-align: left;"> Log of odds ratio stability </td>
<td style="text-align: left;"> Mean of <code>log_OR</code> across all <code class="reqn">(a,b)</code> couples but setting to 0 the value when <code>p_G</code> is larger than <code>sig_cutoff</code> </td>
<td style="text-align: left;">  </td>
</tr>
<tr>
<td style="text-align: left;">
</td>
</tr>
</table>
<p><code>S_lor</code> is then computed as a fraction with as its numerator the sum of all
<code>log_OR</code> values across all <code class="reqn">(a,b)</code> couples for which <code>p_G</code> is lower than
<code>sig_cutoff</code> and as its denominator <code class="reqn">n*m</code>.
For more on <code>log_OR</code>, see the Value section on on <code>assoc_scores()</code>. The final
three columns on the output are meant as a tool in support of the interpretation
of the <code>log_OR</code> column. Considering all <code class="reqn">(a,b)</code> couples for which
<code>p_G</code> is smaller than <code>sig_cutoff</code>, <code>lor_min</code>, <code>lor_max</code> and <code>lor_sd</code>
are their minimum, maximum and standard deviation for each element.
</p>



<h3>Examples</h3>

<pre><code class="language-R">a_corp &lt;- get_fnames(system.file("extdata", "cleveland", package = "mclm"))
b_corp &lt;- get_fnames(system.file("extdata", "roosevelt", package = "mclm"))
slma_ex &lt;- slma(a_corp, b_corp)
</code></pre>


</div>