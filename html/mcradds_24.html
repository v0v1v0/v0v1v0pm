<div class="container">

<table style="width: 100%;"><tr>
<td>getAccuracy</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Summary Method for <code>MCTab</code> Objects</h2>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#experimental"><img src="../help/figures/lifecycle-experimental.svg" alt="[Experimental]"></a>
</p>
<p>Provides a concise summary of the content of <code>MCTab</code> objects. Computes
sensitivity, specificity, positive and negative predictive values and positive
and negative likelihood ratios for a diagnostic test with reference/gold standard.
Computes positive/negative percent agreement, overall percent agreement and Kappa
when the new test is evaluated by comparison to a non-reference standard. Computes
average positive/negative agreement when the both tests are all not the
reference, such as paired reader precision.
</p>


<h3>Usage</h3>

<pre><code class="language-R">getAccuracy(object, ...)

## S4 method for signature 'MCTab'
getAccuracy(
  object,
  ref = c("r", "nr", "bnr"),
  alpha = 0.05,
  r_ci = c("wilson", "wald", "clopper-pearson"),
  nr_ci = c("wilson", "wald", "clopper-pearson"),
  bnr_ci = "bootstrap",
  bootCI = c("perc", "norm", "basic", "stud", "bca"),
  nrep = 1000,
  rng.seed = NULL,
  digits = 4,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>object</code></td>
<td>
<p>(<code>MCTab</code>)<br> input from diagTab function to create 2x2 contingency table.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>other arguments to be passed to DescTools::BinomCI.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ref</code></td>
<td>
<p>(<code>character</code>)<br> reference condition. It is possible to choose one
condition for your require. The <code>r</code> indicates that the comparative test is standard
reference, <code>nr</code> indicates the comparative test is not a standard reference, and
<code>bnr</code> indicates both the new test and comparative test are not references.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alpha</code></td>
<td>
<p>(<code>numeric</code>)<br> type-I-risk, <code class="reqn">\alpha</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>r_ci</code></td>
<td>
<p>(<code>string</code>)<br> string specifying which method to calculate the
confidence interval for a diagnostic test with reference/gold standard. Default
is <code>wilson</code>. Options can be <code>wilson</code>, <code>wald</code> and <code>clopper-pearson</code>, see DescTools::BinomCI.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nr_ci</code></td>
<td>
<p>(<code>string</code>)<br> string specifying which method to calculate the
confidence interval for the comparative test with non-reference standard. Default
is <code>wilson</code>. Options can be <code>wilson</code>, <code>wald</code> and <code>clopper-pearson</code>, see DescTools::BinomCI.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>bnr_ci</code></td>
<td>
<p>(<code>string</code>)<br> string specifying which method to calculate the
confidence interval for both tests are not reference like reader precision. Default
is <code>bootstrap</code>. But when the point estimate of <code>ANA</code> or <code>APA</code> is equal to 0 or 100%,
the method will be changed to <code style="white-space: pre;">⁠transformed wilson⁠</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>bootCI</code></td>
<td>
<p>(<code>string</code>)<br> string specifying the which bootstrap confidence
interval from <code>boot.ci()</code> function in <code>boot</code> package. Default is
<code>perc</code>(bootstrap percentile), options can be <code>norm</code>(normal approximation),
<code>boot</code>(basic bootstrap), <code>stud</code>(studentized bootstrap) and <code>bca</code>(adjusted
bootstrap percentile).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nrep</code></td>
<td>
<p>(<code>integer</code>)<br> number of replicates for bootstrapping, default is 1000.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>rng.seed</code></td>
<td>
<p>(<code>integer</code>)<br> number of the random number generator seed
for bootstrap sampling. If set to NULL currently in the R session used RNG
setting will be used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>digits</code></td>
<td>
<p>(<code>integer</code>)<br> the desired number of digits. Default is 4.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>A data frame contains the qualitative diagnostic accuracy criteria with
three columns for estimated value and confidence interval.
</p>

<ul>
<li>
<p> sens: Sensitivity refers to how often the test is positive when the condition
of interest is present.
</p>
</li>
<li>
<p> spec: Specificity refers to how often the test is negative when the condition
of interest is absent.
</p>
</li>
<li>
<p> ppv: Positive predictive value refers to the percentage of subjects with
a positive test result who have the target condition.
</p>
</li>
<li>
<p> npv: Negative predictive value refers to the percentage of subjects with
a negative test result who do not have the target condition.
</p>
</li>
<li>
<p> plr: Positive likelihood ratio refers to the probability of true positive
rate divided by the false negative rate.
</p>
</li>
<li>
<p> nlr: Negative likelihood ratio refers to the probability of false positive
rate divided by the true negative rate.
</p>
</li>
<li>
<p> ppa: Positive percent agreement, equals to sensitivity when the candidate method
is evaluated by comparison with a comparative method, not reference/gold standard.
</p>
</li>
<li>
<p> npa: Negative percent agreement, equals to specificity when the candidate method
is evaluated by comparison with a comparative method, not reference/gold standard.
</p>
</li>
<li>
<p> opa: Overall percent agreement.
</p>
</li>
<li>
<p> kappa: Cohen's kappa coefficient to measure the level of agreement.
</p>
</li>
<li>
<p> apa: Average positive agreement refers to the positive agreements and can be
regarded as weighted ppa.
</p>
</li>
<li>
<p> ana: Average negative agreement refers to the negative agreements and can be
regarded as weighted npa.
</p>
</li>
</ul>
<h3>Examples</h3>

<pre><code class="language-R"># For qualitative performance
data("qualData")
tb &lt;- qualData %&gt;%
  diagTab(
    formula = ~ CandidateN + ComparativeN,
    levels = c(1, 0)
  )
getAccuracy(tb, ref = "r")
getAccuracy(tb, ref = "nr", nr_ci = "wilson")

# For Between-Reader precision performance
data("PDL1RP")
reader &lt;- PDL1RP$btw_reader
tb2 &lt;- reader %&gt;%
  diagTab(
    formula = Reader ~ Value,
    bysort = "Sample",
    levels = c("Positive", "Negative"),
    rep = TRUE,
    across = "Site"
  )
getAccuracy(tb2, ref = "bnr")
getAccuracy(tb2, ref = "bnr", rng.seed = 12306)
</code></pre>


</div>