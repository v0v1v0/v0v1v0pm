<div class="container">

<table style="width: 100%;"><tr>
<td>sendPrompt</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Send a prompt to a specified language model agent and return the response.</h2>

<h3>Description</h3>

<p>Send a prompt to a specified language model agent and return the response.
</p>


<h3>Usage</h3>

<pre><code class="language-R">sendPrompt(
  agent,
  prompt,
  context = promptContext(type = "simple"),
  return.type = c("text", "object"),
  previous.msgs = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>agent</code></td>
<td>
<p>An object containing the agent's information (e.g., type and model etc.).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>prompt</code></td>
<td>
<p>The prompt text to send to the language model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>context</code></td>
<td>
<p>Optional context to provide alongside the prompt (default is promptContext(type = "simple")).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>return.type</code></td>
<td>
<p>The type of output to return, either the text response ("text") or
the entire response object ("object").</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>previous.msgs</code></td>
<td>
<p>a list of lists for previous prompts and responses.
Useful to add context of the previous messages for the API.
this argument works with openai and generic models, but not with replicate API.
Default: NULL</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Additional arguments to be passed to the LLM API. Such as maximum tokens, ("max_tokens"), to be returned.
Users can also also provide other arguments in openai API-like
arguments documented on [the official documentation](https://platform.openai.com/docs/api-reference/chat/create). Other APIs are also following similar argument naming patterns.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>The text response or the entire response object, based on the specified return type.
</p>


<h3>See Also</h3>

<p><code>promptContext</code> for predefined contexts to use.
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Not run: 
agent &lt;- setupAgent(name="openai",type="chat",model="gpt-4",
                    ai_api_key=Sys.getenv("OPENAI_API_KEY"))
prompt &lt;- "tell me a joke"
response &lt;- sendPrompt(agent, prompt,context="")

# increase tokens, it is important for getting longer responses
response &lt;- sendPrompt(agent,prompt,context="",return.type="text", max_tokens = 500)

# get previous messages into the context
prompt="what about 2010?"
response &lt;- sendPrompt(agent,prompt,context="",
                       return.type="text",
                       previous.msgs=list(
                                          list(
                                               "role" = "user",
                                                "content" = "Who won the world
                                                 series in 2020?"
                                                 ),
                                          list(
                                                "role" = "assistant",
                                              "content" = "The Los Angeles Dodgers"
                                              )
                                          )
                       )



## End(Not run)
</code></pre>


</div>