<div class="container">

<table style="width: 100%;"><tr>
<td>transf</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Transformation Functions</h2>

<h3>Description</h3>

<p>Functions to carry out various types of transformations that are useful for meta-analyses. <script id="MathJax-script" async src="../../mathjaxr/doc/mathjax/es5/tex-chtml-full.js"></script></p>


<h3>Usage</h3>

<pre><code class="language-R">transf.rtoz(xi)
transf.ztor(xi)
transf.logit(xi)
transf.ilogit(xi)
transf.arcsin(xi)
transf.iarcsin(xi)
transf.pft(xi, ni)
transf.ipft(xi, ni)
transf.ipft.hm(xi, targs)
transf.isqrt(xi)
transf.irft(xi, ti)
transf.iirft(xi, ti)
transf.ahw(xi)
transf.iahw(xi)
transf.abt(xi)
transf.iabt(xi)
transf.r2toz(xi)
transf.ztor2(xi)
transf.ztor.int(xi, targs)
transf.exp.int(xi, targs)
transf.ilogit.int(xi, targs)
transf.dtou1(xi)
transf.dtou2(xi)
transf.dtou3(xi)
transf.dtobesd(xi)
transf.dtomd(xi, targs)
transf.dtorpb(xi, n1i, n2i)
transf.dtorbis(xi, n1i, n2i)
transf.rpbtorbis(xi, pi)
transf.rtorpb(xi, pi)
transf.rtod(xi, n1i, n2i)
transf.rpbtod(xi, n1i, n2i)
transf.lnortord(xi, pc)
transf.lnortorr(xi, pc)
transf.lnortod.norm(xi)
transf.lnortod.logis(xi)
transf.dtolnor.norm(xi)
transf.dtolnor.logis(xi)
transf.lnortortet.pearson(xi)
transf.lnortortet.digby(xi)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>xi</code></td>
<td>
<p>vector of values to be transformed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ni</code></td>
<td>
<p>vector of sample sizes.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n1i</code></td>
<td>
<p>vector of sample sizes for the first group.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n2i</code></td>
<td>
<p>vector of sample sizes for the second group.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ti</code></td>
<td>
<p>vector of person-times at risk.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pc</code></td>
<td>
<p>control group risk (either a single value or a vector).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pi</code></td>
<td>
<p>proportion of individuals falling into the first of the two groups that is created by the dichotomization.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>targs</code></td>
<td>
<p>list with additional arguments for the transformation function. See ‘Details’.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The following transformation functions are currently implemented:
</p>

<ul>
<li> <p><code>transf.rtoz</code>: Fisher's r-to-z transformation for correlation coefficients (same as <code>atanh(x)</code>).
</p>
</li>
<li> <p><code>transf.ztor</code>: inverse of the former (i.e., the z-to-r transformation; same as <code>tanh(x)</code>).
</p>
</li>
<li> <p><code>transf.logit</code>: logit (log odds) transformation for proportions (same as <code>qlogis(x)</code>).
</p>
</li>
<li> <p><code>transf.ilogit</code>: inverse of the former (same as <code>plogis(x)</code>).
</p>
</li>
<li> <p><code>transf.arcsin</code>: arcsine square root transformation for proportions.
</p>
</li>
<li> <p><code>transf.iarcsin</code>: inverse of the former.
</p>
</li>
<li> <p><code>transf.pft</code>: Freeman-Tukey (double arcsine) transformation for proportions. See Freeman &amp; Tukey (1950). The <code>xi</code> argument is used to specify the proportions and the <code>ni</code> argument the corresponding sample sizes.
</p>
</li>
<li> <p><code>transf.ipft</code>: inverse of the former. See Miller (1978).
</p>
</li>
<li> <p><code>transf.ipft.hm</code>: inverse of the former, using the harmonic mean of the sample sizes for the back-transformation. See Miller (1978). The sample sizes are specified via the <code>targs</code> argument (the list element should be called <code>ni</code>).
</p>
</li>
<li> <p><code>transf.isqrt</code>: inverse of the square root transformation (i.e., function to square a number).
</p>
</li>
<li> <p><code>transf.irft</code>: Freeman-Tukey transformation for incidence rates. See Freeman &amp; Tukey (1950). The <code>xi</code> argument is used to specify the incidence rates and the <code>ti</code> argument the corresponding person-times at risk.
</p>
</li>
<li> <p><code>transf.iirft</code>: inverse of the former.
</p>
</li>
<li> <p><code>transf.ahw</code>: transformation of coefficient alpha as suggested by Hakstian &amp; Whalen (1976), except that \(1-(1-\alpha)^{1/3}\) is used (so that the transformed values are a monotonically increasing function of the \(\alpha\) values).
</p>
</li>
<li> <p><code>transf.iahw</code>: inverse of the former.
</p>
</li>
<li> <p><code>transf.abt</code>: transformation of coefficient alpha as suggested by Bonett (2002), except that \(-\log(1-\alpha)\) is used (so that the transformed values are a monotonically increasing function of the \(\alpha\) values).
</p>
</li>
<li> <p><code>transf.iabt</code>: inverse of the former.
</p>
</li>
<li> <p><code>transf.r2toz</code>: variance stabilizing transformation for the coefficient of determination, given by \(z_i = \frac{1}{2} \log\mathopen{}\left(\frac{1+\sqrt{R_i^2}}{1-\sqrt{R_i^2}}\right)\mathclose{}\) (see Olkin &amp; Finn, 1995, but with the additional \(\frac{1}{2}\) factor).
</p>
</li>
<li> <p><code>transf.ztor2</code>: inverse of the former.
</p>
</li>
<li> <p><code>transf.ztor.int</code>: integral transformation method for the z-to-r transformation.
</p>
</li>
<li> <p><code>transf.exp.int</code>: integral transformation method for the exponential transformation.
</p>
</li>
<li> <p><code>transf.ilogit.int</code>: integral transformation method for the inverse logit transformation.
</p>
</li>
<li> <p><code>transf.dtou1</code>: transformation of standardized mean differences to Cohen's \(U_1\) values (Cohen, 1988). Under the assumption that the data for those in the first (say, treated) and second (say, control) group are normally distributed with equal variances but potentially different means, Cohen's \(U_1\) indicates the proportion of non-overlap between the two distributions (i.e., when \(d=0\), then \(U_1\) is equal to 0, which goes to 1 as \(d\) increases).
</p>
</li>
<li> <p><code>transf.dtou2</code>: transformation of standardized mean differences to Cohen's \(U_2\) values (Cohen, 1988). Under the same assumptions as above, Cohen's \(U_2\) indicates the proportion in the first group that exceeds the same proportion in the second group (i.e., when \(d=0\), then \(U_2\) is equal to 0.5, which goes to 1 as \(d\) increases).
</p>
</li>
<li> <p><code>transf.dtou3</code>: transformation of standardized mean differences to Cohen's \(U_3\) values (Cohen, 1988). Under the same assumptions as above, Cohen's \(U_3\) indicates the proportion of individuals in the first group that have a higher value than the mean of those in the second group (i.e., when \(d=0\), then \(U_3\) is equal to 0.5, which goes to 1 as \(d\) increases).
</p>
</li>
<li> <p><code>transf.dtocles</code>: transformation of standardized mean differences to common language effect size (CLES) values (McGraw &amp; Wong, 1992) (also called the probability of superiority). A CLES value indicates the probability that a randomly sampled individual from the first group has a higher value than a randomly sampled individual from the second group (i.e., when \(d=0\), then the CLES is equal to 0.5, which goes to 1 as \(d\) increases).
</p>
</li>
<li> <p><code>transf.dtobesd</code>: transformation of standardized mean differences to binomial effect size display values (Rosenthal &amp; Rubin, 1982). Note that the function only provides the proportion in the first group scoring above the median (the proportion in the second group scoring above the median is simply one minus this value).
</p>
</li>
<li> <p><code>transf.dtomd</code>: transformation of standardized mean differences to mean differences given a known standard deviation (which needs to be specified via the <code>targs</code> argument).
</p>
</li>
<li> <p><code>transf.dtorpb</code>: transformation of standardized mean differences to point-biserial correlations. Arguments <code>n1i</code> and <code>n2i</code> denote the number of individuals in the first and second group, respectively. If <code>n1i</code> and <code>n2i</code> are not specified, the function assumes <code>n1i = n2i</code> and uses the approximate formula \(r_{pb} = \frac{d}{\sqrt{d^2 + 4}}\). If <code>n1i</code> and <code>n2i</code> are specified, the function uses the exact transformation formula \(r_{pb} = \frac{d}{\sqrt{d^2 + h}}\), where \(h = \frac{m}{n_1} + \frac{m}{n_2}\) and \(m = n_1 + n_2 - 2\) (Jacobs &amp; Viechtbauer, 2017).
</p>
</li>
<li> <p><code>transf.dtorbis</code>: transformation of standardized mean differences to biserial correlations. Like <code>transf.dtorpb</code>, but the point-biserial correlations are then transformed to biserial correlations with \(r_{bis} = \frac{\sqrt{p(1-p)}}{f(z_p)} r_{pb}\), where \(p = \frac{n_1}{n_1+n_2}\) and \(f(z_p)\) denotes the density of the standard normal distribution at value \(z_p\), which is the point for which \(P(Z &gt; z_p) = p\), with \(Z\) denoting a random variable following a standard normal distribution (Jacobs &amp; Viechtbauer, 2017).
</p>
</li>
<li> <p><code>transf.rpbtorbis</code>: transformation of point-biserial correlations to biserial correlations. Argument <code>pi</code> denotes the proportion of individuals falling into the first of the two groups that is created by the dichotomization (hence, <code>1-pi</code> falls into the second group). If <code>pi</code> is not specified, the function assumes <code>pi=0.5</code>, which corresponds to dichotomization at the median. The transformation is carried out as described for <code>transf.dtorbis</code>.
</p>
</li>
<li> <p><code>transf.rtorpb</code>: transformation of Pearson product-moment correlations to the corresponding point-biserial correlations, when one of the two variables is dichotomized. Argument <code>pi</code> can be used to denote the proportion of individuals falling into the first of the two groups that is created by the dichotomization (hence, <code>1-pi</code> falls into the second group). If <code>pi</code> is not specified, the function assumes <code>pi=0.5</code>, which corresponds to dichotomization at the median. This function is simply the inverse of <code>transf.rpbtorbis</code>.
</p>
</li>
<li> <p><code>transf.rtod</code>: transformation of Pearson product-moment correlations to the corresponding standardized mean differences, when one of the two variables is dichotomized. Arguments <code>n1i</code> and <code>n2i</code> can be used to denote the number of individuals in the first and second group created by the dichotomization. If <code>n1i</code> and <code>n2i</code> are not specified, the function assumes <code>n1i = n2i</code>. This function is simply the inverse of <code>transf.dtorbis</code>.
</p>
</li>
<li> <p><code>transf.rpbtod</code>: transformation of point-biserial correlations to standardized mean differences. This is simply the inverse of <code>transf.dtorpb</code>.
</p>
</li>
<li> <p><code>transf.lnortord</code>: transformation of log odds ratios to risk differences, assuming a particular value for the control group risk (which needs to be specified via the <code>pc</code> argument).
</p>
</li>
<li> <p><code>transf.lnortorr</code>: transformation of log odds ratios to risk ratios, assuming a particular value for the control group risk (which needs to be specified via the <code>pc</code> argument).
</p>
</li>
<li> <p><code>transf.lnortod.norm</code>: transformation of log odds ratios to standardized mean differences (assuming normal distributions) (Cox &amp; Snell, 1989).
</p>
</li>
<li> <p><code>transf.lnortod.logis</code>: transformation of log odds ratios to standardized mean differences (assuming logistic distributions) (Chinn, 2000).
</p>
</li>
<li> <p><code>transf.dtolnor.norm</code>: transformation of standardized mean differences to log odds ratios (assuming normal distributions) (Cox &amp; Snell, 1989).
</p>
</li>
<li> <p><code>transf.dtolnor.logis</code>: transformation of standardized mean differences to log odds ratios (assuming logistic distributions) (Chinn, 2000).
</p>
</li>
<li> <p><code>transf.lnortortet.pearson</code>: transformation of log odds ratios to tetrachoric correlations as suggested by Pearson (1900).
</p>
</li>
<li> <p><code>transf.lnortortet.digby</code>: transformation of log odds ratios to tetrachoric correlations as suggested by Digby (1983).
</p>
</li>
</ul>
<h3>Value</h3>

<p>A vector with the transformed values.
</p>


<h3>Note</h3>

<p>The integral transformation method for a transformation function \(h(z)\) is given by \[\int_{\textrm{lower}}^{\textrm{upper}} h(z) f(z) dz\] using the limits <code>targs$lower</code> and <code>targs$upper</code>, where \(f(z)\) is the density of a normal distribution with mean equal to <code>xi</code> and variance equal to <code>targs$tau2</code>. An example is provided below.
</p>


<h3>Author(s)</h3>

<p>Wolfgang Viechtbauer <a href="mailto:wvb@metafor-project.org">wvb@metafor-project.org</a> <a href="https://www.metafor-project.org">https://www.metafor-project.org</a>
</p>


<h3>References</h3>

<p>Bonett, D. G. (2002). Sample size requirements for testing and estimating coefficient alpha. <em>Journal of Educational and Behavioral Statistics</em>, <b>27</b>(4), 335–340. <code style="white-space: pre;">⁠https://doi.org/10.3102/10769986027004335⁠</code>
</p>
<p>Chinn, S. (2000). A simple method for converting an odds ratio to effect size for use in meta-analysis. <em>Statistics in Medicine</em>, <b>19</b>(22), 3127–3131. <code style="white-space: pre;">⁠https://doi.org/10.1002/1097-0258(20001130)19:22&lt;3127::aid-sim784&gt;3.0.co;2-m⁠</code>
</p>
<p>Cohen, J. (1988). <em>Statistical power analysis for the behavioral sciences</em> (2nd ed.). Hillsdale, NJ: Lawrence Erlbaum Associates.
</p>
<p>Cox, D. R., &amp; Snell, E. J. (1989). <em>Analysis of binary data</em> (2nd ed.). London: Chapman &amp; Hall.
</p>
<p>Digby, P. G. N. (1983). Approximating the tetrachoric correlation coefficient. <em>Biometrics</em>, <b>39</b>(3), 753–757. <code style="white-space: pre;">⁠https://doi.org/10.2307/2531104⁠</code>
</p>
<p>Fisher, R. A. (1921). On the “probable error” of a coefficient of correlation deduced from a small sample. <em>Metron</em>, <b>1</b>, 1–32. <code style="white-space: pre;">⁠http://hdl.handle.net/2440/15169⁠</code>
</p>
<p>Freeman, M. F., &amp; Tukey, J. W. (1950). Transformations related to the angular and the square root. <em>Annals of Mathematical Statistics</em>, <b>21</b>(4), 607–611. <code style="white-space: pre;">⁠https://doi.org/10.1214/aoms/1177729756⁠</code>
</p>
<p>Hakstian, A. R., &amp; Whalen, T. E. (1976). A k-sample significance test for independent alpha coefficients. <em>Psychometrika</em>, <b>41</b>(2), 219–231. <code style="white-space: pre;">⁠https://doi.org/10.1007/BF02291840⁠</code>
</p>
<p>Jacobs, P., &amp; Viechtbauer, W. (2017). Estimation of the biserial correlation and its sampling variance for use in meta-analysis. <em>Research Synthesis Methods</em>, <b>8</b>(2), 161–180. <code style="white-space: pre;">⁠https://doi.org/10.1002/jrsm.1218⁠</code>
</p>
<p>McGraw, K. O., &amp; Wong, S. P. (1992). A common language effect size statistic. <em>Psychological Bulletin</em>, <b>111</b>(2), 361–365. <code style="white-space: pre;">⁠https://doi.org/10.1037/0033-2909.111.2.361⁠</code>
</p>
<p>Miller, J. J. (1978). The inverse of the Freeman-Tukey double arcsine transformation. <em>American Statistician</em>, <b>32</b>(4), 138. <code style="white-space: pre;">⁠https://doi.org/10.1080/00031305.1978.10479283⁠</code>
</p>
<p>Olkin, I., &amp; Finn, J. D. (1995). Correlations redux. <em>Psychological Bulletin</em>, <b>118</b>(1), 155–164. <code style="white-space: pre;">⁠https://doi.org/10.1037/0033-2909.118.1.155⁠</code>
</p>
<p>Pearson, K. (1900). Mathematical contributions to the theory of evolution. VII. On the correlation of characters not quantitatively measurable. <em>Philosophical Transactions of the Royal Society of London, Series A</em>, <b>195</b>, 1–47. <code style="white-space: pre;">⁠https://doi.org/10.1098/rsta.1900.0022⁠</code>
</p>
<p>Rosenthal, R., &amp; Rubin, D. B. (1982). A simple, general purpose display of magnitude of experimental effect. <em>Journal of Educational Psychology</em>, <b>74</b>(2), 166–169. <code style="white-space: pre;">⁠https://doi.org/10.1037/0022-0663.74.2.166⁠</code>
</p>
<p>Viechtbauer, W. (2010). Conducting meta-analyses in R with the metafor package. <em>Journal of Statistical Software</em>, <b>36</b>(3), 1–48. <code style="white-space: pre;">⁠https://doi.org/10.18637/jss.v036.i03⁠</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">### calculate log risk ratios and corresponding sampling variances
dat &lt;- escalc(measure="RR", ai=tpos, bi=tneg, ci=cpos, di=cneg, data=dat.bcg)

### fit random-effects model
res &lt;- rma(yi, vi, data=dat)

### average risk ratio with 95% CI (but technically, this provides an
### estimate of the median risk ratio, not the mean risk ratio!)
predict(res, transf=exp)

### average risk ratio with 95% CI using the integral transformation
predict(res, transf=transf.exp.int, targs=list(tau2=res$tau2, lower=-4, upper=4))

### this also works
predict(res, transf=transf.exp.int, targs=list(tau2=res$tau2))

### this as well
predict(res, transf=transf.exp.int, targs=res$tau2)
</code></pre>


</div>