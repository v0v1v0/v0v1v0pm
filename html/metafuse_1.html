<div class="container">

<table style="width: 100%;"><tr>
<td>metafuse-package</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Fused Lasso Approach in Regression Coefficient Clustering</h2>

<h3>Description</h3>

<p>Fused lasso method to cluster and estimate regression coefficients
of the same covariate across different data sets when a large number of
independent data sets are combined. Package supports Gaussian, binomial,
Poisson and Cox PH models.</p>


<h3>Details</h3>

<p>Simple to use. Accepts <code>X</code>, <code>y</code>, and <code>sid</code> (numerica data source ID for which data entry belongs to) for regression models. Returns regression coefficient estimates and clusterings patterns of coefficients across different datasets, for each covariate. Provides visualization by fusogram, a dendrogram-type of presentation of coefficient clustering pattern across data sources.

</p>


<h3>Author(s)</h3>

<p>Lu Tang, Ling Zhou, Peter X.K. Song <br>
Maintainer: Lu Tang &lt;lutang@umich.edu&gt;
</p>


<h3>References</h3>

<p>Lu Tang, and Peter X.K. Song. Fused Lasso Approach in Regression Coefficients Clustering - Learning Parameter Heterogeneity in Data Integration. <em>Journal of Machine Learning Research</em>, 17(113):1-23, 2016.<br></p>
<p>Fei Wang, Lu Wang, and Peter X.K. Song. Fused lasso with the adaptation of parameter ordering in combining multiple studies with repeated measurements.  <em>Biometrics</em>, DOI:10.1111/biom.12496, 2016. <br></p>


<h3>Examples</h3>

<pre><code class="language-R">########### generate data ###########
n &lt;- 200    # sample size in each dataset (can also be a K-element vector)
K &lt;- 10     # number of datasets for data integration
p &lt;- 3      # number of covariates in X (including the intercept)

# the coefficient matrix of dimension K * p, used to specify the heterogeneous pattern
beta0 &lt;- matrix(c(0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,   # beta_0 of intercept
                  0.0,0.0,0.0,0.0,0.0,1.0,1.0,1.0,1.0,1.0,   # beta_1 of X_1
                  0.0,0.0,0.0,0.0,0.5,0.5,0.5,1.0,1.0,1.0),  # beta_2 of X_2
                K, p)

# generate a data set, family=c("gaussian", "binomial", "poisson", "cox")
data &lt;- datagenerator(n=n, beta0=beta0, family="gaussian", seed=123)

# prepare the input for metafuse
y       &lt;- data$y
sid     &lt;- data$group
X       &lt;- data[,-c(1,ncol(data))]

########### run metafuse ###########
# fuse slopes of X1 (which is heterogeneous with 2 clusters)
metafuse(X=X, y=y, sid=sid, fuse.which=c(1), family="gaussian", intercept=TRUE, alpha=0,
          criterion="EBIC", verbose=TRUE, plots=TRUE, loglambda=TRUE)

# fuse slopes of X2 (which is heterogeneous with 3 clusters)
metafuse(X=X, y=y, sid=sid, fuse.which=c(2), family="gaussian", intercept=TRUE, alpha=0,
          criterion="EBIC", verbose=TRUE, plots=TRUE, loglambda=TRUE)

# fuse all three covariates
metafuse(X=X, y=y, sid=sid, fuse.which=c(0,1,2), family="gaussian", intercept=TRUE, alpha=0,
          criterion="EBIC", verbose=TRUE, plots=TRUE, loglambda=TRUE)

# fuse all three covariates, with sparsity penalty
metafuse(X=X, y=y, sid=sid, fuse.which=c(0,1,2), family="gaussian", intercept=TRUE, alpha=1,
          criterion="EBIC", verbose=TRUE, plots=TRUE, loglambda=TRUE)

# fit metafuse at a given lambda
metafuse.l(X=X, y=y, sid=sid, fuse.which=c(0,1,2), family="gaussian", intercept=TRUE,
          alpha=1, lambda=0.5)
</code></pre>


</div>