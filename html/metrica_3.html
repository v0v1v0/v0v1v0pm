<div class="container">

<table style="width: 100%;"><tr>
<td>accuracy</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Accuracy</h2>

<h3>Description</h3>

<p>It estimates the accuracy for a nominal/categorical predicted-observed
dataset.
</p>


<h3>Usage</h3>

<pre><code class="language-R">accuracy(data = NULL, obs, pred, tidy = FALSE, na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>(Optional) argument to call an existing data frame containing the data.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>obs</code></td>
<td>
<p>Vector with observed values (character | factor).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pred</code></td>
<td>
<p>Vector with predicted values (character | factor).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tidy</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide the type of return. TRUE returns a data.frame, FALSE returns a list (default).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values (NA).
Default is na.rm = TRUE.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Accuracy is the simplest and most popular classification metric in literature.
It refers to a measure of the degree to which the predictions of a model matches the
reality being modeled. The classification accuracy is calculated as the ratio between
the number of correctly classified objects with respect to the total number of cases.
</p>
<p>It is bounded between 0 and 1. The closer to 1 the better. Values towards zero
indicate low accuracy of predictions. It can be also expressed as percentage if
multiplied by 100. It is estimated at a global level (not at the class level).
</p>
<p>Accuracy presents limitations to address classification quality under unbalanced classes,
and it is not able to distinguish among misclassification distributions. For those cases,
it is advised to apply other metrics such as balanced accuracy (baccu), F-score (fscore),
Matthews Correlation Coefficient (mcc), or Cohen's Kappa Coefficient (cohen_kappa).
</p>
<p>Accuracy is directly related to the error_rate, since accuracy = 1 – error_rate.
</p>
<p>For the formula and more details, see
<a href="https://adriancorrendo.github.io/metrica/articles/available_metrics_classification.html">online-documentation</a>
</p>


<h3>Value</h3>

<p>an object of class <code>numeric</code> within a <code>list</code> (if tidy = FALSE) or within a
<code style="white-space: pre;">⁠data frame⁠</code> (if tidy = TRUE).
</p>


<h3>References</h3>

<p>Sammut &amp; Webb (2017).
Accuracy.
<em>In: Sammut C., Webb G.I. (eds) Encyclopedia of Machine Learning and Data Mining.</em>
<em>Springer, Boston, MA.</em> <a href="https://doi.org/10.1007/978-1-4899-7687-1_3">doi:10.1007/978-1-4899-7687-1_3</a>
</p>


<h3>See Also</h3>

<p><code>balacc</code> <code>fscore</code> <code>mcc</code> <code>khat</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">
set.seed(123)
# Two-class
binomial_case &lt;- data.frame(labels = sample(c("True","False"), 100, 
replace = TRUE), predictions = sample(c("True","False"), 100, replace = TRUE))
# Multi-class
multinomial_case &lt;- data.frame(labels = sample(c("Red","Blue", "Green"), 100, 
replace = TRUE), predictions = sample(c("Red","Blue", "Green"), 100, replace = TRUE) )

# Get accuracy estimate for two-class case
accuracy(data = binomial_case, obs = labels, pred = predictions, tidy = TRUE)

# Get accuracy estimate for multi-class case
accuracy(data = multinomial_case, obs = labels, pred = predictions, tidy = TRUE)

</code></pre>


</div>