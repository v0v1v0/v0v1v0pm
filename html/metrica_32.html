<div class="container">

<table style="width: 100%;"><tr>
<td>gmean</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Geometric Mean</h2>

<h3>Description</h3>

<p>It estimates the Geometric Mean score for a nominal/categorical
predicted-observed dataset.
</p>


<h3>Usage</h3>

<pre><code class="language-R">gmean(
  data = NULL,
  obs,
  pred,
  pos_level = 2,
  atom = FALSE,
  tidy = FALSE,
  na.rm = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>(Optional) argument to call an existing data frame containing the data.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>obs</code></td>
<td>
<p>Vector with observed values (character | factor).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pred</code></td>
<td>
<p>Vector with predicted values (character | factor).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pos_level</code></td>
<td>
<p>Integer, for binary cases, indicating the order (1|2) of the level
corresponding to the positive. Generally, the positive level is the second (2)
since following an alpha-numeric order, the most common pairs are
<code>(Negative | Positive)</code>, <code>(0 | 1)</code>, <code>(FALSE | TRUE)</code>. Default : 2.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>atom</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide if the estimate is made for
each class (atom = TRUE) or at a global level (atom = FALSE); Default : FALSE.
When dataset is "binomial" atom does not apply.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tidy</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide the type of return. TRUE
returns a data.frame, FALSE returns a list; Default : FALSE.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values
(NA). Default is na.rm = TRUE.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The gmean is a metric especially useful for imbalanced classes because it
measures the balance between the classification performance on both major (over-represented)
as well as on minor (under-represented) classes. As stated above, it is particularly
useful when the number of observations belonging to each class is uneven.
</p>
<p>The gmean score is equivalent to the square-root of the product of specificity
and recall (a.k.a. sensitivity).
</p>
<p><code class="reqn">gmean = \sqrt{recall * specificity} </code>
</p>
<p>It is bounded between 0 and 1. The closer to 1 the better the classification performance,
while zero represents the worst.
</p>
<p>For the formula and more details, see
<a href="https://adriancorrendo.github.io/metrica/articles/available_metrics_classification.html">online-documentation</a>
</p>


<h3>Value</h3>

<p>an object of class <code>numeric</code> within a <code>list</code> (if tidy = FALSE) or within a
<code style="white-space: pre;">⁠data frame⁠</code> (if tidy = TRUE).
</p>


<h3>References</h3>

<p>De Diego, I.M., Redondo, A.R., Fernández, R.R., Navarro, J., Moguerza, J.M. (2022).
General Performance Score for classification problems.
_ Appl. Intell. (2022)._ <a href="https://doi.org/10.1007/s10489-021-03041-7">doi:10.1007/s10489-021-03041-7</a>
</p>


<h3>Examples</h3>

<pre><code class="language-R">
set.seed(123)
# Two-class
binomial_case &lt;- data.frame(labels = sample(c("True","False"), 100, replace = TRUE), 
predictions = sample(c("True","False"), 100, replace = TRUE))
# Get gmean estimate for two-class case
gmean(data = binomial_case, obs = labels, pred = predictions)


</code></pre>


</div>