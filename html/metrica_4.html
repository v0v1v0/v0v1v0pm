<div class="container">

<table style="width: 100%;"><tr>
<td>agf</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Adjusted F-score</h2>

<h3>Description</h3>

<p>It estimates the Adjusted F-score for a nominal/categorical
predicted-observed dataset.
</p>


<h3>Usage</h3>

<pre><code class="language-R">agf(
  data = NULL,
  obs,
  pred,
  pos_level = 2,
  atom = FALSE,
  tidy = FALSE,
  na.rm = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>(Optional) argument to call an existing data frame containing the data.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>obs</code></td>
<td>
<p>Vector with observed values (character | factor).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pred</code></td>
<td>
<p>Vector with predicted values (character | factor).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pos_level</code></td>
<td>
<p>Integer, for binary cases, indicating the order (1|2) of the level
corresponding to the positive. Generally, the positive level is the second (2)
since following an alpha-numeric order, the most common pairs are
<code>(Negative | Positive)</code>, <code>(0 | 1)</code>, <code>(FALSE | TRUE)</code>. Default : 2.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>atom</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide if the estimate is made for
each class (atom = TRUE) or at a global level (atom = FALSE); Default : FALSE.
When dataset is "binomial" atom does not apply.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tidy</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide the type of return. TRUE
returns a data.frame, FALSE returns a list; Default : FALSE.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values
(NA). Default is na.rm = TRUE.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The Adjusted F-score (or Adjusted F-measure) is an improvement over the
F1-score especially when the data classes are imbalanced. This metric more properly
accounts for the different misclassification costs across classes. It weights more
the sensitivity (recall) metric than precision and gives strength to the false negative
values. This index accounts for all elements of the original confusion matrix and
provides more weight to patterns correctly classified in the minority class (positive).
</p>
<p>It is bounded between 0 and 1.
The closer to 1 the better. Values towards zero indicate low performance.
For the formula and more details, see
<a href="https://adriancorrendo.github.io/metrica/articles/available_metrics_classification.html">online-documentation</a>
</p>


<h3>Value</h3>

<p>an object of class <code>numeric</code> within a <code>list</code> (if tidy = FALSE) or within a
<code style="white-space: pre;">⁠data frame⁠</code> (if tidy = TRUE).
</p>


<h3>References</h3>

<p>Maratea, A., Petrosino, A., Manzo, M. (2014).
Adjusted-F measure and kernel scaling for imbalanced data learning.
<em>Inf. Sci. 257: 331-341.</em> <a href="https://doi.org/10.1016/j.ins.2013.04.016">doi:10.1016/j.ins.2013.04.016</a>
</p>


<h3>Examples</h3>

<pre><code class="language-R">
set.seed(123)
# Two-class
binomial_case &lt;- data.frame(labels = sample(c("True","False"), 100, replace = TRUE), 
predictions = sample(c("True","False"), 100, replace = TRUE))
# Multi-class
multinomial_case &lt;- data.frame(labels = sample(c("Red","Blue", "Green"), 100, replace = TRUE),
predictions = sample(c("Red","Blue", "Green"), 100, replace = TRUE)    )

# Get F-score estimate for two-class case
agf(data = binomial_case, obs = labels, pred = predictions, tidy = TRUE)

# Get F-score estimate for each class for the multi-class case
agf(data = multinomial_case, obs = labels, pred = predictions, tidy = TRUE)

# Get F-score estimate for the multi-class case at a global level
agf(data = multinomial_case, obs = labels, pred = predictions, tidy = TRUE)

</code></pre>


</div>