<div class="container">

<table style="width: 100%;"><tr>
<td>AUC_roc</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Area Under the ROC Curve</h2>

<h3>Description</h3>

<p>The AUC estimates the area under the receiver operator
curve (ROC) for a nominal/categorical predicted-observed dataset using the
Mann-Whitney U-statistic.
</p>


<h3>Usage</h3>

<pre><code class="language-R">AUC_roc(data = NULL, obs, pred, tidy = FALSE, na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>(Optional) argument to call an existing data frame containing the data.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>obs</code></td>
<td>
<p>Vector with observed values (character | factor).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pred</code></td>
<td>
<p>Vector with predicted values (character | factor).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tidy</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide the type of return.
TRUE returns a data.frame, FALSE returns a list (default).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values (NA).
Default is na.rm = TRUE.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The AUC tests whether positives are ranked higher than negatives. It is
simply the area under the ROC curve.
</p>
<p>The AUC estimation of this function follows the procedure described by
Hand &amp; Till (2001). The AUC_roc estimated following the trapezoid approach is
equivalent to the average between recall and specificity (Powers, 2011), which is
equivalent to the balanced accuracy (<code>balacc</code>):
</p>
<p><code class="reqn">AUC_roc = \frac{(recall - FPR + 1)}{2} = \frac{recall+specificity}{2} = 1-\frac{FPR+FNR}{2}</code>
</p>
<p>Interpretation: the AUC is equivalent to the probability that a randomly case
from a given class (positive for binary) will have a smaller estimated probability
of belonging to another class (negative for binary) compared to a randomly
chosen member of the another class.
</p>
<p>Values: the AUC is bounded between 0 and 1. The closer to 1 the better.
Values close to 0 indicate inaccurate predictions. An AUC = 0.5 suggests no
discrimination ability between classes; 0.7 &lt; AUC &lt; 0.8 is considered acceptable,
0.8 &lt; AUC &lt; 0.5 is considered excellent, and AUC &gt; 0.9 is outstanding
(Mandrekar, 2010).
</p>
<p>For the multiclass cases, the AUC is equivalent to the average of AUC of each class
(Hand &amp; Till, 2001).
</p>
<p>Finally, the AUC is directly related to the Gini-index (a.k.a. G1) since Gini + 1 = 2*AUC.
(Hand &amp; Till, 2001).
</p>
<p>For the formula and more details, see
<a href="https://adriancorrendo.github.io/metrica/articles/available_metrics_classification.html">online-documentation</a>
</p>


<h3>Value</h3>

<p>an object of class <code>numeric</code> within a <code>list</code> (if tidy = FALSE) or within a
<code style="white-space: pre;">⁠data frame⁠</code> (if tidy = TRUE).
</p>


<h3>References</h3>

<p>Hanley, J.A., McNeil, J.A. (2017).
The meaning and use of the area under a receiver operating characteristic (ROC) curve.
_ Radiology 143(1): 29-36_ <a href="https://doi.org/10.1148/radiology.143.1.7063747">doi:10.1148/radiology.143.1.7063747</a>
</p>
<p>Hand, D.J., Till, R.J. (2001).
A simple generalisation of the area under the ROC curve for multiple class
classification problems.
_ Machine Learning 45: 171-186_ <a href="https://doi.org/10.1023/A%3A1010920819831">doi:10.1023/A:1010920819831</a>
</p>
<p>Mandrekar, J.N. (2010).
Receiver operating characteristic curve in diagnostic test assessment.
_ J. Thoracic Oncology 5(9): 1315-1316_ <a href="https://doi.org/10.1097/JTO.0b013e3181ec173d">doi:10.1097/JTO.0b013e3181ec173d</a>
</p>
<p>Powers, D.M.W. (2011).
Evaluation: From Precision, Recall and F-Measure to ROC, Informedness, Markedness &amp; Correlation.
<em>Journal of Machine Learning Technologies 2(1): 37–63.</em> <a href="https://doi.org/10.48550/arXiv.2010.16061">doi:10.48550/arXiv.2010.16061</a>
</p>


<h3>Examples</h3>

<pre><code class="language-R">
set.seed(123)
# Two-class
binomial_case &lt;- data.frame(labels = sample(c("True","False"), 100, 
replace = TRUE), predictions = sample(c("True","False"), 100, replace = TRUE))
# Multi-class
multinomial_case &lt;- data.frame(labels = sample(c("Red","Blue", "Green"), 100, 
replace = TRUE), predictions = sample(c("Red","Blue", "Green"), 100, replace = TRUE) )

# Get AUC estimate for two-class case
AUC_roc(data = binomial_case, obs = labels, pred = predictions, tidy = TRUE)

# Get AUC estimate for multi-class case
AUC_roc(data = multinomial_case, obs = labels, pred = predictions, tidy = TRUE)

</code></pre>


</div>