<div class="container">

<table style="width: 100%;"><tr>
<td>p4</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>P4-metric</h2>

<h3>Description</h3>

<p>It estimates the P4-metric for a nominal/categorical predicted-observed dataset.
</p>


<h3>Usage</h3>

<pre><code class="language-R">p4(
  data = NULL,
  obs,
  pred,
  pos_level = 2,
  tidy = FALSE,
  na.rm = TRUE,
  atom = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>(Optional) argument to call an existing data frame containing the data.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>obs</code></td>
<td>
<p>Vector with observed values (character | factor).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pred</code></td>
<td>
<p>Vector with predicted values (character | factor).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pos_level</code></td>
<td>
<p>Integer, for binary cases, indicating the order (1|2) of the level
corresponding to the positive. Generally, the positive level is the second (2)
since following an alpha-numeric order, the most common pairs are
<code>(Negative | Positive)</code>, <code>(0 | 1)</code>, <code>(FALSE | TRUE)</code>. Default : 2.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tidy</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide the type of return. TRUE
returns a data.frame, FALSE returns a list; Default : FALSE.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values
(NA). Default is na.rm = TRUE.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>atom</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide if the estimate is made for
each class (atom = TRUE) or at a global level (atom = FALSE); Default : FALSE.
When dataset is "binomial" atom does not apply.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The P4-metric it is a metric designed for binary classifiers. It is estimated from
precision, recall, specificity, and npv (negative predictive value).
The P4 it was designed to address criticism against the F-score, so it may be perceived as
its extension. Unfortunately, it has not been generalized yet for multinomial cases.
</p>
<p>For binomial/binary cases,
</p>
<p><code class="reqn">p4  =  \frac{(4 x TP x TN)} {(4 x TP x TN + (TP + TN) x FP + FN)} </code>
</p>
<p>Or:
</p>
<p><code class="reqn">p4 = \frac{4} {\frac{1}{precision} + \frac{1}{recall} + \frac{1}{specificity} + \frac{1}{npv} } </code>
</p>
<p>The P4 metric has not been generalized for multinomial cases.
The P4 metric is bounded between 0 and 1.
The closer to 1 the better, which will require precision, recall, specificity and npv being close to 1.
Values towards zero indicate low performance, which could be the product of only one of the four conditional probabilities being close to 0.
</p>
<p>For the formula and more details, see
<a href="https://adriancorrendo.github.io/metrica/articles/available_metrics_classification.html">online-documentation</a>
</p>


<h3>Value</h3>

<p>an object of class <code>numeric</code> within a <code>list</code> (if tidy = FALSE) or within a
<code style="white-space: pre;">⁠data frame⁠</code> (if tidy = TRUE).
</p>


<h3>References</h3>

<p>Sitarz, M. (2023).
Extending F1 metric, probabilistic approach.
_Adv. Artif. Intell. Mach. Learn., 3 (2):1025-1038._<a href="https://doi.org/10.54364/AAIML.2023.1161">doi:10.54364/AAIML.2023.1161</a>
</p>


<h3>Examples</h3>

<pre><code class="language-R">
set.seed(123)
# Two-class
binomial_case &lt;- data.frame(labels = sample(c("True","False"), 100, replace = TRUE), 
predictions = sample(c("True","False"), 100, replace = TRUE))
# Multi-class
multinomial_case &lt;- data.frame(labels = sample(c("Red","Blue", "Green"), 100, replace = TRUE),
predictions = sample(c("Red","Blue", "Green"), 100, replace = TRUE)    )

# Get P4-metric estimate for two-class case
p4(data = binomial_case, obs = labels, pred = predictions, tidy = TRUE)


</code></pre>


</div>