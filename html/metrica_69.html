<div class="container">

<table style="width: 100%;"><tr>
<td>precision</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Precision | Positive Predictive Value</h2>

<h3>Description</h3>

<p><code>precision</code> estimates the precision (a.k.a. positive predictive
value -ppv-) for a nominal/categorical predicted-observed dataset.
</p>
<p><code>ppv</code> estimates the Positive Predictive Value (equivalent
to precision) for a nominal/categorical predicted-observed dataset.
</p>
<p><code>FDR</code> estimates the complement of precision (a.k.a. positive predictive
value -PPV-) for a nominal/categorical predicted-observed dataset.
</p>


<h3>Usage</h3>

<pre><code class="language-R">precision(
  data = NULL,
  obs,
  pred,
  tidy = FALSE,
  atom = FALSE,
  na.rm = TRUE,
  pos_level = 2
)

ppv(
  data = NULL,
  obs,
  pred,
  tidy = FALSE,
  atom = FALSE,
  na.rm = TRUE,
  pos_level = 2
)

FDR(
  data = NULL,
  obs,
  pred,
  atom = FALSE,
  pos_level = 2,
  tidy = FALSE,
  na.rm = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>(Optional) argument to call an existing data frame containing the data.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>obs</code></td>
<td>
<p>Vector with observed values (character | factor).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pred</code></td>
<td>
<p>Vector with predicted values (character | factor).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tidy</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide the type of return. TRUE
returns a data.frame, FALSE returns a list; Default : FALSE.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>atom</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide if the estimate is made for
each class (atom = TRUE) or at a global level (atom = FALSE); Default : FALSE.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values
(NA). Default is na.rm = TRUE.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pos_level</code></td>
<td>
<p>Integer, for binary cases, indicating the order (1|2) of the level
corresponding to the positive. Generally, the positive level is the second (2)
since following an alpha-numeric order, the most common pairs are
<code>(Negative | Positive)</code>, <code>(0 | 1)</code>, <code>(FALSE | TRUE)</code>. Default : 2.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The precision is a non-normalized coefficient that represents the
ratio between the correctly predicted cases (or true positive -TP- for binary cases)
to the total predicted observations for a given class (or total predicted positive
-PP- for binary cases) or at overall level.
</p>
<p>For binomial cases, <code class="reqn">precision = \frac{TP}{PP} = \frac{TP}{TP + FP} </code>
</p>
<p>The <code>precision</code> metric is bounded between 0 and 1. The closer to 1 the better.
Values towards zero indicate low precision of predictions. It can be estimated
for each particular class or at a global level.
</p>
<p>The false detection rate or false discovery rate (FDR) represents the proportion
of false positives with respect to the total number of cases predicted as positive.
</p>
<p>For binomial cases, <code class="reqn">FDR = 1 - precision = \frac{FP}{PP} = \frac{FP}{TP + FP} </code>
</p>
<p>The <code>precision</code> metric is bounded between 0 and 1. The closer to 1 the better.
Values towards zero indicate low precision of predictions.
</p>
<p>For the formula and more details, see
<a href="https://adriancorrendo.github.io/metrica/articles/available_metrics_classification.html">online-documentation</a>
</p>


<h3>Value</h3>

<p>an object of class <code>numeric</code> within a <code>list</code> (if tidy = FALSE) or within a
<code style="white-space: pre;">⁠data frame⁠</code> (if tidy = TRUE).
</p>


<h3>References</h3>

<p>Ting K.M. (2017)
Precision and Recall.
<em>In: Sammut C., Webb G.I. (eds) Encyclopedia of Machine Learning and Data Mining.</em>
<em>Springer, Boston, MA.</em> <a href="https://doi.org/10.1007/978-1-4899-7687-1_659">doi:10.1007/978-1-4899-7687-1_659</a>
</p>


<h3>Examples</h3>

<pre><code class="language-R">
set.seed(123)
# Two-class
binomial_case &lt;- data.frame(labels = sample(c("True","False"), 100, 
replace = TRUE), predictions = sample(c("True","False"), 100, replace = TRUE))
# Multi-class
multinomial_case &lt;- data.frame(labels = sample(c("Red","Blue", "Green"), 100, 
replace = TRUE), predictions = sample(c("Red","Blue", "Green"), 100, replace = TRUE))

# Get precision estimate for two-class case
precision(data = binomial_case, obs = labels, pred = predictions, tidy = TRUE)

# Get FDR estimate for two-class case
FDR(data = binomial_case, obs = labels, pred = predictions, tidy = TRUE)

# Get precision estimate for each class for the multi-class case
precision(data = multinomial_case, obs = labels, pred = predictions, tidy = TRUE, atom = TRUE)

# Get precision estimate for the multi-class case at a global level
precision(data = multinomial_case, obs = labels, pred = predictions, tidy = TRUE, atom = TRUE)

</code></pre>


</div>