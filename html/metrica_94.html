<div class="container">

<table style="width: 100%;"><tr>
<td>specificity</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Specificity  | Selectivity | True Negative Rate</h2>

<h3>Description</h3>

<p><code>specificity</code> estimates the specificity (a.k.a. selectivity,
or true negative rate -TNR-)
for a nominal/categorical predicted-observed dataset.
</p>
<p><code>selectivity</code> alternative to <code>specificity()</code>.
</p>
<p><code>TNR</code> alternative to <code>specificity()</code>.
</p>
<p><code>FPR</code> estimates the false positive rate (a.k.a fall-out or false alarm)
for a nominal/categorical predicted-observed dataset.
</p>


<h3>Usage</h3>

<pre><code class="language-R">specificity(
  data = NULL,
  obs,
  pred,
  atom = FALSE,
  pos_level = 2,
  tidy = FALSE,
  na.rm = TRUE
)

selectivity(
  data = NULL,
  obs,
  pred,
  atom = FALSE,
  pos_level = 2,
  tidy = FALSE,
  na.rm = TRUE
)

TNR(
  data = NULL,
  obs,
  pred,
  atom = FALSE,
  pos_level = 2,
  tidy = FALSE,
  na.rm = TRUE
)

FPR(
  data = NULL,
  obs,
  pred,
  atom = FALSE,
  pos_level = 2,
  tidy = FALSE,
  na.rm = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>(Optional) argument to call an existing data frame containing the data.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>obs</code></td>
<td>
<p>Vector with observed values (character | factor).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pred</code></td>
<td>
<p>Vector with predicted values (character | factor).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>atom</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide if the estimate is made for
each class (atom = TRUE) or at a global level (atom = FALSE); Default : FALSE.
When dataset is "binomial" atom does not apply.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pos_level</code></td>
<td>
<p>Integer, for binary cases, indicating the order (1|2) of the level
corresponding to the positive. Generally, the positive level is the second (2)
since following an alpha-numeric order, the most common pairs are
<code>(Negative | Positive)</code>, <code>(0 | 1)</code>, <code>(FALSE | TRUE)</code>. Default : 2.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tidy</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide the type of return. TRUE
returns a data.frame, FALSE returns a list; Default : FALSE.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values
(NA). Default is na.rm = TRUE.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The specificity (or selectivity, or true negative rate-TNR-) is a non-normalized
coefficient that represents the ratio between the correctly negative predicted
cases (or true negative -TN- for binary cases) to the total number of actual
observations not belonging to a given class (actual negatives -N- for binary cases).
</p>
<p>For binomial cases, <code class="reqn">specificity  =  \frac{TN}{N} = \frac{TN}{TN+FP}</code>
</p>
<p>The <code>specificity</code> metric is bounded between 0 and 1. The closer to 1 the better.
Values towards zero indicate low performance. For multinomial cases, it can be
either estimated for each particular class or at a global level.
</p>
<p>Metrica offers 3 identical alternative functions that do the same job: i) <code>specificity</code>,
ii) <code>selectivity</code>, and iii) <code>TNR</code>. However, consider
when using <code>metrics_summary</code>, only the <code>specificity</code> alternative is used.
</p>
<p>The false positive rate (or false alarm, or fall-out) is the complement of the
specificity, representing the ratio between the number of false positives (FP)
to the actual number of negatives (N). The <code>FPR</code> formula is:
</p>
<p><code class="reqn">FPR = 1 - specificity = 1 - TNR = \frac{FP}{N}</code>
</p>
<p>The <code>FPR</code> is bounded between 0 and 1. The closer to 0 the better. Low performance
is indicated with FPR &gt; 0.5.
</p>
<p>For the formula and more details, see
<a href="https://adriancorrendo.github.io/metrica/articles/available_metrics_classification.html">online-documentation</a>
</p>


<h3>Value</h3>

<p>an object of class <code>numeric</code> within a <code>list</code> (if tidy = FALSE) or within a
<code style="white-space: pre;">⁠data frame⁠</code> (if tidy = TRUE).
</p>


<h3>References</h3>

<p>Ting K.M. (2017)
Sensitivity and Specificity.
<em>In: Sammut C., Webb G.I. (eds) Encyclopedia of Machine Learning and Data Mining.</em>
<em>Springer, Boston, MA.</em> <a href="https://doi.org/10.1007/978-0-387-30164-8_752">doi:10.1007/978-0-387-30164-8_752</a>
</p>
<p>Trevethan, R. (2017).
<em>Sensitivity, Specificity, and Predictive Values: Foundations, Pliabilities, and Pitfalls</em>
_ in Research and Practice. Front. Public Health 5:307_ <a href="https://doi.org/10.3389/fpubh.2017.00307">doi:10.3389/fpubh.2017.00307</a>
</p>


<h3>Examples</h3>

<pre><code class="language-R">
set.seed(123)
# Two-class
binomial_case &lt;- data.frame(labels = sample(c("True","False"), 100, 
replace = TRUE), predictions = sample(c("True","False"), 100, replace = TRUE))
# Multi-class
multinomial_case &lt;- data.frame(labels = sample(c("Red","Blue", "Green"), 100, 
replace = TRUE), predictions = sample(c("Red","Blue", "Green"), 100, replace = TRUE)    )

# Get specificity and FPR estimates for two-class case
specificity(data = binomial_case, obs = labels, pred = predictions, tidy = TRUE)
FPR(data = binomial_case, obs = labels, pred = predictions, tidy = TRUE)

# Get specificity estimate for each class for the multi-class case
specificity(data = multinomial_case, obs = labels, pred = predictions, tidy = TRUE)

# Get specificity estimate for the multi-class case at a global level
specificity(data = multinomial_case, obs = labels, pred = predictions, tidy = TRUE)

</code></pre>


</div>