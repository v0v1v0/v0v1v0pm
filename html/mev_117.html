<div class="container">

<table style="width: 100%;"><tr>
<td>gpd</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Generalized Pareto distribution</h2>

<h3>Description</h3>

<p>Likelihood, score function and information matrix, bias,
approximate ancillary statistics and sample space derivative
for the generalized Pareto distribution
</p>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>par</code></td>
<td>
<p>vector of <code>scale</code> and <code>shape</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>dat</code></td>
<td>
<p>sample vector</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tol</code></td>
<td>
<p>numerical tolerance for the exponential model</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p>string indicating whether to use the expected  (<code>'exp'</code>) or the observed (<code>'obs'</code> - the default) information matrix.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>V</code></td>
<td>
<p>vector calculated by <code>gpd.Vfun</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n</code></td>
<td>
<p>sample size</p>
</td>
</tr>
</table>
<h3>Usage</h3>

<pre>gpd.ll(par, dat, tol=1e-5)
gpd.ll.optim(par, dat, tol=1e-5)
gpd.score(par, dat)
gpd.infomat(par, dat, method = c('obs','exp'))
gpd.bias(par, n)
gpd.Fscore(par, dat, method = c('obs','exp'))
gpd.Vfun(par, dat)
gpd.phi(par, dat, V)
gpd.dphi(par, dat, V)</pre>


<h3>Functions</h3>


<ul>
<li> <p><code>gpd.ll</code>: log likelihood
</p>
</li>
<li> <p><code>gpd.ll.optim</code>: negative log likelihood parametrized in terms of <code>log(scale)</code> and shape
in order to perform unconstrained optimization
</p>
</li>
<li> <p><code>gpd.score</code>: score vector
</p>
</li>
<li> <p><code>gpd.infomat</code>: observed or expected information matrix
</p>
</li>
<li> <p><code>gpd.bias</code>: Cox-Snell first order bias
</p>
</li>
<li> <p><code>gpd.Fscore</code>: Firth's modified score equation
</p>
</li>
<li> <p><code>gpd.Vfun</code>: vector implementing conditioning on approximate ancillary statistics for the TEM
</p>
</li>
<li> <p><code>gpd.phi</code>: canonical parameter in the local exponential family approximation
</p>
</li>
<li> <p><code>gpd.dphi</code>: derivative matrix of the canonical parameter in the local
exponential family approximation
</p>
</li>
</ul>
<h3>Author(s)</h3>

<p>Leo Belzile
</p>


<h3>References</h3>

<p>Firth, D. (1993). Bias reduction of maximum likelihood estimates, <em>Biometrika</em>, <strong>80</strong>(1), 27–38.
</p>
<p>Coles, S. (2001). <em>An Introduction to Statistical Modeling of Extreme Values</em>, Springer, 209 p.
</p>
<p>Cox, D. R. and E. J. Snell (1968). A general definition of residuals, <em>Journal of the Royal Statistical Society: Series B (Methodological)</em>, <strong>30</strong>, 248–275.
</p>
<p>Cordeiro, G. M. and R. Klein (1994). Bias correction in ARMA models, <em>Statistics and Probability Letters</em>, <strong>19</strong>(3), 169–176.
</p>
<p>Giles, D. E., Feng, H. and R. T. Godwin (2016).  Bias-corrected maximum likelihood estimation of the  parameters of the generalized Pareto distribution, <em>Communications in Statistics - Theory and Methods</em>, <strong>45</strong>(8), 2465–2483.
</p>


</div>