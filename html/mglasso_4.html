<div class="container">

<table style="width: 100%;"><tr>
<td>conesta</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>CONESTA solver.</h2>

<h3>Description</h3>

<p>Solve the MGLasso optimization problem using CONESTA algorithm. Interface to
the pylearn.parsimony python library.
</p>


<h3>Usage</h3>

<pre><code class="language-R">conesta(
  X,
  lam1,
  lam2,
  beta_warm = c(0),
  type_ = "initial",
  W_ = NULL,
  mean_ = FALSE,
  max_iter_ = 10000,
  prec_ = 0.01
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>Data matrix nxp.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lam1</code></td>
<td>
<p>Sparsity penalty.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lam2</code></td>
<td>
<p>Total variation penalty.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>beta_warm</code></td>
<td>
<p>Warm initialization vector.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>type_</code></td>
<td>
<p>Character scalar. By default set to initial version which doesn't
use weights</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>W_</code></td>
<td>
<p>Weights matrix for total variation penalties.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mean_</code></td>
<td>
<p>Logical scalar. If TRUE weights the optimization function by the
inverse of sample size.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>max_iter_</code></td>
<td>
<p>Numeric scalar. Maximum number of iterations.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>prec_</code></td>
<td>
<p>Numeric scalar. Tolerance for the stopping criterion (duality gap).</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p><em>COntinuation with NEsterov smoothing in a Shrinkage-Thresholding
Algorithm</em> (CONESTA, Hadj-Selem et al. 2018) <a href="doi:10.1109/TMI.2018.2829802">doi:10.1109/TMI.2018.2829802</a>
is an algorithm design for solving optimization problems including group-wise
penalties. This function is an interface with the python solver. The MGLasso
problem is first reformulated in a problem of the form </p>
<p style="text-align: center;"><code class="reqn">argmin 1/2 ||Y -
\tilde{X} \tilde{\beta}||_2^2 + \lambda_1 ||\tilde{\beta}||_1 + \lambda_2
\sum_{i&lt;j} ||\boldsymbol A_{ij} \tilde{\beta}||_2</code>
</p>
<p> where vector <code class="reqn">Y</code> is
the vectorized form of matrix <code class="reqn">X</code>.
</p>


<h3>Value</h3>

<p>Numeric matrix of size pxp. Line <code>k</code> of the matrix represents
the coefficients obtained from the L1-L2 penalized regression of variable
<code>k</code> on the others.
</p>


<h3>See Also</h3>

<p><code>mglasso()</code> for the MGLasso model estimation.
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Not run: # because of installation of external packages during checks
mglasso::install_pylearn_parsimony(envname = "rmglasso", method = "conda")
reticulate::use_condaenv("rmglasso", required = TRUE)
reticulate::py_config()
n = 30
K = 2
p = 4
rho = 0.85
blocs &lt;- list()
for (j in 1:K) {
 bloc &lt;- matrix(rho, nrow = p/K, ncol = p/K)
   for(i in 1:(p/K)) { bloc[i,i] &lt;- 1 }
   blocs[[j]] &lt;- bloc
   }

mat.covariance &lt;- Matrix::bdiag(blocs)
mat.covariance
set.seed(11)
X &lt;- mvtnorm::rmvnorm(n, mean = rep(0,p), sigma = as.matrix(mat.covariance))
X &lt;- scale(X)
res &lt;- conesta(X, 0.1, 0.1)

## End(Not run)
</code></pre>


</div>