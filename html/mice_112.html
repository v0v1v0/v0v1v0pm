<div class="container">

<table style="width: 100%;"><tr>
<td>mice.impute.midastouch</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Imputation by predictive mean matching with distance aided donor selection</h2>

<h3>Description</h3>

<p>Imputes univariate missing data using predictive mean matching.
</p>


<h3>Usage</h3>

<pre><code class="language-R">mice.impute.midastouch(
  y,
  ry,
  x,
  wy = NULL,
  ridge = 1e-05,
  midas.kappa = NULL,
  outout = TRUE,
  neff = NULL,
  debug = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>Vector to be imputed</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ry</code></td>
<td>
<p>Logical vector of length <code>length(y)</code> indicating the
the subset <code>y[ry]</code> of elements in <code>y</code> to which the imputation
model is fitted. The <code>ry</code> generally distinguishes the observed
(<code>TRUE</code>) and missing values (<code>FALSE</code>) in <code>y</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>Numeric design matrix with <code>length(y)</code> rows with predictors for
<code>y</code>. Matrix <code>x</code> may have no missing values.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>wy</code></td>
<td>
<p>Logical vector of length <code>length(y)</code>. A <code>TRUE</code> value
indicates locations in <code>y</code> for which imputations are created.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ridge</code></td>
<td>
<p>The ridge penalty used in <code>.norm.draw()</code> to prevent
problems with multicollinearity. The default is <code>ridge = 1e-05</code>,
which means that 0.01 percent of the diagonal is added to the cross-product.
Larger ridges may result in more biased estimates. For highly noisy data
(e.g. many junk variables), set <code>ridge = 1e-06</code> or even lower to
reduce bias. For highly collinear data, set <code>ridge = 1e-04</code> or higher.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>midas.kappa</code></td>
<td>
<p>Scalar. If <code>NULL</code> (default) then the
optimal <code>kappa</code> gets selected automatically. Alternatively, the user
may specify a scalar. Siddique and Belin 2008 find <code>midas.kappa = 3</code>
to be sensible.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>outout</code></td>
<td>
<p>Logical. If <code>TRUE</code> (default) one model is estimated
for each donor (leave-one-out principle). For speedup choose
<code>outout = FALSE</code>, which estimates one model for all observations
leading to in-sample predictions for the donors and out-of-sample
predictions for the recipients. Mind the inappropriateness, though.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>neff</code></td>
<td>
<p>FOR EXPERTS. Null or character string. The name of an existing
environment in which the effective sample size of the donors for each
loop (CE iterations times multiple imputations) is supposed to be written.
The effective sample size is necessary to compute the correction for the
total variance as originally suggested by Parzen, Lipsitz and
Fitzmaurice 2005. The objectname is <code>midastouch.neff</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>debug</code></td>
<td>
<p>FOR EXPERTS. Null or character string. The name of an existing
environment in which the input is supposed to be written. The objectname
is <code>midastouch.inputlist</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Other named arguments.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Imputation of <code>y</code> by predictive mean matching, based on
Rubin (1987, p. 168, formulas a and b) and Siddique and Belin 2008.
The procedure is as follows:
</p>

<ol>
<li>
<p> Draw a bootstrap sample from the donor pool.
</p>
</li>
<li>
<p> Estimate a beta matrix on the bootstrap sample by the leave one out principle.
</p>
</li>
<li>
<p> Compute type II predicted values for <code>yobs</code> (nobs x 1) and <code>ymis</code> (nmis x nobs).
</p>
</li>
<li>
<p> Calculate the distance between all <code>yobs</code> and the corresponding <code>ymis</code>.
</p>
</li>
<li>
<p> Convert the distances in drawing probabilities.
</p>
</li>
<li>
<p> For each recipient draw a donor from the entire pool while considering the probabilities from the model.
</p>
</li>
<li>
<p> Take its observed value in <code>y</code> as the imputation.
</p>
</li>
</ol>
<h3>Value</h3>

<p>Vector with imputed data, same type as <code>y</code>, and of
length <code>sum(wy)</code>
</p>


<h3>Author(s)</h3>

<p>Philipp Gaffert, Florian Meinfelder, Volker Bosch 2015
</p>


<h3>References</h3>

<p>Gaffert, P., Meinfelder, F., Bosch V. (2015) Towards an MI-proper
Predictive Mean Matching, Discussion Paper.
<a href="https://www.uni-bamberg.de/fileadmin/uni/fakultaeten/sowi_lehrstuehle/statistik/Personen/Dateien_Florian/properPMM.pdf">https://www.uni-bamberg.de/fileadmin/uni/fakultaeten/sowi_lehrstuehle/statistik/Personen/Dateien_Florian/properPMM.pdf</a>
</p>
<p>Little, R.J.A. (1988), Missing data adjustments in large
surveys (with discussion), Journal of Business Economics and
Statistics, 6, 287–301.
</p>
<p>Parzen, M., Lipsitz, S. R., Fitzmaurice, G. M. (2005), A note on reducing
the bias of the approximate Bayesian bootstrap imputation variance estimator.
Biometrika <b>92</b>, 4, 971–974.
</p>
<p>Rubin, D.B. (1987), Multiple imputation for nonresponse in surveys. New York: Wiley.
</p>
<p>Siddique, J., Belin, T.R. (2008), Multiple imputation using an iterative
hot-deck with distance-based donor selection. Statistics in medicine,
<b>27</b>, 1, 83–102
</p>
<p>Van Buuren, S., Brand, J.P.L., Groothuis-Oudshoorn C.G.M., Rubin, D.B. (2006),
Fully conditional specification in multivariate imputation.
<em>Journal of Statistical Computation and Simulation</em>, <b>76</b>, 12,
1049–1064.
</p>
<p>Van Buuren, S., Groothuis-Oudshoorn, K. (2011), <code>mice</code>: Multivariate
Imputation by Chained Equations in <code>R</code>. <em>Journal of
Statistical Software</em>, <b>45</b>, 3, 1–67. <a href="https://doi.org/10.18637/jss.v045.i03">doi:10.18637/jss.v045.i03</a>
</p>


<h3>See Also</h3>

<p>Other univariate imputation functions: 
<code>mice.impute.cart()</code>,
<code>mice.impute.lasso.logreg()</code>,
<code>mice.impute.lasso.norm()</code>,
<code>mice.impute.lasso.select.logreg()</code>,
<code>mice.impute.lasso.select.norm()</code>,
<code>mice.impute.lda()</code>,
<code>mice.impute.logreg.boot()</code>,
<code>mice.impute.logreg()</code>,
<code>mice.impute.mean()</code>,
<code>mice.impute.mnar.logreg()</code>,
<code>mice.impute.mpmm()</code>,
<code>mice.impute.norm.boot()</code>,
<code>mice.impute.norm.nob()</code>,
<code>mice.impute.norm.predict()</code>,
<code>mice.impute.norm()</code>,
<code>mice.impute.pmm()</code>,
<code>mice.impute.polr()</code>,
<code>mice.impute.polyreg()</code>,
<code>mice.impute.quadratic()</code>,
<code>mice.impute.rf()</code>,
<code>mice.impute.ri()</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R"># do default multiple imputation on a numeric matrix
imp &lt;- mice(nhanes, method = "midastouch")
imp

# list the actual imputations for BMI
imp$imp$bmi

# first completed data matrix
complete(imp)

# imputation on mixed data with a different method per column
mice(nhanes2, method = c("sample", "midastouch", "logreg", "norm"))
</code></pre>


</div>