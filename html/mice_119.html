<div class="container">

<table style="width: 100%;"><tr>
<td>mice.impute.norm.predict</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Imputation by linear regression through prediction</h2>

<h3>Description</h3>

<p>Imputes the "best value" according to the linear regression model, also
known as <em>regression imputation</em>.
</p>


<h3>Usage</h3>

<pre><code class="language-R">mice.impute.norm.predict(y, ry, x, wy = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>Vector to be imputed</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ry</code></td>
<td>
<p>Logical vector of length <code>length(y)</code> indicating the
the subset <code>y[ry]</code> of elements in <code>y</code> to which the imputation
model is fitted. The <code>ry</code> generally distinguishes the observed
(<code>TRUE</code>) and missing values (<code>FALSE</code>) in <code>y</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>Numeric design matrix with <code>length(y)</code> rows with predictors for
<code>y</code>. Matrix <code>x</code> may have no missing values.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>wy</code></td>
<td>
<p>Logical vector of length <code>length(y)</code>. A <code>TRUE</code> value
indicates locations in <code>y</code> for which imputations are created.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Other named arguments.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Calculates regression weights from the observed data and returns predicted
values to as imputations. This
method is known as <em>regression imputation</em>.
</p>


<h3>Value</h3>

<p>Vector with imputed data, same type as <code>y</code>, and of length
<code>sum(wy)</code>
</p>


<h3>Warning</h3>

<p>THIS METHOD SHOULD NOT BE USED FOR DATA ANALYSIS.
This method is seductive because it imputes the most
likely value according to the model. However, it ignores the uncertainty
of the missing values and artificially
amplifies the relations between the columns of the data. Application of
richer models having more parameters does not help to evade these issues.
Stochastic regression methods, like <code>mice.impute.pmm</code> or
<code>mice.impute.norm</code>, are generally preferred.
</p>
<p>At best, prediction can give reasonable estimates of the mean, especially
if normality assumptions are plausible. See Little and Rubin (2002, p. 62-64)
or Van Buuren (2012, p. 11-13, p. 45-46) for a discussion of this method.
</p>


<h3>Author(s)</h3>

<p>Gerko Vink, Stef van Buuren, 2018
</p>


<h3>References</h3>

<p>Little, R.J.A. and Rubin, D.B. (2002). Statistical Analysis with Missing
Data.  New York: John Wiley and Sons.
</p>
<p>Van Buuren, S. (2018).
<a href="https://stefvanbuuren.name/fimd/sec-linearnormal.html"><em>Flexible Imputation of Missing Data. Second Edition.</em></a>
Chapman &amp; Hall/CRC. Boca Raton, FL.
</p>


<h3>See Also</h3>

<p>Other univariate imputation functions: 
<code>mice.impute.cart()</code>,
<code>mice.impute.lasso.logreg()</code>,
<code>mice.impute.lasso.norm()</code>,
<code>mice.impute.lasso.select.logreg()</code>,
<code>mice.impute.lasso.select.norm()</code>,
<code>mice.impute.lda()</code>,
<code>mice.impute.logreg.boot()</code>,
<code>mice.impute.logreg()</code>,
<code>mice.impute.mean()</code>,
<code>mice.impute.midastouch()</code>,
<code>mice.impute.mnar.logreg()</code>,
<code>mice.impute.mpmm()</code>,
<code>mice.impute.norm.boot()</code>,
<code>mice.impute.norm.nob()</code>,
<code>mice.impute.norm()</code>,
<code>mice.impute.pmm()</code>,
<code>mice.impute.polr()</code>,
<code>mice.impute.polyreg()</code>,
<code>mice.impute.quadratic()</code>,
<code>mice.impute.rf()</code>,
<code>mice.impute.ri()</code>
</p>


</div>