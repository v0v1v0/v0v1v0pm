<div class="container">

<table style="width: 100%;"><tr>
<td>mice.impute.lasso.logreg</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Imputation by direct use of lasso logistic regression</h2>

<h3>Description</h3>

<p>Imputes univariate missing binary data using lasso logistic regression with bootstrap.
</p>


<h3>Usage</h3>

<pre><code class="language-R">mice.impute.lasso.logreg(y, ry, x, wy = NULL, nfolds = 10, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>Vector to be imputed</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ry</code></td>
<td>
<p>Logical vector of length <code>length(y)</code> indicating the
the subset <code>y[ry]</code> of elements in <code>y</code> to which the imputation
model is fitted. The <code>ry</code> generally distinguishes the observed
(<code>TRUE</code>) and missing values (<code>FALSE</code>) in <code>y</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>Numeric design matrix with <code>length(y)</code> rows with predictors for
<code>y</code>. Matrix <code>x</code> may have no missing values.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>wy</code></td>
<td>
<p>Logical vector of length <code>length(y)</code>. A <code>TRUE</code> value
indicates locations in <code>y</code> for which imputations are created.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nfolds</code></td>
<td>
<p>The number of folds for the cross-validation of the lasso penalty.
The default is 10.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Other named arguments.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The method consists of the following steps:
</p>

<ol>
<li>
<p> For a given y variable under imputation, draw a bootstrap version y*
with replacement from the observed cases <code>y[ry]</code>, and stores in x* the
corresponding values from <code>x[ry, ]</code>.
</p>
</li>
<li>
<p> Fit a regularised (lasso) logistic regression with y* as the outcome,
and x* as predictors.
A vector of regression coefficients bhat is obtained.
All of these coefficients are considered random draws from the imputation model
parameters posterior distribution.
Same of these coefficients will be shrunken to 0.
</p>
</li>
<li>
<p> Compute predicted scores for m.d., i.e. logit-1(X bhat)
</p>
</li>
<li>
<p> Compare the score to a random (0,1) deviate, and impute.
</p>
</li>
</ol>
<p>The method is based on the Direct Use of Regularized Regression (DURR) proposed by
Zhao &amp; Long (2016) and Deng et al (2016).
</p>


<h3>Value</h3>

<p>Vector with imputed data, same type as <code>y</code>, and of length
<code>sum(wy)</code>
</p>


<h3>Author(s)</h3>

<p>Edoardo Costantini, 2021
</p>


<h3>References</h3>

<p>Deng, Y., Chang, C., Ido, M. S., &amp; Long, Q. (2016). Multiple imputation for
general missing data patterns in the presence of high-dimensional data.
Scientific reports, 6(1), 1-10.
</p>
<p>Zhao, Y., &amp; Long, Q. (2016). Multiple imputation in the presence of
high-dimensional data. Statistical Methods in Medical Research, 25(5),
2021-2035.
</p>


<h3>See Also</h3>

<p>Other univariate imputation functions: 
<code>mice.impute.cart()</code>,
<code>mice.impute.lasso.norm()</code>,
<code>mice.impute.lasso.select.logreg()</code>,
<code>mice.impute.lasso.select.norm()</code>,
<code>mice.impute.lda()</code>,
<code>mice.impute.logreg.boot()</code>,
<code>mice.impute.logreg()</code>,
<code>mice.impute.mean()</code>,
<code>mice.impute.midastouch()</code>,
<code>mice.impute.mnar.logreg()</code>,
<code>mice.impute.mpmm()</code>,
<code>mice.impute.norm.boot()</code>,
<code>mice.impute.norm.nob()</code>,
<code>mice.impute.norm.predict()</code>,
<code>mice.impute.norm()</code>,
<code>mice.impute.pmm()</code>,
<code>mice.impute.polr()</code>,
<code>mice.impute.polyreg()</code>,
<code>mice.impute.quadratic()</code>,
<code>mice.impute.rf()</code>,
<code>mice.impute.ri()</code>
</p>


</div>