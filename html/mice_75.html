<div class="container">

<table style="width: 100%;"><tr>
<td>mice.impute.lasso.select.norm</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Imputation by indirect use of lasso linear regression</h2>

<h3>Description</h3>

<p>Imputes univariate missing data using Bayesian linear regression following a
preprocessing lasso variable selection step.
</p>


<h3>Usage</h3>

<pre><code class="language-R">mice.impute.lasso.select.norm(y, ry, x, wy = NULL, nfolds = 10, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>Vector to be imputed</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ry</code></td>
<td>
<p>Logical vector of length <code>length(y)</code> indicating the
the subset <code>y[ry]</code> of elements in <code>y</code> to which the imputation
model is fitted. The <code>ry</code> generally distinguishes the observed
(<code>TRUE</code>) and missing values (<code>FALSE</code>) in <code>y</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>Numeric design matrix with <code>length(y)</code> rows with predictors for
<code>y</code>. Matrix <code>x</code> may have no missing values.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>wy</code></td>
<td>
<p>Logical vector of length <code>length(y)</code>. A <code>TRUE</code> value
indicates locations in <code>y</code> for which imputations are created.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nfolds</code></td>
<td>
<p>The number of folds for the cross-validation of the lasso penalty.
The default is 10.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Other named arguments.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The method consists of the following steps:
</p>

<ol>
<li>
<p> For a given <code>y</code> variable under imputation, fit a linear regression with lasso
penalty using <code>y[ry]</code> as dependent variable and <code>x[ry, ]</code> as predictors.
Coefficients that are not shrunk to 0 define an active set of predictors
that will be used for imputation
</p>
</li>
<li>
<p> Define a Bayesian linear model using <code>y[ry]</code> as the
dependent variable, the active set of <code>x[ry, ]</code> as predictors, and standard
non-informative priors
</p>
</li>
<li>
<p> Draw parameter values for the intercept, regression weights, and error
variance from their posterior distribution
</p>
</li>
<li>
<p> Draw imputations from the posterior predictive distribution
</p>
</li>
</ol>
<p>The user can specify a <code>predictorMatrix</code> in the <code>mice</code> call
to define which predictors are provided to this univariate imputation method.
The lasso regularization will select, among the variables indicated by
the user, the ones that are important for imputation at any given iteration.
Therefore, users may force the exclusion of a predictor from a given
imputation model by specifying a <code>0</code> entry.
However, a non-zero entry does not guarantee the variable will be used,
as this decision is ultimately made by the lasso variable selection
procedure.
</p>
<p>The method is based on the Indirect Use of Regularized Regression (IURR) proposed by
Zhao &amp; Long (2016) and Deng et al (2016).
</p>


<h3>Value</h3>

<p>Vector with imputed data, same type as <code>y</code>, and of length
<code>sum(wy)</code>
</p>


<h3>Author(s)</h3>

<p>Edoardo Costantini, 2021
</p>


<h3>References</h3>

<p>Deng, Y., Chang, C., Ido, M. S., &amp; Long, Q. (2016). Multiple imputation for
general missing data patterns in the presence of high-dimensional data.
Scientific reports, 6(1), 1-10.
</p>
<p>Zhao, Y., &amp; Long, Q. (2016). Multiple imputation in the presence of
high-dimensional data. Statistical Methods in Medical Research, 25(5),
2021-2035.
</p>


<h3>See Also</h3>

<p>Other univariate imputation functions: 
<code>mice.impute.cart()</code>,
<code>mice.impute.lasso.logreg()</code>,
<code>mice.impute.lasso.norm()</code>,
<code>mice.impute.lasso.select.logreg()</code>,
<code>mice.impute.lda()</code>,
<code>mice.impute.logreg.boot()</code>,
<code>mice.impute.logreg()</code>,
<code>mice.impute.mean()</code>,
<code>mice.impute.midastouch()</code>,
<code>mice.impute.mnar.logreg()</code>,
<code>mice.impute.mpmm()</code>,
<code>mice.impute.norm.boot()</code>,
<code>mice.impute.norm.nob()</code>,
<code>mice.impute.norm.predict()</code>,
<code>mice.impute.norm()</code>,
<code>mice.impute.pmm()</code>,
<code>mice.impute.polr()</code>,
<code>mice.impute.polyreg()</code>,
<code>mice.impute.quadratic()</code>,
<code>mice.impute.rf()</code>,
<code>mice.impute.ri()</code>
</p>


</div>