<div class="container">

<table style="width: 100%;"><tr>
<td>cv.sglfit</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Cross-validation fit for sg-LASSO</h2>

<h3>Description</h3>

<p>Does k-fold cross-validation for sg-LASSO regression model.
</p>
<p>The function runs sglfit <code>nfolds+1</code> times; the first to get the path solution in λ sequence, the rest to compute the fit with each of the folds omitted. 
The average error and standard deviation over the folds is computed, and the optimal regression coefficients are returned for <code>lam.min</code> and <code>lam.1se</code>. Solutions are computed for a fixed γ
</p>


<h3>Usage</h3>

<pre><code class="language-R">cv.sglfit(x, y, lambda = NULL, gamma = 1.0, gindex = 1:p, 
  nfolds = 10, foldid, parallel = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>T by p data matrix, where T and p respectively denote the sample size and the number of regressors.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>T by 1 response variable.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda</code></td>
<td>
<p>a user-supplied lambda sequence. By leaving this option unspecified (recommended), users can have the program compute its own λ sequence based on <code>nlambda</code> and γ <code>lambda.factor.</code> It is better to supply, if necessary, a decreasing sequence of lambda values than a single (small) value, as warm-starts are used in the optimization algorithm. The program will ensure that the user-supplied <code>lambda</code> sequence is sorted in decreasing order before fitting the model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>gamma</code></td>
<td>
<p>sg-LASSO mixing parameter. γ = 1 gives LASSO solution and γ = 0 gives group LASSO solution.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>gindex</code></td>
<td>
<p>p by 1 vector indicating group membership of each covariate.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nfolds</code></td>
<td>
<p>number of folds of the cv loop. Default set to <code>10</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>foldid</code></td>
<td>
<p>the fold assignments used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>parallel</code></td>
<td>
<p>if <code>TRUE</code>, use parallel foreach to fit each fold. Must register parallel before hand, such as doMC or others. See the example below.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Other arguments that can be passed to sglfit.</p>
</td>
</tr>
</table>
<h3>Details</h3>

The cross-validation is run for sg-LASSO linear model. The sequence of linear regression models implied by λ vector is fit by block coordinate-descent. The objective function is  <br><br> ||y - ια - xβ||<sup>2</sup><sub>T</sub> + 2λ  Ω<sub>γ</sub>(β), <br> where ι∈R<sup>T</sup>enter&gt; and ||u||<sup>2</sup><sub>T</sub>=&lt;u,u&gt;/T is the empirical inner product. The penalty function Ω<sub>γ</sub>(.) is applied on  β coefficients and is <br><br> Ω<sub>γ</sub>(β) = γ |β|<sub>1</sub> + (1-γ)|β|<sub>2,1</sub>, <br> a convex combination of LASSO and group LASSO penalty functions.


<h3>Value</h3>

<p>cv.sglfit object.
</p>


<h3>Author(s)</h3>

<p>Jonas Striaukas
</p>


<h3>Examples</h3>

<pre><code class="language-R">set.seed(1)
x = matrix(rnorm(100 * 20), 100, 20)
beta = c(5,4,3,2,1,rep(0, times = 15))
y = x%*%beta + rnorm(100)
gindex = sort(rep(1:4,times=5))
cv.sglfit(x = x, y = y, gindex = gindex, gamma = 0.5, 
  standardize = FALSE, intercept = FALSE)
## Not run:  
# Parallel
require(doMC)
registerDoMC(cores = 2)
x = matrix(rnorm(1000 * 20), 1000, 20)
beta = c(5,4,3,2,1,rep(0, times = 15))
y = x%*%beta + rnorm(1000)
gindex = sort(rep(1:4,times=5))
system.time(cv.sglfit(x = x, y = y, gindex = gindex, gamma = 0.5, 
  standardize = FALSE, intercept = FALSE))
system.time(cv.sglfit(x = x, y = y, gindex = gindex, gamma = 0.5, 
  standardize = FALSE, intercept = FALSE, parallel = TRUE))

## End(Not run)
</code></pre>


</div>