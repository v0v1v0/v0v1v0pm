<div class="container">

<table style="width: 100%;"><tr>
<td>mice.impute.midastouch</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Predictive Mean Matching with distance aided selection of donors</h2>

<h3>Description</h3>

<p>Imputes univariate missing data using predictive mean matching
</p>


<h3>Usage</h3>

<pre><code class="language-R">mice.impute.midastouch(y, ry, x, ridge = 1e-05, 
	midas.kappa = NULL, outout = TRUE, neff = NULL, debug = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>Numeric vector with incomplete data</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ry</code></td>
<td>
<p>Response pattern of <code>y</code> (<code>TRUE</code>=observed,
<code>FALSE</code>=missing)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>Design matrix with <code>length(y)</code> rows and <code>p</code> columns
containing complete covariates.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ridge</code></td>
<td>
<p>The ridge penalty applied to prevent problems with multicollinearity. The default is <code>ridge = 1e-05</code>, which means that 0.001 percent of the diagonal is added to the cross-product. Larger ridges may result in more biased estimates. For highly noisy data (e.g. many junk variables), set <code>ridge = 1e-06</code> or even lower to reduce bias. For highly collinear data, set <code>ridge = 1e-04</code> or higher.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>midas.kappa</code></td>
<td>
<p>Scalar. If <code>NULL</code> (default) then the optimal <code>kappa</code> gets selected automatically. Alternatively, the user may specify a scalar. Siddique and Belin 2008 find <code>midas.kappa = 3</code> to be sensible.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>outout</code></td>
<td>
<p>Logical. If <code>TRUE</code> (default) one model is estimated for each donor (leave-one-out principle). For speedup choose <code>outout = FALSE</code>, which estimates one model for all observations leading to in-sample predictions for the donors and out-of-sample predictions for the recipients. Mind the inappropriateness, though.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>neff</code></td>
<td>
<p>FOR EXPERTS. Null or character string. The name of an existing environment in which the effective sample size of the donors for each loop (CE iterations times multiple imputations) is supposed to be written. The effective sample size is necessary to compute the correction for the total variance as originally suggested by Parzen, Lipsitz and Fitzmaurice 2005. The objectname is <code>midastouch.neff</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>debug</code></td>
<td>
<p>FOR EXPERTS. Null or character string. The name of an existing environment in which the input is supposed to be written. The objectname is <code>midastouch.inputlist</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Other named arguments.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Imputation of <code>y</code> by predictive mean matching, based on Rubin (1987, p.
168, formulas a and b) and Siddique and Belin 2008. The procedure is as follows:
</p>

<ol>
<li>
<p> Draw a bootstrap sample from the donor pool.
</p>
</li>
<li>
<p> Estimate a beta matrix on the bootstrap sample by the leave one out principle.
</p>
</li>
<li>
<p> Compute type II predicted values for <code>yobs</code> (nobs x 1) and <code>ymis</code> (nmis x nobs).
</p>
</li>
<li>
<p> Calculate the distance between all <code>yobs</code> and the corresponding <code>ymis</code>. 
</p>
</li>
<li>
<p> Convert the distances in drawing probabilities.
</p>
</li>
<li>
<p> For each recipient draw a donor from the entire pool while considering the probabilities from the model.
</p>
</li>
<li>
<p> Take its observed value in <code>y</code> as the imputation.
</p>
</li>
</ol>
<h3>Value</h3>

<p>Numeric vector of length <code>sum(!ry)</code> with imputations
</p>


<h3>Author(s)</h3>

<p>Philipp Gaffert, Florian Meinfelder, Volker Bosch 2015
</p>


<h3>References</h3>

<p>Gaffert, P., Meinfelder, F., Bosch V. (2015) Towards an MI-proper Predictive Mean Matching, Discussion Paper. 
<a href="https://www.uni-bamberg.de/fileadmin/uni/fakultaeten/sowi_lehrstuehle/statistik/Personen/Dateien_Florian/properPMM.pdf">https://www.uni-bamberg.de/fileadmin/uni/fakultaeten/sowi_lehrstuehle/statistik/Personen/Dateien_Florian/properPMM.pdf</a>
</p>
<p>Little, R.J.A. (1988), Missing data adjustments in large surveys
(with discussion), Journal of Business Economics and Statistics, 6, 287–301.
</p>
<p>Parzen, M., Lipsitz, S. R., Fitzmaurice, G. M. (2005), A note on reducing the bias of the approximate
bayesian bootstrap imputation variance estimator. Biometrika <b>92</b>, 4, 971–974.
</p>
<p>Rubin, D.B. (1987), Multiple imputation for nonresponse in surveys. New York:
Wiley.
</p>
<p>Siddique, J., Belin, T.R. (2008), Multiple imputation using an iterative hot-deck with distance-based donor selection. Statistics in medicine, <b>27</b>, 1, 83–102
</p>
<p>Van Buuren, S., Brand, J.P.L., Groothuis-Oudshoorn C.G.M., Rubin, D.B. (2006),
Fully conditional specification in multivariate imputation.  <em>Journal of
Statistical Computation and Simulation</em>, <b>76</b>, 12, 1049–1064.
</p>
<p>Van Buuren, S., Groothuis-Oudshoorn, K. (2011), <code>mice</code>: Multivariate
Imputation by Chained Equations in <code>R</code>. <em>Journal of Statistical
Software</em>, <b>45</b>, 3, 1–67. <a href="http://www.jstatsoft.org/v45/i03/">http://www.jstatsoft.org/v45/i03/</a>
</p>


<h3>Examples</h3>

<pre><code class="language-R">## from R:: mice, slightly adapted ##

# do default multiple imputation on a numeric matrix
library(midastouch)
library(mice)
imp &lt;- mice(nhanes, method = 'midastouch')
imp

# list the actual imputations for BMI
imp$imp$bmi

# first completed data matrix
complete(imp)


# imputation on mixed data with a different method per column

mice(nhanes2, method = c('sample','midastouch','logreg','norm'))
</code></pre>


</div>