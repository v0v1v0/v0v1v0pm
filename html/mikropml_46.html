<div class="container">

<table style="width: 100%;"><tr>
<td>define_cv</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Define cross-validation scheme and training parameters</h2>

<h3>Description</h3>

<p>Define cross-validation scheme and training parameters
</p>


<h3>Usage</h3>

<pre><code class="language-R">define_cv(
  train_data,
  outcome_colname,
  hyperparams_list,
  perf_metric_function,
  class_probs,
  kfold = 5,
  cv_times = 100,
  groups = NULL,
  group_partitions = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>train_data</code></td>
<td>
<p>Dataframe for training model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>outcome_colname</code></td>
<td>
<p>Column name as a string of the outcome variable
(default <code>NULL</code>; the first column will be chosen automatically).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>hyperparams_list</code></td>
<td>
<p>Named list of lists of hyperparameters.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>perf_metric_function</code></td>
<td>
<p>Function to calculate the performance metric to
be used for cross-validation and test performance. Some functions are
provided by caret (see <code>caret::defaultSummary()</code>).
Defaults: binary classification = <code>twoClassSummary</code>,
multi-class classification = <code>multiClassSummary</code>,
regression = <code>defaultSummary</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>class_probs</code></td>
<td>
<p>Whether to use class probabilities (TRUE for categorical outcomes, FALSE for numeric outcomes).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>kfold</code></td>
<td>
<p>Fold number for k-fold cross-validation (default: <code>5</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cv_times</code></td>
<td>
<p>Number of cross-validation partitions to create (default: <code>100</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>groups</code></td>
<td>
<p>Vector of groups to keep together when splitting the data into
train and test sets. If the number of groups in the training set is larger
than <code>kfold</code>, the groups will also be kept together for cross-validation.
Length matches the number of rows in the dataset (default: <code>NULL</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>group_partitions</code></td>
<td>
<p>Specify how to assign <code>groups</code> to the training and
testing partitions (default: <code>NULL</code>). If <code>groups</code> specifies that some
samples belong to group <code>"A"</code> and some belong to group <code>"B"</code>, then setting
<code>group_partitions = list(train = c("A", "B"), test = c("B"))</code> will result
in all samples from group <code>"A"</code> being placed in the training set, some
samples from <code>"B"</code> also in the training set, and the remaining samples from
<code>"B"</code> in the testing set. The partition sizes will be as close to
<code>training_frac</code> as possible. If the number of groups in the training set is
larger than <code>kfold</code>, the groups will also be kept together for
cross-validation.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>Caret object for trainControl that controls cross-validation
</p>


<h3>Author(s)</h3>

<p>Begüm Topçuoğlu, <a href="mailto:topcuoglu.begum@gmail.com">topcuoglu.begum@gmail.com</a>
</p>
<p>Kelly Sovacool, <a href="mailto:sovacool@umich.edu">sovacool@umich.edu</a>
</p>


<h3>Examples</h3>

<pre><code class="language-R">training_inds &lt;- get_partition_indices(otu_small %&gt;% dplyr::pull("dx"),
  training_frac = 0.8,
  groups = NULL
)
train_data &lt;- otu_small[training_inds, ]
test_data &lt;- otu_small[-training_inds, ]
cv &lt;- define_cv(train_data,
  outcome_colname = "dx",
  hyperparams_list = get_hyperparams_list(otu_small, "glmnet"),
  perf_metric_function = caret::multiClassSummary,
  class_probs = TRUE,
  kfold = 5
)
</code></pre>


</div>