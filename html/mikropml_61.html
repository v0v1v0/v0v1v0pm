<div class="container">

<table style="width: 100%;"><tr>
<td>get_performance_tbl</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Get model performance metrics as a one-row tibble</h2>

<h3>Description</h3>

<p>Get model performance metrics as a one-row tibble
</p>


<h3>Usage</h3>

<pre><code class="language-R">get_performance_tbl(
  trained_model,
  test_data,
  outcome_colname,
  perf_metric_function,
  perf_metric_name,
  class_probs,
  method,
  seed = NA
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>trained_model</code></td>
<td>
<p>Trained model from <code>caret::train()</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>test_data</code></td>
<td>
<p>Held out test data: dataframe of outcome and features.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>outcome_colname</code></td>
<td>
<p>Column name as a string of the outcome variable
(default <code>NULL</code>; the first column will be chosen automatically).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>perf_metric_function</code></td>
<td>
<p>Function to calculate the performance metric to
be used for cross-validation and test performance. Some functions are
provided by caret (see <code>caret::defaultSummary()</code>).
Defaults: binary classification = <code>twoClassSummary</code>,
multi-class classification = <code>multiClassSummary</code>,
regression = <code>defaultSummary</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>perf_metric_name</code></td>
<td>
<p>The column name from the output of the function
provided to perf_metric_function that is to be used as the performance metric.
Defaults: binary classification = <code>"ROC"</code>,
multi-class classification = <code>"logLoss"</code>,
regression = <code>"RMSE"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>class_probs</code></td>
<td>
<p>Whether to use class probabilities (TRUE for categorical outcomes, FALSE for numeric outcomes).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p>ML method.
Options: <code>c("glmnet", "rf", "rpart2", "svmRadial", "xgbTree")</code>.
</p>

<ul>
<li>
<p> glmnet: linear, logistic, or multiclass regression
</p>
</li>
<li>
<p> rf: random forest
</p>
</li>
<li>
<p> rpart2: decision tree
</p>
</li>
<li>
<p> svmRadial: support vector machine
</p>
</li>
<li>
<p> xgbTree: xgboost
</p>
</li>
</ul>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>seed</code></td>
<td>
<p>Random seed (default: <code>NA</code>).
Your results will only be reproducible if you set a seed.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>A one-row tibble with a column for the cross-validation performance,
columns for each of the performance metrics for the test data,
plus the <code>method</code>, and <code>seed</code>.
</p>


<h3>Author(s)</h3>

<p>Kelly Sovacool, <a href="mailto:sovacool@umich.edu">sovacool@umich.edu</a>
</p>
<p>Zena Lapp, <a href="mailto:zenalapp@umich.edu">zenalapp@umich.edu</a>
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Not run: 
results &lt;- run_ml(otu_small, "glmnet", kfold = 2, cv_times = 2)
names(results$trained_model$trainingData)[1] &lt;- "dx"
get_performance_tbl(results$trained_model, results$test_data,
  "dx",
  multiClassSummary, "AUC",
  class_probs = TRUE,
  method = "glmnet"
)

## End(Not run)

</code></pre>


</div>