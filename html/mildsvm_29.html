<div class="container">

<table style="width: 100%;"><tr>
<td>mior</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Fit MIOR model to the data</h2>

<h3>Description</h3>

<p>This function fits the MIOR model, proposed by Xiao Y, Liu B, and Hao Z
(2018) in "Multiple-instance Ordinal Regression".  MIOR is a modified SVM
framework with parallel, ordered hyperplanes where the error terms are based
only on the instance closest to a midpoint between hyperplanes.
</p>


<h3>Usage</h3>

<pre><code class="language-R">## Default S3 method:
mior(
  x,
  y,
  bags,
  cost = 1,
  cost_eta = 1,
  method = "qp-heuristic",
  weights = NULL,
  control = list(kernel = "linear", sigma = if (is.vector(x)) 1 else 1/ncol(x),
    max_step = 500, scale = TRUE, verbose = FALSE, time_limit = 60, option =
    c("corrected", "xiao")),
  ...
)

## S3 method for class 'formula'
mior(formula, data, ...)

## S3 method for class 'mi_df'
mior(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>A data.frame, matrix, or similar object of covariates, where each
row represents an instance. If a <code>mi_df</code> object is passed, <code style="white-space: pre;">⁠y, bags⁠</code> are
automatically extracted, and all other columns will be used as predictors.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>A numeric, character, or factor vector of bag labels for each
instance.  Must satisfy <code>length(y) == nrow(x)</code>. Suggest that one of the
levels is 1, '1', or TRUE, which becomes the positive class; otherwise, a
positive class is chosen and a message will be supplied.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>bags</code></td>
<td>
<p>A vector specifying which instance belongs to each bag.  Can be a
string, numeric, of factor.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cost</code></td>
<td>
<p>The cost parameter in SVM. If <code>method = 'heuristic'</code>, this will
be fed to <code>kernlab::ksvm()</code>, otherwise it is similarly in internal
functions.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cost_eta</code></td>
<td>
<p>The additional cost parameter in MIOR which controls how far
away the first and last separating hyperplanes are relative to other costs.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p>The algorithm to use in fitting (default  <code>'heuristic'</code>).  When
<code>method = 'heuristic'</code>, which employs an algorithm similar to Andrews et
al. (2003). When <code>method = 'mip'</code>, the novel MIP method will be used.  When
<code style="white-space: pre;">⁠method = 'qp-heuristic⁠</code>, the heuristic algorithm is computed using the
dual SVM.  See details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>weights</code></td>
<td>
<p>named vector, or <code>TRUE</code>, to control the weight of the cost
parameter for each possible y value.  Weights multiply against the cost
vector. If <code>TRUE</code>, weights are calculated based on inverse counts of
instances with given label, where we only count one positive instance per
bag. Otherwise, names must match the levels of <code>y</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>control</code></td>
<td>
<p>list of additional parameters passed to the method that
control computation with the following components:
</p>

<ul>
<li> <p><code>kernel</code> either a character the describes the kernel ('linear' or
'radial') or a kernel matrix at the instance level.
</p>
</li>
<li> <p><code>sigma</code> argument needed for radial basis kernel.
</p>
</li>
<li> <p><code>max_step</code> argument used when <code>method = 'heuristic'</code>. Maximum steps of
iteration for the heuristic algorithm.
</p>
</li>
<li> <p><code>scale</code> argument used for all methods. A logical for whether to rescale
the input before fitting.
</p>
</li>
<li> <p><code>verbose</code> argument used when <code>method = 'mip'</code>. Whether to message output
to the console.
</p>
</li>
<li> <p><code>time_limit</code> argument used when <code>method = 'mip'</code>. <code>FALSE</code>, or a time
limit (in seconds) passed to <code>gurobi()</code> parameters.  If <code>FALSE</code>, no time
limit is given.
</p>
</li>
<li> <p><code>option</code> argument the controls the constraint calculation.  See details.
</p>
</li>
</ul>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Arguments passed to or from other methods.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>formula</code></td>
<td>
<p>a formula with specification <code>mi(y, bags) ~ x</code> which uses the
<code>mi</code> function to create the bag-instance structure. This argument is an
alternative to the <code style="white-space: pre;">⁠x, y, bags⁠</code> arguments, but requires the <code>data</code>
argument. See examples.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>If <code>formula</code> is provided, a data.frame or similar from which
formula elements will be extracted</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Predictions (see <code>predict.mior()</code>) are determined by considering the smallest
distance from each point to the midpoint hyperplanes across all instances in
the bag.  The prediction corresponds to the hyperplane having such a minimal
distance.
</p>
<p>It appears as though an error in Equation (12) persists to the dual form in
(21). A corrected version of this dual formulation can be used with
<code>control$option = 'corrected'</code>, or the formulation as written can be used
with <code>control$option = 'xiao'</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>mior</code>  The object contains at least the following
components:
</p>

<ul>
<li> <p><code>gurobi_fit</code>: A fit from model optimization that includes relevant
components.
</p>
</li>
<li> <p><code>call_type</code>: A character indicating which method <code>misvm()</code> was called
with.
</p>
</li>
<li> <p><code>features</code>: The names of features used in training.
</p>
</li>
<li> <p><code>levels</code>: The levels of <code>y</code> that are recorded for future prediction.
</p>
</li>
<li> <p><code>cost</code>: The cost parameter from function inputs.
</p>
</li>
<li> <p><code>weights</code>: The calculated weights on the <code>cost</code> parameter.
</p>
</li>
<li> <p><code>repr_inst</code>: The instances from positive bags that are selected to be
most representative of the positive instances.
</p>
</li>
<li> <p><code>n_step</code>: If <code>method %in% c('heuristic', 'qp-heuristic')</code>, the total
steps used in the heuristic algorithm.
</p>
</li>
<li> <p><code>x_scale</code>: If <code>scale = TRUE</code>, the scaling parameters for new predictions.
</p>
</li>
</ul>
<h3>Methods (by class)</h3>


<ul>
<li> <p><code>default</code>: Method for data.frame-like objects
</p>
</li>
<li> <p><code>formula</code>: Method for passing formula
</p>
</li>
<li> <p><code>mi_df</code>: Method for <code>mi_df</code> objects, automatically handling bag
names, labels, and all covariates.
</p>
</li>
</ul>
<h3>Author(s)</h3>

<p>Sean Kent
</p>


<h3>References</h3>

<p>Xiao, Y., Liu, B., &amp; Hao, Z. (2017). Multiple-instance ordinal
regression. <em>IEEE Transactions on Neural Networks and Learning Systems</em>,
<em>29</em>(9), 4398-4413. doi: <a href="https://doi.org/10.1109/TNNLS.2017.2766164">10.1109/TNNLS.2017.2766164</a>
</p>


<h3>See Also</h3>

<p><code>predict.misvm()</code> for prediction on new data.
</p>


<h3>Examples</h3>

<pre><code class="language-R">if (require(gurobi)) {
  set.seed(8)
  # make some data
  n &lt;- 15
  X &lt;- rbind(
    mvtnorm::rmvnorm(n/3, mean = c(4, -2, 0)),
    mvtnorm::rmvnorm(n/3, mean = c(0, 0, 0)),
    mvtnorm::rmvnorm(n/3, mean = c(-2, 1, 0))
  )
  score &lt;- X %*% c(2, -1, 0)
  y &lt;- as.numeric(cut(score, c(-Inf, quantile(score, probs = 1:2 / 3), Inf)))
  bags &lt;- 1:length(y)

  # add in points outside boundaries
  X &lt;- rbind(
    X,
    mvtnorm::rmvnorm(n, mean = c(6, -3, 0)),
    mvtnorm::rmvnorm(n, mean = c(-6, 3, 0))
  )
  y &lt;- c(y, rep(-1, 2*n))
  bags &lt;- rep(bags, 3)
  repr &lt;- c(rep(1, n), rep(0, 2*n))

  y_bag &lt;- classify_bags(y, bags, condense = FALSE)

  mdl1 &lt;- mior(X, y_bag, bags)
  predict(mdl1, X, new_bags = bags)
}

</code></pre>


</div>