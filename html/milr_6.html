<div class="container">

<table style="width: 100%;"><tr>
<td>milr</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Maximum likelihood estimation of multiple-instance logistic regression with LASSO penalty</h2>

<h3>Description</h3>

<p>Please refer to milr-package.
</p>


<h3>Usage</h3>

<pre><code class="language-R">milr(
  y,
  x,
  bag,
  lambda = 0,
  numLambda = 20L,
  lambdaCriterion = "BIC",
  nfold = 10L,
  maxit = 500L
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>a vector. Bag-level binary labels.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>the design matrix. The number of rows of <code>x</code> must be equal to the length of <code>y</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>bag</code></td>
<td>
<p>a vector, bag id.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda</code></td>
<td>
<p>the tuning parameter for LASSO-penalty.  If <code>lambda</code> is a real value number, then the <code>milr</code> 
fits the model based on this lambda value.  Second, if <code>lambda</code> is vector, then the optimal lambda value would be
be chosen based on the optimality criterion, <code>lambdaCriterion</code>.  
Finally, if <code>lambda = -1</code>, then the optimal lambda value would be chosen automatically.
The default is 0.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>numLambda</code></td>
<td>
<p>An integer, the maximum length of LASSO-penalty. in atuo-tunning mode 
(<code>lambda = -1</code>). The default is 20.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambdaCriterion</code></td>
<td>
<p>a string, the used optimality criterion for tuning the <code>lambda</code> value.
It can be specified with <code>lambdaCriterion = "BIC"</code> or <code>lambdaCriterion = "deviance"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nfold</code></td>
<td>
<p>an integer, the number of fold for cross-validation to choose the optimal <code>lambda</code> when
<code>lambdaCriterion = "deviance"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>maxit</code></td>
<td>
<p>an integer, the maximum iteration for the EM algorithm. The default is 500.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>An object with S3 class "milr".
</p>

<ul>
<li>
<p>lambdaa vector of candidate lambda values.
</p>
</li>
<li>
<p>cva vector of predictive deviance via <code>nfold</code>-fold cross validation
when <code>lambdaCriterion = "deviance"</code>.
</p>
</li>
<li>
<p>deviancea vector of deviance of candidate model for each candidate lambda value.
</p>
</li>
<li>
<p>BICa vector of BIC of candidate model for each candidate lambda value.
</p>
</li>
<li>
<p>best_indexan integer, indicates the index of the best model among candidate lambda values.
</p>
</li>
<li>
<p>best_modela list of the information for the best model including deviance (not cv deviance), 
BIC, chosen lambda, coefficients, fitted values, log-likelihood and variances of coefficients.
</p>
</li>
</ul>
<h3>Examples</h3>

<pre><code class="language-R">set.seed(100)
beta &lt;- runif(5, -5, 5)
trainData &lt;- DGP(40, 3, beta)
testData &lt;- DGP(5, 3, beta)
# default (not use LASSO)
milr_result &lt;- milr(trainData$Z, trainData$X, trainData$ID)
coef(milr_result)      # coefficients
fitted(milr_result)                    # fitted bag labels
fitted(milr_result, type = "instance") # fitted instance labels
summary(milr_result)   # summary milr
predict(milr_result, testData$X, testData$ID)                    # predicted bag labels
predict(milr_result, testData$X, testData$ID, type = "instance") # predicted instance labels

# use BIC to choose penalty (not run)
#milr_result &lt;- milr(trainData$Z, trainData$X, trainData$ID,
#                    exp(seq(log(0.01), log(50), length = 30)))
#coef(milr_result)      # coefficients
#fitted(milr_result)                    # fitted bag labels
#fitted(milr_result, type = "instance") # fitted instance labels
#summary(milr_result)   # summary milr
#predict(milr_result, testData$X, testData$ID)                    # predicted bag labels
#predict(milr_result, testData$X, testData$ID, type = "instance") # predicted instance labels

# use auto-tuning (not run)
#milr_result &lt;- milr(trainData$Z, trainData$X, trainData$ID, lambda = -1, numLambda = 20)
#coef(milr_result)      # coefficients
#fitted(milr_result)                    # fitted bag labels
#fitted(milr_result, type = "instance") # fitted instance labels
#summary(milr_result)   # summary milr
#predict(milr_result, testData$X, testData$ID)                    # predicted bag labels
#predict(milr_result, testData$X, testData$ID, type = "instance") # predicted instance labels

# use cv in auto-tuning (not run)
#milr_result &lt;- milr(trainData$Z, trainData$X, trainData$ID, 
#                    lambda = -1, numLambda = 20, lambdaCriterion = "deviance")
#coef(milr_result)      # coefficients
#fitted(milr_result)                    # fitted bag labels
#fitted(milr_result, type = "instance") # fitted instance labels
#summary(milr_result)   # summary milr
#predict(milr_result, testData$X, testData$ID)                    # predicted bag labels
#predict(milr_result, testData$X, testData$ID, type = "instance") # predicted instance labels
</code></pre>


</div>