<div class="container">

<table style="width: 100%;"><tr>
<td>SIBTEST</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>(Generalized) Simultaneous Item Bias Test (SIBTEST)</h2>

<h3>Description</h3>

<p>Classical test theory approach to detecting unidirectional and bidirectional (with one
crossing location) DIF. This family of statistics is intended for unidimensional tests,
and applies a regression-corrected matched-total score approach to quantify the response
bias between two or more groups. Can be used for DIF, DBF, and DTF testing with two or more
discrete groups.
</p>


<h3>Usage</h3>

<pre><code class="language-R">SIBTEST(
  dat,
  group,
  suspect_set,
  match_set,
  focal_name = unique(group)[2],
  guess_correction = 0,
  Jmin = 5,
  na.rm = FALSE,
  randomize = FALSE,
  C = cbind(1, -diag(length(unique(group)) - 1L)),
  pairwise = FALSE,
  DIF = FALSE,
  p.adjust.method = "none",
  permute = 1000,
  pk_focal = FALSE,
  correction = TRUE,
  remove_cross = FALSE,
  details = FALSE,
  plot = "none",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>dat</code></td>
<td>
<p>integer-based dataset to be tested, containing dichotomous or polytomous responses</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>group</code></td>
<td>
<p>a (factor) vector indicating group membership
with the same length as the number of rows in <code>dat</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>suspect_set</code></td>
<td>
<p>an integer vector indicating which items to inspect with SIBTEST. Including only
one value will perform a DIF test, while including more than one will perform a simultaneous
bundle test (DBF); including all non-matched items will perform DTF.
If missing, a simultaneous test using all the items not listed in match_set
will be used (i.e., DTF)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>match_set</code></td>
<td>
<p>an integer vector indicating which items to use as the items which are matched
(i.e., contain no DIF). These are analogous to 'anchor' items in the likelihood method to locate
DIF. If missing, all items other than the items found in the <code>suspect_set</code> will be used</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>focal_name</code></td>
<td>
<p>name of the focal group; e.g., <code>'focal'</code>. If not specified then one will be
selected automatically using <code>unique(group)[2]</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>guess_correction</code></td>
<td>
<p>a vector of numbers from 0 to 1 indicating how much to correct the items
for guessing. It's length should be the same as ncol(dat)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Jmin</code></td>
<td>
<p>the minimum number of observations required when splitting the data into focal and
reference groups conditioned on the matched set</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>na.rm</code></td>
<td>
<p>logical; remove rows in <code>dat</code> with any missing values? If <code>TRUE</code>,
rows with missing data will be removed, as well as the corresponding elements in the <code>group</code>
input</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>randomize</code></td>
<td>
<p>logical; perform the crossing test for non-compensatory bias
using Li and Stout's (1996) permutation approach? Default is <code>FALSE</code>, which uses the
ad-hoc mixed degrees of freedom method suggested by Chalmers (2018)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>C</code></td>
<td>
<p>a contrast matrix to use for pooled testing with more than two groups. Default uses an
effects coding approach, where the last group (last column of the matrix) is treated as the reference
group, and each column is associated with the respective name via <code>unique(group)</code> (i.e., the first
column is the coefficient for <code>unique(group)[1]</code>, second column for <code>unique(group)[2]</code>, and
so on)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pairwise</code></td>
<td>
<p>logical; perform pairwise comparisons in multi-group applications?</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>DIF</code></td>
<td>
<p>logical; should the elements in <code>suspect_set</code> be treated one at a time
to test for DIF? Use of this logical will treat all other items as part of the <code>match_set</code>
unless this input is provided explicitly. Default is <code>FALSE</code> to allow DBF and DTF tests</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>p.adjust.method</code></td>
<td>
<p>a character input dictating which <code>method</code> to use in <code>p.adjust</code>.
when studying more than two groups. Default does not present any p-value adjustments</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>permute</code></td>
<td>
<p>number of permutations to perform when <code>randomize = TRUE</code>. Default is 1000</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pk_focal</code></td>
<td>
<p>logical; using the group weights from the focal group instead of the total
sample? Default is FALSE as per Shealy and Stout's recommendation</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>correction</code></td>
<td>
<p>logical; apply the composite correction for the difference between focal
composite scores using the true-score regression technique? Default is <code>TRUE</code>,
reflecting Shealy and Stout's linear extrapolation method</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>remove_cross</code></td>
<td>
<p>logical; remove the subtest information associated with the approximate
crossing location? If TRUE this reflects the CSIBTEST definition of Li and Stout (1996);
if FALSE, this reflects the version of CSIBTEST utilized by Chalmers (2018). Only applicable
in two-group settings (in multi-group this is fixed to FALSE)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>details</code></td>
<td>
<p>logical; return a data.frame containing the details required to compute SIBTEST?</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>plot</code></td>
<td>
<p>a character input indicating the type of plot to construct. Options are <code>'none'</code>
(default), <code>'observed'</code> for the scaled focal subtest scores against the matched subtest
scores, <code>'weights'</code> for the proportion weights used (i.e., the proportion of observations at
each matched score), <code>'difference'</code> for the difference between the scaled focal subtest scores
against the matched subtest scores, and <code>'wdifference'</code> for the conditional differences multiplied
by each respective weight. Note that the last plot reflects the components used in SIBTEST,
and therefore the sum of these plotted observations will equal the beta coefficient for SIBTEST</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>additional plotting arguments to be passed</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>SIBTEST is similar to the Mantel-Haenszel approach for detecting DIF but uses a regression
correction based on the KR-20/coefficient alpha reliability index to correct the observed
differences when the latent trait distributions are not equal.
Function supports the standard SIBTEST for dichotomous and polytomous data (compensatory) and
supports crossing DIF testing (i.e., non-compensatory/non-uniform) using the asymptotic sampling
distribution version of the Crossing-SIBTEST (CSIBTEST) statistic described by
Chalmers (2018) and the permutation method described by Li and Stout (1996). This
function also supports the multi-group generalizations (GSIBTEST and GCSIBTEST)
proposed by Chalmers and Zheng (2023), where users may specify alternative
contrast matrices to evaluate specific comparisons between groups as well as
perform joint hypothesis tests.
</p>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R. P. (2018). Improving the Crossing-SIBTEST statistic for
detecting non-uniform DIF. <em>Psychometrika, 83</em>, 2, 376-386.
</p>
<p>Chalmers, R., P. (2012). mirt: A Multidimensional Item Response Theory
Package for the R Environment. <em>Journal of Statistical Software, 48</em>(6), 1-29.
<a href="https://doi.org/10.18637/jss.v048.i06">doi:10.18637/jss.v048.i06</a>
</p>
<p>Chalmers, R. P. &amp; Zheng, G. (2023). Multi-group Generalizations of
SIBTEST and Crossing-SIBTEST. <em>Applied Measurement in Education, 36</em>(2), 171-191,
<a href="https://doi.org/10.1080/08957347.2023.2201703">doi:10.1080/08957347.2023.2201703</a>.
</p>
<p>Chang, H. H., Mazzeo, J. &amp; Roussos, L. (1996). DIF for Polytomously Scored Items: An Adaptation of the
SIBTEST Procedure. <em>Journal of Educational Measurement, 33</em>, 333-353.
</p>
<p>Li, H.-H. &amp; Stout, W. (1996). A new procedure for detection of crossing DIF.
<em>Psychometrika, 61</em>, 647-677.
</p>
<p>Shealy, R. &amp; Stout, W. (1993). A model-based standardization approach that separates true
bias/DIF from group ability differences and detect test bias/DTF as well as item bias/DIF.
<em>Psychometrika, 58</em>, 159-194.
</p>


<h3>Examples</h3>

<pre><code class="language-R">
## Not run: 

set.seed(1234)
n &lt;- 30
N &lt;- 500
a &lt;- matrix(1, n)
d &lt;- matrix(rnorm(n), n)
group &lt;- c(rep('reference', N), rep('focal', N*2))

## -------------
# groups completely equal
dat1 &lt;- simdata(a, d, N, itemtype = 'dich')
dat2 &lt;- simdata(a, d, N*2, itemtype = 'dich')
dat &lt;- rbind(dat1, dat2)

# DIF (all other items as anchors)
SIBTEST(dat, group, suspect_set = 6)

# Some plots depicting the above tests
SIBTEST(dat, group, suspect_set = 6, plot = 'observed')
SIBTEST(dat, group, suspect_set = 6, plot = 'weights')
SIBTEST(dat, group, suspect_set = 6, plot = 'wdifference')

# Include CSIBTEST with randomization method
SIBTEST(dat, group, suspect_set = 6, randomize = TRUE)

# remove crossing-location (identical to Li and Stout 1996 definition of CSIBTEST)
SIBTEST(dat, group, suspect_set = 6, randomize = TRUE, remove_cross=TRUE)

# DIF (specific anchors)
SIBTEST(dat, group, match_set = 1:5, suspect_set = 6)
SIBTEST(dat, group, match_set = 1:5, suspect_set = 6, randomize=TRUE)

# DBF (all and specific anchors, respectively)
SIBTEST(dat, group, suspect_set = 11:30)
SIBTEST(dat, group, match_set = 1:5, suspect_set = 11:30)

# DTF
SIBTEST(dat, group, suspect_set = 11:30)
SIBTEST(dat, group, match_set = 1:10) #equivalent

# different hyper pars
dat1 &lt;- simdata(a, d, N, itemtype = 'dich')
dat2 &lt;- simdata(a, d, N*2, itemtype = 'dich', mu = .5, sigma = matrix(1.5))
dat &lt;- rbind(dat1, dat2)
SIBTEST(dat, group, 6:30)
SIBTEST(dat, group, 11:30)

# DIF testing with anchors 1 through 5
SIBTEST(dat, group, 6, match_set = 1:5)
SIBTEST(dat, group, 7, match_set = 1:5)
SIBTEST(dat, group, 8, match_set = 1:5)

# DIF testing with all other items as anchors
SIBTEST(dat, group, 6)
SIBTEST(dat, group, 7)
SIBTEST(dat, group, 8)

## -------------
## systematic differing slopes and intercepts (clear DTF)
dat1 &lt;- simdata(a, d, N, itemtype = 'dich')
dat2 &lt;- simdata(a + c(numeric(15), rnorm(n-15, 1, .25)), d + c(numeric(15), rnorm(n-15, 1, 1)),
  N*2, itemtype = 'dich')
dat &lt;- rbind(dat1, dat2)
SIBTEST(dat, group, 6:30)
SIBTEST(dat, group, 11:30)

# Some plots depicting the above tests
SIBTEST(dat, group, suspect_set = 11:30, plot = 'observed')
SIBTEST(dat, group, suspect_set = 11:30, plot = 'weights')
SIBTEST(dat, group, suspect_set = 11:30, plot = 'wdifference')

# DIF testing using valid anchors
SIBTEST(dat, group, suspect_set = 6, match_set = 1:5)
SIBTEST(dat, group, suspect_set = 7, match_set = 1:5)
SIBTEST(dat, group, suspect_set = 30, match_set = 1:5)

# test DIF using specific match_set
SIBTEST(dat, group, suspect_set = 6:30, match_set = 1:5, DIF=TRUE)

# test DIF using all-other-as-anchors method (not typically recommended)
SIBTEST(dat, group, suspect_set = 1:30, DIF=TRUE)

# randomization method is fairly poor when smaller matched-set used
SIBTEST(dat, group, suspect_set = 30, match_set = 1:5, randomize=TRUE)
SIBTEST(dat, group, suspect_set = 30, randomize=TRUE)

## ----------------------------------
# three group SIBTEST test
set.seed(1234)
n &lt;- 30
N &lt;- 1000
a &lt;- matrix(1, n)
d &lt;- matrix(rnorm(n), n)
group &lt;- c(rep('group1', N), rep('group2', N), rep('group3', N))

# groups completely equal
dat1 &lt;- simdata(a, d, N, itemtype = 'dich')
dat2 &lt;- simdata(a, d, N, itemtype = 'dich')
dat3 &lt;- simdata(a, d, N, itemtype = 'dich')
dat &lt;- rbind(dat1, dat2, dat3)

# omnibus test using effects-coding contrast matrix (default)
SIBTEST(dat, group, suspect_set = 6)
SIBTEST(dat, group, suspect_set = 6, randomize=TRUE)

# explicit contrasts
SIBTEST(dat, group, suspect_set = 6, randomize=TRUE,
        C = matrix(c(1,-1,0), 1))

# test all items for DIF
SIBTEST(dat, group, suspect_set = 1:ncol(dat), DIF=TRUE)
SIBTEST(dat, group, suspect_set = 16:ncol(dat), DIF=TRUE,
        match_set = 1:15) # specific anchors

# post-hoc between two groups only
pick &lt;- group %in% c('group1', 'group2')
SIBTEST(subset(dat, pick), group[pick], suspect_set = 1:ncol(dat), DIF=TRUE)

# post-hoc pairwise comparison for all groups
SIBTEST(dat, group, suspect_set = 1:ncol(dat), DIF=TRUE, pairwise = TRUE)

## systematic differing slopes and intercepts
dat2 &lt;- simdata(a + c(numeric(15), .5,.5,.5,.5,.5, numeric(10)),
        d + c(numeric(15), 0,.6,.7,.8,.9, numeric(10)),
        N, itemtype = 'dich')
dat &lt;- rbind(dat1, dat2, dat3)

SIBTEST(dat, group, suspect_set = 16)
SIBTEST(dat, group, suspect_set = 16, randomize=TRUE)

SIBTEST(dat, group, suspect_set = 19)
SIBTEST(dat, group, suspect_set = 19, randomize=TRUE)

SIBTEST(dat, group, suspect_set = c(16, 19), DIF=TRUE)
SIBTEST(dat, group, suspect_set = c(16, 19), DIF=TRUE, pairwise=TRUE)



## End(Not run)
</code></pre>


</div>