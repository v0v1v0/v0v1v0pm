<div class="container">

<table style="width: 100%;"><tr>
<td>DIF</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Differential item functioning statistics</h2>

<h3>Description</h3>

<p>This function runs the Wald and likelihood-ratio approaches for testing differential
item functioning (DIF) with two or more groups. This is primarily a convenience wrapper to the
<code>multipleGroup</code> function for performing standard DIF procedures. Independent
models can be estimated in parallel by defining a parallel object with <code>mirtCluster</code>,
which will help to decrease the runtime. For best results, the baseline model should contain
a set of 'anchor' items and have freely estimated hyper-parameters in the focal groups.
</p>


<h3>Usage</h3>

<pre><code class="language-R">DIF(
  MGmodel,
  which.par,
  scheme = "add",
  items2test = 1:extract.mirt(MGmodel, "nitems"),
  groups2test = "all",
  seq_stat = "SABIC",
  Wald = FALSE,
  p.adjust = "none",
  pairwise = FALSE,
  return_models = FALSE,
  return_seq_model = FALSE,
  max_run = Inf,
  plotdif = FALSE,
  type = "trace",
  simplify = TRUE,
  verbose = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>MGmodel</code></td>
<td>
<p>an object returned from <code>multipleGroup</code> to be used as the reference
model</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>which.par</code></td>
<td>
<p>a character vector containing the parameter names which will be inspected for
DIF</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>scheme</code></td>
<td>
<p>type of DIF analysis to perform, either by adding or dropping constraints across
groups. These can be:
</p>

<dl>
<dt>'add'</dt>
<dd>
<p>parameters in <code>which.par</code> will be constrained each item one at a time for
items that are specified in <code>items2test</code>. This is beneficial when examining DIF from a
model with parameters freely estimated across groups, and when inspecting differences via
the Wald test</p>
</dd>
<dt>'drop'</dt>
<dd>
<p>parameters in <code>which.par</code> will be freely estimated for items that are
specified in <code>items2test</code>. This is useful when supplying an overly restrictive model
and attempting to detect DIF with a slightly less restrictive model</p>
</dd>
<dt>'add_sequential'</dt>
<dd>
<p>sequentially loop over the items being tested, and at the end of the
loop treat DIF tests that satisfy the <code>seq_stat</code> criteria as invariant. The loop is
then re-run on the remaining invariant items to determine if they are now displaying DIF in
the less constrained model, and when no new invariant item is found the algorithm stops and
returns the items that displayed DIF. Note that the DIF statistics are relative to this final,
less constrained model which includes the DIF effects</p>
</dd>
<dt>'drop_sequential'</dt>
<dd>
<p>sequentially loop over the items being tested, and at the end of the
loop treat items that violate the <code>seq_stat</code> criteria as demonstrating DIF. The loop is
then re-run, leaving the items that previously demonstrated DIF as variable across groups,
and the remaining test items that previously showed invariance are re-tested. The algorithm
stops when no more items showing DIF are found and returns the items that displayed DIF.
Note that the DIF statistics are relative to this final,
less constrained model which includes the DIF effects</p>
</dd>
</dl>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>items2test</code></td>
<td>
<p>a numeric vector, or character vector containing the item names, indicating
which items will be tested for DIF. In models where anchor items are known, omit them from
this vector. For example, if items 1 and 2 are anchors in a 10 item test, then
<code>items2test = 3:10</code> would work for testing the remaining items (important to remember
when using sequential schemes)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>groups2test</code></td>
<td>
<p>a character vector indicating which groups to use in the DIF testing
investigations. Default is <code>'all'</code>, which uses all group information to perform
joint hypothesis tests of DIF (for a two group setup these result in pair-wise tests).
For example, if the group names were 'g1', 'g2' and 'g3', and DIF was only to be investigated
between group 'g1' and 'g3' then pass <code>groups2test = c('g1', 'g3')</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>seq_stat</code></td>
<td>
<p>select a statistic to test for in the sequential schemes. Potential values are
(in descending order of power) <code>'AIC'</code>, <code>'SABIC'</code>, <code>'HQ'</code>, and <code>'BIC'</code>.
If a numeric value is input that ranges between 0 and 1, the 'p' value will be tested
(e.g., <code>seq_stat = .05</code> will test for the difference of p &lt; .05 in the add scheme,
or p &gt; .05 in the drop scheme), along with the specified <code>p.adjust</code> input</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Wald</code></td>
<td>
<p>logical; perform Wald tests for DIF instead of likelihood ratio test?</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>p.adjust</code></td>
<td>
<p>string to be passed to the <code>p.adjust</code> function to adjust p-values.
Adjustments are located in the <code>adj_p</code> element in the returned list</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pairwise</code></td>
<td>
<p>logical; perform pairwise tests between groups when the number of groups
is greater than 2? Useful as quickly specified post-hoc tests</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>return_models</code></td>
<td>
<p>logical; return estimated model objects for further analysis?
Default is FALSE</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>return_seq_model</code></td>
<td>
<p>logical; on the last iteration of the sequential schemes, return
the fitted multiple-group model containing the freely estimated parameters indicative of
DIF? This is generally only useful when <code>scheme = 'add_sequential'</code>. Default is FALSE</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>max_run</code></td>
<td>
<p>a number indicating the maximum number of cycles to perform in sequential
searches. The default is to perform search until no further DIF is found</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>plotdif</code></td>
<td>
<p>logical; create item plots for items that are displaying DIF according to the
<code>seq_stat</code> criteria? Only available for 'add' type schemes</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>type</code></td>
<td>
<p>the <code>type</code> of plot argument passed to <code>plot()</code>. Default is 'trace', though
another good option is 'infotrace'. For ease of viewing, the <code>facet_item</code> argument to
mirt's <code>plot()</code> function is set to <code>TRUE</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>simplify</code></td>
<td>
<p>logical; simplify the output by returning a data.frame object with
the differences between AIC, BIC, etc, as well as the chi-squared test (X2) and associated
df and p-values</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>
<p>logical print extra information to the console?</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>additional arguments to be passed to <code>multipleGroup</code> and <code>plot</code></p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Generally, the precomputed baseline model should have been
configured with two estimation properties: 1) a set of 'anchor' items,
where the anchor items have various parameters that have been constrained to be equal
across the groups, and 2) contain freely estimated latent mean and variance terms in
all but one group (the so-called 'reference' group).
These two properties help to fix the metric of the groups so that
item parameter estimates do not contain latent distribution characteristics.
</p>


<h3>Value</h3>

<p>a <code>mirt_df</code> object with the information-based criteria for DIF, though this may be changed
to a list output when <code>return_models</code> or <code>simplify</code> are modified. As well, a silent
<code>'DIF_coefficeints'</code> attribute is included to view the item parameter differences
between the groups
</p>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R., P. (2012). mirt: A Multidimensional Item Response Theory
Package for the R Environment. <em>Journal of Statistical Software, 48</em>(6), 1-29.
<a href="https://doi.org/10.18637/jss.v048.i06">doi:10.18637/jss.v048.i06</a>
</p>
<p>Chalmers, R. P., Counsell, A., and Flora, D. B. (2016). It might not
make a big DIF: Improved Differential Test Functioning statistics that account for
sampling variability. <em>Educational and Psychological Measurement, 76</em>, 114-140.
<a href="https://doi.org/10.1177/0013164415584576">doi:10.1177/0013164415584576</a>
</p>


<h3>See Also</h3>

<p><code>multipleGroup</code>, <code>DRF</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Not run: 

# simulate data where group 2 has a smaller slopes and more extreme intercepts
set.seed(12345)
a1 &lt;- a2 &lt;- matrix(abs(rnorm(15,1,.3)), ncol=1)
d1 &lt;- d2 &lt;- matrix(rnorm(15,0,.7),ncol=1)
a2[1:2, ] &lt;- a1[1:2, ]/3
d1[c(1,3), ] &lt;- d2[c(1,3), ]/4
head(data.frame(a.group1 = a1, a.group2 = a2, d.group1 = d1, d.group2 = d2))
itemtype &lt;- rep('2PL', nrow(a1))
N &lt;- 1000
dataset1 &lt;- simdata(a1, d1, N, itemtype)
dataset2 &lt;- simdata(a2, d2, N, itemtype, mu = .1, sigma = matrix(1.5))
dat &lt;- rbind(dataset1, dataset2)
group &lt;- c(rep('D1', N), rep('D2', N))

#### no anchors, all items tested for DIF by adding item constrains one item at a time.
# define a parallel cluster (optional) to help speed up internal functions
if(interactive()) mirtCluster()

# Information matrix with Oakes' identity (not controlling for latent group differences)
# NOTE: Without properly equating the groups the following example code is not testing for DIF,
     # but instead reflects a combination of DIF + latent-trait distribution effects
model &lt;- multipleGroup(dat, 1, group, SE = TRUE)

# Likelihood-ratio test for DIF (as well as model information)
dif &lt;- DIF(model, c('a1', 'd'))
dif

# function silently includes "DIF_coefficients" attribute to view
# the IRT parameters post-completion
extract.mirt(dif, "DIF_coefficients")

# same as above, but using Wald tests with Benjamini &amp; Hochberg adjustment
DIF(model, c('a1', 'd'), Wald = TRUE, p.adjust = 'fdr')

# equate the groups by assuming the last 5 items have no DIF
itemnames &lt;- colnames(dat)
model &lt;- multipleGroup(dat, 1, group, SE = TRUE,
   invariance = c(itemnames[11:ncol(dat)], 'free_means', 'free_var'))

# test whether adding slopes and intercepts constraints results in DIF. Plot items showing DIF
resulta1d &lt;- DIF(model, c('a1', 'd'), plotdif = TRUE, items2test=1:10)
resulta1d

# test whether adding only slope constraints results in DIF for all items
DIF(model, 'a1', items2test=1:10)

# Determine whether it's a1 or d parameter causing DIF (could be joint, however)
(a1s &lt;- DIF(model, 'a1', items2test = 1:3))
(ds &lt;- DIF(model, 'd', items2test = 1:3))

### drop down approach (freely estimating parameters across groups) when
### specifying a highly constrained model with estimated latent parameters
model_constrained &lt;- multipleGroup(dat, 1, group,
  invariance = c(colnames(dat), 'free_means', 'free_var'))
dropdown &lt;- DIF(model_constrained, c('a1', 'd'), scheme = 'drop')
dropdown

# View silent "DIF_coefficients" attribute
extract.mirt(dropdown, "DIF_coefficients")

### sequential schemes (add constraints)

### sequential searches using SABIC as the selection criteria
# starting from completely different models
stepup &lt;- DIF(model, c('a1', 'd'), scheme = 'add_sequential',
              items2test=1:10)
stepup

# step down procedure for highly constrained model
stepdown &lt;- DIF(model_constrained, c('a1', 'd'), scheme = 'drop_sequential')
stepdown

# view final MG model (only useful when scheme is 'add_sequential')
updated_mod &lt;- DIF(model, c('a1', 'd'), scheme = 'add_sequential',
               return_seq_model=TRUE)
plot(updated_mod, type='trace')


###################################
# Multi-group example

a1 &lt;- a2 &lt;- a3 &lt;- matrix(abs(rnorm(15,1,.3)), ncol=1)
d1 &lt;- d2 &lt;- d3 &lt;- matrix(rnorm(15,0,.7),ncol=1)
a2[1:2, ] &lt;- a1[1:2, ]/3
d3[c(1,3), ] &lt;- d2[c(1,3), ]/4
head(data.frame(a.group1 = a1, a.group2 = a2, a.group3 = a3,
                d.group1 = d1, d.group2 = d2, d.group3 = d3))
itemtype &lt;- rep('2PL', nrow(a1))
N &lt;- 1000
dataset1 &lt;- simdata(a1, d1, N, itemtype)
dataset2 &lt;- simdata(a2, d2, N, itemtype, mu = .1, sigma = matrix(1.5))
dataset3 &lt;- simdata(a3, d3, N, itemtype, mu = .2)
dat &lt;- rbind(dataset1, dataset2, dataset3)
group &lt;- gl(3, N, labels = c('g1', 'g2', 'g3'))

# equate the groups by assuming the last 5 items have no DIF
itemnames &lt;- colnames(dat)
model &lt;- multipleGroup(dat, group=group, SE=TRUE,
   invariance = c(itemnames[11:ncol(dat)], 'free_means', 'free_var'))
coef(model, simplify=TRUE)

# omnibus tests
dif &lt;- DIF(model, which.par = c('a1', 'd'), items2test=1:9)
dif

# pairwise post-hoc tests for items flagged via omnibus tests
dif.posthoc &lt;- DIF(model, which.par = c('a1', 'd'), items2test=1:2,
                   pairwise = TRUE)
dif.posthoc

# further probing for df = 1 tests, this time with Wald tests
DIF(model, which.par = c('a1'), items2test=1:2, pairwise = TRUE,
    Wald=TRUE)
DIF(model, which.par = c('d'), items2test=1:2, pairwise = TRUE,
    Wald=TRUE)


## End(Not run)
</code></pre>


</div>