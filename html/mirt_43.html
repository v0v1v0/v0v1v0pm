<div class="container">

<table style="width: 100%;"><tr>
<td>itemfit</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Item fit statistics</h2>

<h3>Description</h3>

<p>Computes item-fit statistics for a variety of unidimensional and multidimensional models.
Poorly fitting items should be inspected with the empirical plots/tables
for unidimensional models, otherwise <code>itemGAM</code> can be used to diagnose
where the functional form of the IRT model was misspecified, or models can be refit using
more flexible semi-parametric response models (e.g., <code>itemtype = 'spline'</code>).
If the latent trait density was approximated (e.g., Davidian curves, Empirical histograms, etc)
then passing <code>use_dentype_estimate = TRUE</code> will use the internally saved quadrature and
density components (where applicable). Currently, only S-X2 statistic supported for
mixture IRT models. Finally, where applicable the root mean-square error of approximation (RMSEA)
is reported to help gauge the magnitude of item misfit.
</p>


<h3>Usage</h3>

<pre><code class="language-R">itemfit(
  x,
  fit_stats = "S_X2",
  which.items = 1:extract.mirt(x, "nitems"),
  na.rm = FALSE,
  p.adjust = "none",
  group.bins = 10,
  group.size = NA,
  group.fun = mean,
  mincell = 1,
  mincell.X2 = 2,
  return.tables = FALSE,
  pv_draws = 30,
  boot = 1000,
  boot_dfapprox = 200,
  S_X2.plot = NULL,
  S_X2.plot_raw.score = TRUE,
  ETrange = c(-2, 2),
  ETpoints = 11,
  empirical.plot = NULL,
  empirical.CI = 0.95,
  empirical.poly.collapse = FALSE,
  method = "EAP",
  Theta = NULL,
  par.strip.text = list(cex = 0.7),
  par.settings = list(strip.background = list(col = "#9ECAE1"), strip.border = list(col =
    "black")),
  auto.key = list(space = "right", points = FALSE, lines = TRUE),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>a computed model object of class <code>SingleGroupClass</code>,
<code>MultipleGroupClass</code>, or <code>DiscreteClass</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fit_stats</code></td>
<td>
<p>a character vector indicating which fit statistics should be computed.
Supported inputs are:
</p>

<ul>
<li> <p><code>'S_X2'</code> : Orlando and Thissen (2000, 2003) and
Kang and Chen's (2007) signed chi-squared test (default)
</p>
</li>
<li> <p><code>'Zh'</code> : Drasgow, Levine, &amp; Williams (1985) Zh
</p>
</li>
<li> <p><code>'X2'</code> : Bock's (1972) chi-squared method.
The default inputs compute Yen's (1981) Q1 variant of the X2 statistic
(i.e., uses a fixed <code>group.bins = 10</code>). However, Bock's group-size variable
median-based method can be computed by passing <code>group.fun = median</code> and
modifying the <code>group.size</code> input to the desired number of bins
</p>
</li>
<li> <p><code>'G2'</code> : McKinley &amp; Mills (1985) G2 statistic (similar method to Q1,
but with the likelihood-ratio test).
</p>
</li>
<li> <p><code>'PV_Q1'</code> : Chalmers and Ng's (2017) plausible-value variant
of the Q1 statistic.
</p>
</li>
<li> <p><code>'PV_Q1*'</code> : Chalmers and Ng's (2017) plausible-value variant
of the Q1 statistic that uses parametric bootstrapping to obtain a suitable empirical
distribution.
</p>
</li>
<li> <p><code>'X2*'</code> : Stone's (2000) fit statistics that require parametric
bootstrapping
</p>
</li>
<li> <p><code>'X2*_df'</code> : Stone's (2000) fit statistics that require parametric
bootstrapping to obtain scaled versions of the X2* and degrees of freedom
</p>
</li>
<li> <p><code>'infit'</code> : Compute the infit and outfit statistics
</p>
</li>
</ul>
<p>Note that 'S_X2' and 'Zh' cannot be computed when there are missing response data
(i.e., will require multiple-imputation/row-removal techniques).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>which.items</code></td>
<td>
<p>an integer vector indicating which items to test for fit.
Default tests all possible items</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>na.rm</code></td>
<td>
<p>logical; remove rows with any missing values? This is required for methods such
as S-X2 because they require the "EAPsum" method from <code>fscores</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>p.adjust</code></td>
<td>
<p>method to use for adjusting all p-values for each respective item fit
statistic (see <code>p.adjust</code> for available options). Default is <code>'none'</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>group.bins</code></td>
<td>
<p>the number of bins to use for X2 and G2. For example,
setting <code>group.bins = 10</code> will will compute Yen's (1981) Q1 statistic when <code>'X2'</code> is
requested</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>group.size</code></td>
<td>
<p>approximate size of each group to be used in calculating the <code class="reqn">\chi^2</code>
statistic. The default <code>NA</code>
disables this command and instead uses the <code>group.bins</code> input to try and construct
equally sized bins</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>group.fun</code></td>
<td>
<p>function used when <code>'X2'</code> or <code>'G2'</code> are computed. Determines the central
tendency measure within each partitioned group. E.g., setting <code>group.fun = median</code> will
obtain the median of each respective ability estimate in each subgroup (this is what was used
by Bock, 1972)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mincell</code></td>
<td>
<p>the minimum expected cell size to be used in the S-X2 computations. Tables will be
collapsed across items first if polytomous, and then across scores if necessary</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mincell.X2</code></td>
<td>
<p>the minimum expected cell size to be used in the X2 computations. Tables will be
collapsed if polytomous, however if this condition can not be met then the group block will
be omitted in the computations</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>return.tables</code></td>
<td>
<p>logical; return tables when investigating <code>'X2'</code>, <code>'S_X2'</code>,
and <code>'X2*'</code>?</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pv_draws</code></td>
<td>
<p>number of plausible-value draws to obtain for PV_Q1 and PV_Q1*</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>boot</code></td>
<td>
<p>number of parametric bootstrap samples to create for PV_Q1* and X2*</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>boot_dfapprox</code></td>
<td>
<p>number of parametric bootstrap samples to create for the X2*_df statistic
to approximate the scaling factor for X2* as well as the scaled degrees of freedom estimates</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>S_X2.plot</code></td>
<td>
<p>argument input is the same as <code>empirical.plot</code>, however the resulting image
is constructed according to the S-X2 statistic's conditional sum-score information</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>S_X2.plot_raw.score</code></td>
<td>
<p>logical; use the raw-score information in the plot in stead of the latent
trait scale score? Default is <code>FALSE</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ETrange</code></td>
<td>
<p>rangone of integration nodes for Stone's X2* statistic</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ETpoints</code></td>
<td>
<p>number of integration nodes to use for Stone's X2* statistic</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>empirical.plot</code></td>
<td>
<p>a single numeric value or character of the item name indicating which
item to plot (via <code>itemplot</code>) and overlay with the empirical <code class="reqn">\theta</code> groupings (see
<code>empirical.CI</code>). Useful for plotting the expected bins based on the <code>'X2'</code> or
<code>'G2'</code> method</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>empirical.CI</code></td>
<td>
<p>a numeric value indicating the width of the empirical confidence interval
ranging between 0 and 1 (default of 0 plots not interval). For example, a 95
interval would be plotted when <code>empirical.CI = .95</code>. Only applicable to dichotomous items</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>empirical.poly.collapse</code></td>
<td>
<p>logical; collapse polytomous item categories to for expected scoring
functions for empirical plots? Default is <code>FALSE</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p>type of factor score estimation method. See <code>fscores</code> for more detail</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Theta</code></td>
<td>
<p>a matrix of factor scores for each person used for statistics that require
empirical estimates. If supplied, arguments typically passed to <code>fscores()</code> will be
ignored and these values will be used instead. Also required when estimating statistics
with missing data via imputation</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>par.strip.text</code></td>
<td>
<p>plotting argument passed to <code>lattice</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>par.settings</code></td>
<td>
<p>plotting argument passed to <code>lattice</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>auto.key</code></td>
<td>
<p>plotting argument passed to <code>lattice</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>additional arguments to be passed to <code>fscores()</code> and <code>lattice</code></p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Bock, R. D. (1972). Estimating item parameters and latent ability when responses are scored
in two or more nominal categories. <em>Psychometrika, 37</em>, 29-51.
</p>
<p>Chalmers, R., P. (2012). mirt: A Multidimensional Item Response Theory
Package for the R Environment. <em>Journal of Statistical Software, 48</em>(6), 1-29.
<a href="https://doi.org/10.18637/jss.v048.i06">doi:10.18637/jss.v048.i06</a>
</p>
<p>Chalmers, R. P. &amp; Ng, V. (2017). Plausible-Value Imputation Statistics for Detecting
Item Misfit. <em>Applied Psychological Measurement, 41</em>, 372-387.
<a href="https://doi.org/10.1177/0146621617692079">doi:10.1177/0146621617692079</a>
</p>
<p>Drasgow, F., Levine, M. V., &amp; Williams, E. A. (1985). Appropriateness measurement with
polychotomous item response models and standardized indices.
<em>British Journal of Mathematical and Statistical Psychology, 38</em>, 67-86.
</p>
<p>Kang, T. &amp; Chen, Troy, T. (2007). An investigation of the performance of the generalized
S-X2 item-fit index for polytomous IRT models. ACT
</p>
<p>McKinley, R., &amp; Mills, C. (1985). A comparison of several goodness-of-fit statistics.
Applied Psychological Measurement, 9, 49-57.
</p>
<p>Orlando, M. &amp; Thissen, D. (2000). Likelihood-based item fit indices for dichotomous item
response theory models. <em>Applied Psychological Measurement, 24</em>, 50-64.
</p>
<p>Reise, S. P. (1990). A comparison of item- and person-fit methods of assessing model-data fit
in IRT. <em>Applied Psychological Measurement, 14</em>, 127-137.
</p>
<p>Stone, C. A. (2000). Monte Carlo Based Null Distribution for an Alternative Goodness-of-Fit
Test Statistics in IRT Models. <em>Journal of Educational Measurement, 37</em>, 58-75.
</p>
<p>Wright B. D. &amp; Masters, G. N. (1982). <em>Rating scale analysis</em>. MESA Press.
</p>
<p>Yen, W. M. (1981). Using simulation results to choose a latent trait model.
<em>Applied Psychological Measurement, 5</em>, 245-262.
</p>


<h3>See Also</h3>

<p><code>personfit</code>, <code>itemGAM</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">
## Not run: 

P &lt;- function(Theta){exp(Theta^2 * 1.2 - 1) / (1 + exp(Theta^2 * 1.2 - 1))}

#make some data
set.seed(1234)
a &lt;- matrix(rlnorm(20, meanlog=0, sdlog = .1),ncol=1)
d &lt;- matrix(rnorm(20),ncol=1)
Theta &lt;- matrix(rnorm(2000))
items &lt;- rep('2PL', 20)
ps &lt;- P(Theta)
baditem &lt;- numeric(2000)
for(i in 1:2000)
   baditem[i] &lt;- sample(c(0,1), 1, prob = c(1-ps[i], ps[i]))
data &lt;- cbind(simdata(a,d, 2000, items, Theta=Theta), baditem=baditem)

x &lt;- mirt(data, 1)
raschfit &lt;- mirt(data, 1, itemtype='Rasch')
fit &lt;- itemfit(x)
fit

# p-value adjustment
itemfit(x, p.adjust='fdr')

# two different fit stats (with/without p-value adjustment)
itemfit(x, c('S_X2' ,'X2'), p.adjust='fdr')
itemfit(x, c('S_X2' ,'X2'))

# Conditional sum-score plot from S-X2 information
itemfit(x, S_X2.plot = 1) # good fit
itemfit(x, S_X2.plot = 2) # good fit
itemfit(x, S_X2.plot = 21) # bad fit

itemfit(x, 'X2') # just X2
itemfit(x, 'X2', method = 'ML') # X2 with maximum-likelihood estimates for traits
itemfit(x, group.bins=15, empirical.plot = 1, method = 'ML') #empirical item plot with 15 points
itemfit(x, group.bins=15, empirical.plot = 21, method = 'ML')

# PV and X2* statistics (parametric bootstrap stats not run to save time)
itemfit(x, 'PV_Q1')

if(interactive()) mirtCluster() # improve speed of bootstrap samples by running in parallel
# itemfit(x, 'PV_Q1*')
# itemfit(x, 'X2*') # Stone's 1993 statistic
# itemfit(x, 'X2*_df') # Stone's 2000 scaled statistic with df estimate

# empirical tables for X2 statistic
tabs &lt;- itemfit(x, 'X2', return.tables=TRUE, which.items = 1)
tabs

#infit/outfit statistics. method='ML' agrees better with eRm package
itemfit(raschfit, 'infit', method = 'ML') #infit and outfit stats

#same as above, but inputting ML estimates instead (saves time for re-use)
Theta &lt;- fscores(raschfit, method = 'ML')
itemfit(raschfit, 'infit', Theta=Theta)
itemfit(raschfit, empirical.plot=1, Theta=Theta)
itemfit(raschfit, 'X2', return.tables=TRUE, Theta=Theta, which.items=1)

# fit a new more flexible model for the mis-fitting item
itemtype &lt;- c(rep('2PL', 20), 'spline')
x2 &lt;- mirt(data, 1, itemtype=itemtype)
itemfit(x2)
itemplot(x2, 21)
anova(x, x2)

#------------------------------------------------------------

#similar example to Kang and Chen 2007
a &lt;- matrix(c(.8,.4,.7, .8, .4, .7, 1, 1, 1, 1))
d &lt;- matrix(rep(c(2.0,0.0,-1,-1.5),10), ncol=4, byrow=TRUE)
dat &lt;- simdata(a,d,2000, itemtype = rep('graded', 10))
head(dat)

mod &lt;- mirt(dat, 1)
itemfit(mod)
itemfit(mod, 'X2') # less useful given inflated Type I error rates
itemfit(mod, empirical.plot = 1)
itemfit(mod, empirical.plot = 1, empirical.poly.collapse=TRUE)

# collapsed tables (see mincell.X2) for X2 and G2
itemfit(mod, 'X2', return.tables = TRUE, which.items = 1)

mod2 &lt;- mirt(dat, 1, 'Rasch')
itemfit(mod2, 'infit', method = 'ML')

# massive list of tables for S-X2
tables &lt;- itemfit(mod, return.tables = TRUE)

#observed and expected total score patterns for item 1 (post collapsing)
tables$O[[1]]
tables$E[[1]]

# can also select specific items
# itemfit(mod, return.tables = TRUE, which.items=1)

# fit stats with missing data (run in parallel using all cores)
dat[sample(1:prod(dim(dat)), 100)] &lt;- NA
raschfit &lt;- mirt(dat, 1, itemtype='Rasch')

# use only valid data by removing rows with missing terms
itemfit(raschfit, c('S_X2', 'infit'), na.rm = TRUE)

# note that X2, G2, PV-Q1, and X2* do not require complete datasets
thetas &lt;- fscores(raschfit, method = 'ML') # save for faster computations
itemfit(raschfit, c('X2', 'G2'), Theta=thetas)
itemfit(raschfit, empirical.plot=1, Theta=thetas)
itemfit(raschfit, 'X2', return.tables=TRUE, which.items=1, Theta=thetas)


## End(Not run)

</code></pre>


</div>