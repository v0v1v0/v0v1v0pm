<div class="container">

<table style="width: 100%;"><tr>
<td>PLCI.mirt</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Compute profiled-likelihood (or posterior) confidence intervals</h2>

<h3>Description</h3>

<p>Computes profiled-likelihood based confidence intervals. Supports the inclusion of
equality constraints. Object returns the confidence intervals
and whether the respective interval could be found.
</p>


<h3>Usage</h3>

<pre><code class="language-R">PLCI.mirt(
  mod,
  parnum = NULL,
  alpha = 0.05,
  search_bound = TRUE,
  step = 0.5,
  lower = TRUE,
  upper = TRUE,
  inf2val = 30,
  NealeMiller = FALSE,
  verbose = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>mod</code></td>
<td>
<p>a converged mirt model</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>parnum</code></td>
<td>
<p>a numeric vector indicating which parameters to estimate.
Use <code>mod2values</code> to determine parameter numbers. If <code>NULL</code>, all possible
parameters are used</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alpha</code></td>
<td>
<p>two-tailed alpha critical level</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>search_bound</code></td>
<td>
<p>logical; use a fixed grid of values around the ML estimate to
determine more suitable optimization bounds? Using this has much better behaviour
than setting fixed upper/lower bound values and searching from more extreme ends</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>step</code></td>
<td>
<p>magnitude of steps used when <code>search_bound</code> is <code>TRUE</code>.
Smaller values create more points to search a suitable bound for (up to the
lower bound value visible with <code>mod2values</code>). When upper/lower bounds are detected
this value will be adjusted accordingly</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lower</code></td>
<td>
<p>logical; search for the lower CI?</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>upper</code></td>
<td>
<p>logical; search for the upper CI?</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>inf2val</code></td>
<td>
<p>a numeric used to change parameter bounds which are infinity to a finite number.
Decreasing this too much may not allow a suitable bound to be located. Default is 30</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>NealeMiller</code></td>
<td>
<p>logical; use the Neale and Miller 1997 approximation? Default is <code>FALSE</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>
<p>logical; include additional information in the console?</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>additional arguments to pass to the estimation functions</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R., P. (2012). mirt: A Multidimensional Item Response Theory
Package for the R Environment. <em>Journal of Statistical Software, 48</em>(6), 1-29.
<a href="https://doi.org/10.18637/jss.v048.i06">doi:10.18637/jss.v048.i06</a>
</p>
<p>Chalmers, R. P., Pek, J., &amp; Liu, Y. (2017). Profile-likelihood Confidence
Intervals in Item Response Theory Models. <em>Multivariate Behavioral Research, 52</em>, 533-550.
<a href="https://doi.org/10.1080/00273171.2017.1329082">doi:10.1080/00273171.2017.1329082</a>
</p>
<p>Neale, M. C. &amp; Miller, M. B. (1997). The use of likelihood-based confidence intervals in genetic
models. <em>Behavior Genetics, 27</em>, 113-120.
</p>


<h3>See Also</h3>

<p><code>boot.mirt</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">
## Not run: 
if(interactive()) mirtCluster() #use all available cores to estimate CI's in parallel
dat &lt;- expand.table(LSAT7)
mod &lt;- mirt(dat, 1)

result &lt;- PLCI.mirt(mod)
result

# model with constraints
mod &lt;- mirt(dat, 'F = 1-5
                  CONSTRAIN = (1-5, a1)')

result &lt;- PLCI.mirt(mod)
result

mod2 &lt;- mirt(Science, 1)
result2 &lt;- PLCI.mirt(mod2)
result2

# only estimate CI's slopes
sv &lt;- mod2values(mod2)
parnum &lt;- sv$parnum[sv$name == 'a1']
result3 &lt;- PLCI.mirt(mod2, parnum)
result3


## End(Not run)
</code></pre>


</div>