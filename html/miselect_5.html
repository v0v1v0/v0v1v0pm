<div class="container">

<table style="width: 100%;"><tr>
<td>cv.galasso</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Cross Validated Multiple Imputation Grouped Adaptive LASSO</h2>

<h3>Description</h3>

<p>Does k-fold cross-validation for <code>galasso</code>, and returns an optimal value
for lambda.
</p>


<h3>Usage</h3>

<pre><code class="language-R">cv.galasso(
  x,
  y,
  pf,
  adWeight,
  family = c("gaussian", "binomial"),
  nlambda = 100,
  lambda.min.ratio = ifelse(isTRUE(all.equal(adWeight, rep(1, p))), 0.001, 1e-06),
  lambda = NULL,
  nfolds = 5,
  foldid = NULL,
  maxit = 1000,
  eps = 1e-05
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>A length <code>m</code> list of <code>n * p</code> numeric matrices. No matrix
should contain an intercept, or any missing values</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>A length <code>m</code> list of length <code>n</code> numeric response vectors.
No vector should contain missing values</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pf</code></td>
<td>
<p>Penalty factor. Can be used to differentially penalize certain
variables</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>adWeight</code></td>
<td>
<p>Numeric vector of length p representing the adaptive weights
for the L1 penalty</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>family</code></td>
<td>
<p>The type of response. "gaussian" implies a continuous response
and "binomial" implies a binary response. Default is "gaussian".</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nlambda</code></td>
<td>
<p>Length of automatically generated "lambda" sequence. If
"lambda" is non NULL, "nlambda" is ignored. Default is 100</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda.min.ratio</code></td>
<td>
<p>Ratio that determines the minimum value of "lambda"
when automatically generating a "lambda" sequence. If "lambda" is not
NULL, "lambda.min.ratio" is ignored. Default is 1e-4</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda</code></td>
<td>
<p>Optional numeric vector of lambdas to fit. If NULL,
<code>galasso</code> will automatically generate a lambda sequence based off
of <code>nlambda</code> and <code>lambda.min.ratio</code>. Default is NULL</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nfolds</code></td>
<td>
<p>Number of foldid to use for cross validation. Default is 5,
minimum is 3</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>foldid</code></td>
<td>
<p>an optional length <code>n</code> vector of values between 1 and
<code>cv.galasso</code> will automatically generate folds</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>maxit</code></td>
<td>
<p>Maximum number of iterations to run. Default is 10000</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>eps</code></td>
<td>
<p>Tolerance for convergence. Default is 1e-5</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p><code>cv.galasso</code> works by adding a group penalty to the aggregated objective
function to ensure selection consistency across imputations. Simulations
suggest that the "stacked" objective function approaches (i.e., <code>saenet</code>)
tend to be more computationally efficient and have better estimation and
selection properties.
</p>


<h3>Value</h3>

<p>An object of type "cv.galasso" with 7 elements:
</p>

<dl>
<dt>call</dt>
<dd>
<p>The call that generated the output.</p>
</dd>
<dt>lambda</dt>
<dd>
<p>The sequence of lambdas fit.</p>
</dd>
<dt>cvm</dt>
<dd>
<p>Average cross validation error for each "lambda". For
family = "gaussian", "cvm" corresponds to mean squared error,
and for binomial "cvm" corresponds to deviance.</p>
</dd>
<dt>cvse</dt>
<dd>
<p>Standard error of "cvm".</p>
</dd>
<dt>galasso.fit</dt>
<dd>
<p>A "galasso" object fit to the full data.</p>
</dd>
<dt>lambda.min</dt>
<dd>
<p>The lambda value for the model with the minimum cross
validation error.</p>
</dd>
<dt>lambda.1se</dt>
<dd>
<p>The lambda value for the  sparsest model within one
standard error of the minimum cross validation error.</p>
</dd>
<dt>df</dt>
<dd>
<p>The number of nonzero coefficients for each value of lambda.</p>
</dd>
</dl>
<h3>References</h3>

<p>Du, J., Boss, J., Han, P., Beesley, L. J., Kleinsasser, M., Goutman, S. A., ... 
&amp; Mukherjee, B. (2022). Variable selection with multiply-imputed datasets: 
choosing between stacked and grouped methods. Journal of Computational and 
Graphical Statistics, 31(4), 1063-1075. &lt;doi:10.1080/10618600.2022.2035739&gt;
</p>


<h3>Examples</h3>

<pre><code class="language-R">
library(miselect)
library(mice)

set.seed(48109)

# Using the mice defaults for sake of example only.
mids &lt;- mice(miselect.df, m = 5, printFlag = FALSE)
dfs &lt;- lapply(1:5, function(i) complete(mids, action = i))

# Generate list of imputed design matrices and imputed responses
x &lt;- list()
y &lt;- list()
for (i in 1:5) {
    x[[i]] &lt;- as.matrix(dfs[[i]][, paste0("X", 1:20)])
    y[[i]] &lt;- dfs[[i]]$Y
}

pf       &lt;- rep(1, 20)
adWeight &lt;- rep(1, 20)

fit &lt;- cv.galasso(x, y, pf, adWeight)

# By default 'coef' returns the betas for lambda.min.
coef(fit)

</code></pre>


</div>