<div class="container">

<table style="width: 100%;"><tr>
<td>AKMCS</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Active learning reliability method combining Kriging and Monte Carlo
Simulation</h2>

<h3>Description</h3>

<p>Estimate a failure probability with the AKMCS method.
</p>


<h3>Usage</h3>

<pre><code class="language-R">AKMCS(
  dimension,
  lsf,
  N = 5e+05,
  N1 = 10 * dimension,
  Nmax = 200,
  Nmin = 2,
  X = NULL,
  y = NULL,
  failure = 0,
  precision = 0.05,
  bayesian = TRUE,
  compute.PPP = FALSE,
  meta_model = NULL,
  kernel = "matern5_2",
  learn_each_train = TRUE,
  crit_min = 2,
  lower.tail = TRUE,
  limit_fun_MH = NULL,
  failure_MH = 0,
  sampling_strategy = "MH",
  first_DOE = "Gaussian",
  seeds = NULL,
  seeds_eval = limit_fun_MH(seeds),
  burnin = 30,
  plot = FALSE,
  limited_plot = FALSE,
  add = FALSE,
  output_dir = NULL,
  verbose = 0
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>dimension</code></td>
<td>
<p>dimension of the input space.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lsf</code></td>
<td>
<p>the function defining the failure/safety domain.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>N</code></td>
<td>
<p>Monte-Carlo population size.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>N1</code></td>
<td>
<p>size of the first DOE.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Nmax</code></td>
<td>
<p>maximum number of calls to the LSF.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Nmin</code></td>
<td>
<p>minimum number of calls during enrichment step.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>coordinates of already known points.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>value of the LSF on these points.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>failure</code></td>
<td>
<p>failure threshold.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>precision</code></td>
<td>
<p>maximum desired cov on the Monte-Carlo estimate.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>bayesian</code></td>
<td>
<p>estimate the conditional expectation E_X [ P[meta(X)&lt;failure] ].</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>compute.PPP</code></td>
<td>
<p>to simulate a Poisson process at each iteration to estimate
the conditional expectation and the SUR criteria based on the conditional
variance: h (average probability of misclassification at level <code>failure</code>)
and I (integral of h over the whole interval [failure, infty))</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>meta_model</code></td>
<td>
<p>provide here a kriging metamodel from km if wanted.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>kernel</code></td>
<td>
<p>specify the kernel to use for km.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>learn_each_train</code></td>
<td>
<p>specify if kernel parameters are re-estimated at each train.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>crit_min</code></td>
<td>
<p>minimum value of the criteria to be used for refinement.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lower.tail</code></td>
<td>
<p>as for pxxxx functions, TRUE for estimating P(lsf(X) &lt; failure), FALSE
for P(lsf(X) &gt; failure)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>limit_fun_MH</code></td>
<td>
<p>define an area of exclusion with a limit function.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>failure_MH</code></td>
<td>
<p>the theshold for the limit_fun_MH function.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sampling_strategy</code></td>
<td>
<p>either MH for Metropolis-Hastings of AR for accept-reject.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>first_DOE</code></td>
<td>
<p>either Gaussian or Uniform, to specify the population on which
clustering is done. Set to "No" for no initial DoE (use together with a first DoE
given in <code>X</code> for instance).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>seeds</code></td>
<td>
<p>if some points are already known to be in the appropriate subdomain.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>seeds_eval</code></td>
<td>
<p>value of the metamodel on these points.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>burnin</code></td>
<td>
<p>burnin parameter for MH.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>plot</code></td>
<td>
<p>set to TRUE for a full plot, ie refresh at each iteration.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>limited_plot</code></td>
<td>
<p>set to TRUE for a final plot with final DOE, metamodel and LSF.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>add</code></td>
<td>
<p>if plots are to be added to a current device.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>output_dir</code></td>
<td>
<p>if plots are to be saved in jpeg in a given directory.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>
<p>either 0 for almost no output, 1 for medium size output and 2 for all
outputs.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>AKMCS strategy is based on a original Monte-Carlo population which
is classified
with a kriging-based metamodel. This means that no sampling is done during
refinements
steps. Indeed, it tries to classify this Monte-Carlo population with a
confidence greater
than a given value, for instance ‘distance’ to the failure should be
greater than
<code>crit_min</code> standard deviation.
</p>
<p>Thus, while this criterion is not verified, the point minimizing it is added to
the learning database and then evaluated.
</p>
<p>Finally, once all points are classified or when the maximum number of calls
has been reached, crude Monte-Carlo is performed. A final test controlling
the size of this population regarding the targeted coefficient of variation
is done; if it is too small then a new population of sufficient size
(considering ordre of magnitude of found probability) is generated, and
algorithm run again.
</p>


<h3>Value</h3>

<p>An object of class <code>list</code> containing the failure probability and some
more outputs as described below:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>p</code></td>
<td>
<p>the estimated failure probability.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cov</code></td>
<td>
<p>the coefficient of variation of the Monte-Carlo probability estimate.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Ncall</code></td>
<td>
<p>the total number of calls to the <code>lsf</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>the final learning database, ie. all points where <code>lsf</code> has
been calculated.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>the value of the <code>lsf</code> on the learning database.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>h</code></td>
<td>
<p>the sequence of the estimated relative SUR criteria.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>I</code></td>
<td>
<p>the sequence of the estimated integrated SUR criteria.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>meta_fun</code></td>
<td>
<p>the metamodel approximation of the <code>lsf</code>. A call output is a
list containing the value and the standard deviation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>meta_model</code></td>
<td>
<p>the final metamodel. An S4 object from <span class="pkg">DiceKriging</span>. Note
that the algorithm enforces the problem to be the estimation of P[lsf(X)&lt;failure]
and so using ‘predict’ with this object will return inverse values if
<code>lower.tail==FALSE</code>; in this scope prefer using directly <code>meta_fun</code> which
handles this possible issue.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>points</code></td>
<td>
<p>points in the failure domain according to the metamodel.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>meta_eval</code></td>
<td>
<p>evaluation of the metamodel on these points.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>z_meta</code></td>
<td>
<p>if <code>plot</code>==TRUE, the evaluation of the metamodel on the plot grid.</p>
</td>
</tr>
</table>
<h3>Note</h3>

<p>Problem is supposed to be defined in the standard space. If not,
use <code>UtoX</code> to do so. Furthermore, each time a set of vector
is defined as a matrix, ‘nrow’ = <code>dimension</code> and
‘ncol’ = number of vector to be consistent with <code>as.matrix</code>
transformation of a vector.
</p>
<p>Algorithm calls lsf(X) (where X is a matrix as defined previously) and
expects a vector in return. This allows the user to optimise the computation
of a batch of points, either by vectorial computation, or by the use of
external codes (optimised C or C++ codes for example) and/or parallel
computation; see examples in MonteCarlo.
</p>


<h3>Author(s)</h3>

<p>Clement WALTER <a href="mailto:clementwalter@icloud.com">clementwalter@icloud.com</a>
</p>


<h3>References</h3>


<ul>
<li>
<p>B. Echard, N. Gayton, M. Lemaire:<br><em>AK-MCS : an Active learning reliability method combining Kriging and
Monte Carlo Simulation</em><br>
Structural Safety, Elsevier, 2011.<br></p>
</li>
<li>
<p>B. Echard, N. Gayton, M. Lemaire and N. Relun:<br><em>A combined Importance Sampling and Kriging reliability method for
small failure probabilities with time-demanding numerical models</em><br>
Reliability Engineering and System Safety,2012<br></p>
</li>
<li>
<p>B. Echard, N. Gayton and A. Bignonnet:<br><em>A reliability analysis method for fatigue design</em><br>
International Journal of Fatigue, 2014<br></p>
</li>
</ul>
<h3>See Also</h3>

<p><code>SubsetSimulation</code>
<code>MonteCarlo</code>
<code>MetaIS</code>
<code>km</code> (in package <span class="pkg">DiceKriging</span>)
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Not run: 
res = AKMCS(dimension=2,lsf=kiureghian,plot=TRUE)

#Compare with crude Monte-Carlo reference value
N = 500000
dimension = 2
U = matrix(rnorm(dimension*N),dimension,N)
G = kiureghian(U)
P = mean(G&lt;0)
cov = sqrt((1-P)/(N*P))

## End(Not run)

#See impact of kernel choice with serial function from Waarts:
waarts = function(u) {
  u = as.matrix(u)
  b1 = 3+(u[1,]-u[2,])^2/10 - sign(u[1,] + u[2,])*(u[1,]+u[2,])/sqrt(2)
  b2 = sign(u[2,]-u[1,])*(u[1,]-u[2,])+7/sqrt(2)
  val = apply(cbind(b1, b2), 1, min)
}

## Not run: 
res = list()
res$matern5_2 = AKMCS(2, waarts, plot=TRUE)
res$matern3_2 = AKMCS(2, waarts, kernel="matern3_2", plot=TRUE)
res$gaussian  = AKMCS(2, waarts, kernel="gauss", plot=TRUE)
res$exp       = AKMCS(2, waarts, kernel="exp", plot=TRUE)

#Compare with crude Monte-Carlo reference value
N = 500000
dimension = 2
U = matrix(rnorm(dimension*N),dimension,N)
G = waarts(U)
P = mean(G&lt;0)
cov = sqrt((1-P)/(N*P))

## End(Not run)

</code></pre>


</div>