<div class="container">

<table style="width: 100%;"><tr>
<td>multilevel.r2</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>R-Squared Measures for Multilevel and Linear Mixed Effects Models</h2>

<h3>Description</h3>

<p>This function computes R-squared measures by Raudenbush and Bryk (2002),
Snijders and Bosker (1994), Nakagawa and Schielzeth (2013) as extended by
Johnson (2014), and Rights and Sterba (2019) for multilevel and linear mixed
effects models estimated by using the <code>lmer()</code> function in the package
<span class="pkg">lme4</span> or <code>lme()</code> function in the package <span class="pkg">nlme</span>.
</p>


<h3>Usage</h3>

<pre><code class="language-R">multilevel.r2(model, print = c("all", "RB", "SB", "NS", "RS"), digits = 3,
              plot = FALSE, gray = FALSE, start = 0.15, end = 0.85,
              color = c("#D55E00", "#0072B2", "#CC79A7", "#009E73", "#E69F00"),
              write = NULL, append = TRUE, check = TRUE, output = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>model</code></td>
<td>
<p>a fitted model of class <code>"lmerMod"</code> from the <span class="pkg">lme4</span>
package or <code>"lme"</code> from the <span class="pkg">nlme</span> package.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>print</code></td>
<td>
<p>a character vector indicating which R-squared measures to be
printed on the console, i.e., <code>RB</code> for measures from
Raudenbush and Bryk (2002), <code>SB</code> for measures from Snijders
and Bosker (1994), <code>NS</code> for measures from Nakagawa and
Schielzeth (2013) as extended by Johnson (2014), and <code>RS</code>
for measures from Rights and Sterba (2019). The default setting
is <code>print = "RS"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>digits</code></td>
<td>
<p>an integer value indicating the number of decimal places to be used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>plot</code></td>
<td>
<p>logical: if <code>TRUE</code>, bar chart showing the decomposition of
scaled total, within-cluster, and between-cluster outcome variance
into five (total), three (within-cluster), and two (between-cluster)
proportions is drawn. Note that the <span class="pkg">ggplot2</span> package is required
to draw the bar chart.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>gray</code></td>
<td>
<p>logical: if <code>TRUE</code>, graphical parameter to draw the bar chart
in gray scale.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>start</code></td>
<td>
<p>a numeric value between 0 and 1, graphical parameter to specify
the gray value at the low end of the palette.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>end</code></td>
<td>
<p>a numeric value between 0 and 1, graphical parameter to specify
the gray value at the high end of the palette.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>color</code></td>
<td>
<p>a character vector, graphical parameter indicating the color of
bars in the bar chart in the following order: Fixed slopes (Within),
Fixed slopes (Between), Slope variation (Within), Intercept variation
(Between), and Residual (Within). By default, colors from the
colorblind-friendly palettes are used</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>write</code></td>
<td>
<p>a character string naming a text file with file extension
<code>".txt"</code> (e.g., <code>"Output.txt"</code>) for writing the
output into a text file.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>append</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output will be appended
to an existing text file with extension <code>.txt</code> specified
in <code>write</code>, if <code>FALSE</code> existing text file will be
overwritten.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>check</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), argument specification is checked.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>output</code></td>
<td>
<p>logical: if <code>TRUE</code> (default), output is shown on the console.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>A number of R-squared measures for multilevel and linear mixed effects models have
been developed in the methodological literature (see Rights &amp; Sterba, 2018).
Based on these measures, following measures were implemented in the current function:
</p>

<dl>
<dt><strong>Raudenbush and Bryk (2002)</strong></dt>
<dd>
<p>R-squared measures by Raudenbush
and Bryk (2002) are based on the proportional reduction of unexplained variance
when predictors are added. More specifically, variance estimates from the
baseline/null model (i.e., <code class="reqn">\sigma^2_{e|b}</code> and <code class="reqn">\sigma^2_{u0|b}</code>)
and variance estimates from the model including predictors (i.e., <code class="reqn">\sigma^2_{e|m}</code>
and <code class="reqn">\sigma^2_{u0|m}</code>) are used to compute the proportional reduction in
variance between baseline/null model and the complete model by:
</p>
<p style="text-align: center;"><code class="reqn">R^2_1(RB) = \frac{\sigma^2_{e|b} - \sigma^2_{e|m}}{\sigma^2_{e|b}}</code>
</p>

<p>for the proportional reduction at level-1 (within-cluster) and by:
</p>
<p style="text-align: center;"><code class="reqn">R^2_2(RB) = \frac{\sigma^2_{u0|b} - \sigma^2_{u0|m}}{\sigma^2_{u0|b}}</code>
</p>

<p>for the proportional reduction at level-2 (between-cluster), where <code class="reqn">|b</code>
and <code class="reqn">|m</code> represent the baseline and full models, respectively (Hox et al.,
2018; Roberts et al., 2010).
</p>
<p>A major disadvantage of these measures is that adding predictors can increases
rather than decreases some of the variance components and it is even possible
to obtain negative values for <code class="reqn">R^2</code> with these formulas (Snijders &amp; Bosker,
2012). According to Snijders and Bosker (1994) this can occur because the
between-group variance is a function of both level-1 and level-2 variance:
</p>
<p style="text-align: center;"><code class="reqn">var(\bar{Y}_j) = \sigma^2_{u0} + \frac{\sigma^2_e}{n_j}</code>
</p>

<p>Hence, adding a predictor (e.g., cluster-mean centered predictor) that explains
proportion of the within-group variance will decrease the estimate of <code class="reqn">\sigma^2_e</code>
and increase the estimate <code class="reqn">\sigma^2_{u0}</code> if this predictor does not explain
a proportion of the between-group variance to balance out the decrease in
<code class="reqn">\sigma^2_e</code> (LaHuis et al., 2014). Negative estimates for <code class="reqn">R^2</code> can
also simply occur due to chance fluctuation in sample estimates from the two
models.
</p>
<p>Another disadvantage of these measures is that <code class="reqn">R^2_2(RB)</code> for the explained
variance at level-2 has been shown to perform poorly in simulation studies even
with <code class="reqn">j = 200</code> clusters with group cluster size of <code class="reqn">n_j = 50</code> (LaHuis
et al., 2014; Rights &amp; Sterba, 2019).
</p>
<p>Moreover, when there is missing data in the level-1 predictors, it is possible
that sample sizes for the baseline and complete models differ.
</p>
<p>Finally, it should be noted that R-squared measures by Raudenbush and Bryk (2002)
are appropriate for random intercept models, but not for random intercept and
slope models. For random slope models, Snijders and Bosker (2012) suggested to
re-estimate the model as random intercept models with the same predictors while
omitting the random slopes to compute the R-squared measures. However, the
simulation study by LaHuis (2014) suggested that the R-squared measures showed
an acceptable performance when there was little slope variance, but did not
perform well in the presence of higher levels of slope variance.</p>
</dd>
<dt><strong>Snijders and Bosker (1994)</strong></dt>
<dd>
<p>R-squared measures by Snijders and
Bosker (1994) are based on the proportional reduction of mean squared prediction
error and is computed using the formula:
</p>
<p style="text-align: center;"><code class="reqn">R^2_1(SB) = \frac{\hat{\sigma}^2_{e|m} + \hat{\sigma}^2_{u0|m}}{\hat{\sigma}^2_{e|b} + \hat{\sigma}^2_{u0|b}}</code>
</p>

<p>for computing the proportional reduction of error at level-1 representing
the total amount of explained variance and using the formula:
</p>
<p style="text-align: center;"><code class="reqn">R^2_2(SB) = \frac{\hat{\sigma}^2_{e|m} / n_j + \hat{\sigma}^2_{u0|m}}{\hat{\sigma}^2_{e|b} / n_j + \hat{\sigma}^2_{u0|b}}</code>
</p>

<p>for computing the proportional reduction of error at level-2 by dividing the
<code class="reqn">\hat{\sigma}^2_e</code> by the group cluster size <code class="reqn">n_j</code> or by the average
cluster size for unbalanced data (Roberts et al., 2010). Note that the function
uses the harmonic mean of the group sizes as recommended by Snijders and Bosker
(1994). The population values of <code class="reqn">R^2</code> based on these measures cannot be
negative because the interplay of level-1 and level-2 variance components is
considered. However, sample estimates of <code class="reqn">R^2</code> can be negative either due
to chance fluctuation when sample sizes are small or due to model misspecification
(Snijders and Bosker, 2012).
</p>
<p>When there is missing data in the level-1 predictors, it is possible that sample
sizes for the baseline and complete models differ.
</p>
<p>Similar to the R-squared measures by Raudenbush and Bryk (2002), the measures
by Snijders and Bosker (1994) are appropriate for random intercept models, but
not for random intercept and slope models. Accordingly, for random slope models,
Snijders and Bosker (2012) suggested to re-estimate the model as random intercept
models with the same predictors while omitting the random slopes to compute the
R-squared measures. The simulation study by LaHuis et al. (2014) revealed that
the R-squared measures showed an acceptable performance, but it should be noted
that <code class="reqn">R^2_2(SB)</code> the explained variance at level-2 was not investigated in
their study.</p>
</dd>
<dt><strong>Nakagawa and Schielzeth (2013)</strong></dt>
<dd>
<p>R-squared measures by Nakagawa
and Schielzeth (2013) are based on partitioning model-implied variance from a
single fitted model and uses the variance of predicted values of <code class="reqn">var(\hat{Y}_{ij})</code>
to form both the outcome variance in the denominator and the explained variance
in the numerator of the formulas:
</p>
<p style="text-align: center;"><code class="reqn">R^2_m(NS) = \frac{var(\hat{Y}_{ij})}{var(\hat{Y}_{ij}) + \sigma^2_{u0} + \sigma^2_{e}}</code>
</p>

<p>for marginal total <code class="reqn">R^2_m(NS)</code> and:
</p>
<p style="text-align: center;"><code class="reqn">R^2_c(NS) = \frac{var(\hat{Y}_{ij}) + \sigma^2_{u0}}{var(\hat{Y}_{ij}) + \sigma^2_{u0} + \sigma^2_{e}}</code>
</p>

<p>for conditional total <code class="reqn">R^2_c(NS)</code>. In the former formula <code class="reqn">R^2</code> predicted
scores are marginalized across random effects to indicate the variance explained
by fixed effects and in the latter formula <code class="reqn">R^2</code> predicted scores are conditioned
on random effects to indicate the variance explained by fixed and random effects
(Rights and Sterba, 2019).
</p>
<p>The advantage of these measures is that they can never become negative and
that they can also be extended to generalized linear mixed effects models (GLMM)
when outcome variables are not continuous (e.g., binary outcome variables).
Note that currently the function does not provide <code class="reqn">R^2</code> measures for GLMMs,
but these measures can be obtained using the <code>r.squaredGLMM()</code> function in
the <span class="pkg">MuMIn</span> package.
</p>
<p>A disadvantage is that these measures do not allow random slopes and are restricted
to the simplest random effect structure (i.e., random intercept model). In other
words, these measures do not fully reflect the structure of the fitted model when
using random intercept and slope models. However, Johnson (2014) extended these
measures to allow random slope by taking into account the contribution of random
slopes, intercept-slope covariances, and the covariance matrix of random slope
to the variance in <code class="reqn">Y_{ij}</code>. As a result, R-squared measures by Nakagawa
and Schielzeth (2013) as extended by Johnson (2014) can be used for both random
intercept, and random intercept and slope models.
</p>
<p>The major criticism of the R-squared measures by Nakagawa and Schielzeth (2013)
as extended by Johnson (2014) is that these measures do not decompose outcome
variance into each of total, within-cluster, and between-cluster variance which
precludes from computing level-specific <code class="reqn">R^2</code> measures. In addition, these
measures do not distinguish variance attributable to level-1 versus level-2
predictors via fixed effects, and they also do not distinguish between random
intercept and random slope variation (Rights and Sterba, 2019).</p>
</dd>
<dt><strong>Rights and Sterba (2019)</strong></dt>
<dd>
<p>R-squared measures by Rights and Sterba
(2019) provide an integrative framework of R-squared measures for multilevel
and linear mixed effects models with random intercepts and/or slopes. Their
measures are also based on partitioning model implied variance from a single
fitted model, but they provide a full partitioning of the total outcome variance
to one of five specific sources:
</p>

<ul>
<li>
<p> variance attributable to level-1 predictors via fixed slopes (shorthand:
variance attributable to <code>f1</code>)
</p>
</li>
<li>
<p> variance attributable to level-2 predictors via fixed slopes (shorthand:
variance attributable to <code>f2</code>)
</p>
</li>
<li>
<p> variance attributable to level-1 predictors via random slope variation/
covariation (shorthand: variance attributable to <code>v</code>)
</p>
</li>
<li>
<p> variance attributable to cluster-specific outcome means via random
intercept variation (shorthand: variance attributable to <code>m</code>)
</p>
</li>
<li>
<p> variance attributable to level-1 residuals
</p>
</li>
</ul>
<p><code class="reqn">R^2</code> measures are based on the outcome variance of interest (total,
within-cluster, or between-cluster) in the denominator, and the source contributing
to explained variance in the numerator:
</p>

<dl>
<dt><strong>Total <code class="reqn">R^2</code> measures</strong></dt>
<dd>
<p>incorporate both within-cluster
and between cluster variance in the denominator and quantify variance
explained in an omnibus sense:
</p>

<ul>
<li>
<p><code class="reqn">R^{2(f_1)}_t</code>: Proportion of total outcome variance explained
by level-1 predictors via fixed slopes.
</p>
</li>
<li>
<p><code class="reqn">R^{2(f_2)}_t</code>: Proportion of total outcome variance explained
by level-2 predictors via fixed slopes.
</p>
</li>
<li>
<p><code class="reqn">R^{2(f)}_t</code>: Proportion of total outcome variance explained
by all predictors via fixed slopes.
</p>
</li>
<li>
<p><code class="reqn">R^{2(v)}_t</code>: Proportion of total outcome variance explained
by level-1 predictors via random slope variation/covariation.
</p>
</li>
<li>
<p><code class="reqn">R^{2(m)}_t</code>: Proportion of total outcome variance explained
by cluster-specific outcome means via random intercept variation.
</p>
</li>
<li>
<p><code class="reqn">R^{2(fv)}_t</code>: Proportion of total outcome variance explained
by predictors via fixed slopes and random slope variation/covariation.
</p>
</li>
<li>
<p><code class="reqn">R^{2(fvm)}_t</code>: Proportion of total outcome variance explained
by predictors via fixed slopes and random slope variation/covariation
and by cluster-specific outcome means via random intercept variation.
</p>
</li>
</ul>
</dd>
<dt><strong>Within-Cluster <code class="reqn">R^2</code> measures</strong></dt>
<dd>
<p>incorporate only within-cluster
variance in the denominator and indicate
the degree to which within-cluster variance can be explained by a given model:
</p>

<ul>
<li>
<p><code class="reqn">R^{2(f_1)}_w</code>: Proportion of within-cluster outcome variance
explained by level-1 predictors via fixed slopes.
</p>
</li>
<li>
<p><code class="reqn">R^{2(v)}_w</code>: Proportion of within-cluster outcome variance
explained by level-1 predictors via random slope variation/covariation.
</p>
</li>
<li>
<p><code class="reqn">R^{2(f_1v)}_w</code>: Proportion of within-cluster outcome variance
explained by level-1 predictors via fixed slopes and random slope
variation/covariation.
</p>
</li>
</ul>
</dd>
<dt><strong>Between-Cluster <code class="reqn">R^2</code> measures</strong></dt>
<dd>
<p>incorporate only between-cluster
variance in the denominator and indicate the degree to which between-cluster
variance can be explained by a given model:
</p>

<ul>
<li>
<p><code class="reqn">R^{2(f_2)}_b</code>: Proportion of between-cluster outcome variance
explained by level-2 predictors via fixed slopes.
</p>
</li>
<li>
<p><code class="reqn">R^{2(m)}_b</code>: Proportion of between-cluster outcome variance
explained by cluster-specific outcome means via random intercept variation.
</p>
</li>
</ul>
</dd>
</dl>
<p>The decomposition of the total outcome variance can be visualized in a bar
chart by specifying <code>plot = TRUE</code>. The first column of the bar chart
decomposes scaled total variance into five distinct proportions (i.e.,
<code class="reqn">R^{2(f_1)}_t</code>, <code class="reqn">R^{2(f_2)}_t</code>, <code class="reqn">R^{2(f)}_t</code>, <code class="reqn">R^{2(v)}_t</code>,
<code class="reqn">R^{2(m)}_t</code>, <code class="reqn">R^{2(fv)}_t</code>, and <code class="reqn">R^{2(fvm)}_t</code>), the second
column decomposes scaled within-cluster variance into three distinct proportions
(i.e., <code class="reqn">R^{2(f_1)}_w</code>, <code class="reqn">R^{2(v)}_w</code>, and <code class="reqn">R^{2(f_1v)}_w</code>), and
the third column decomposes scaled between-cluster variance into two distinct
proportions (i.e., <code class="reqn">R^{2(f_2)}_b</code>, <code class="reqn">R^{2(m)}_b</code>).
</p>
<p>Note that the function assumes that all level-1 predictors are centered within
cluster (i.e., group-mean or cluster-mean centering) as has been widely recommended
(e.g., Enders &amp; Tofighi, D., 2007; Rights et al., 2019). In fact, it does not
matter whether a lower-level predictor is merely a control variable, or is
quantitative or categorical (Yaremych et al., 2021), cluster-mean centering
should always be used for lower-level predictors to obtain an orthogonal
between-within partitioning of a lower-level predictor's variance that directly
parallels what happens to a level-1 outcome (Hoffman &amp; Walters, 2022). In the
absence of cluster-mean-centering, however, the function provides total <code class="reqn">R^2</code>
measures, but does not provide any within-cluster or between-cluster <code class="reqn">R^2</code>
measures.</p>
</dd>
</dl>
<p>By default, the function only computes R-squared measures by Rights and Sterba
(2019) because the other R-squared measures reflect the same population quantity
provided by Rights and Sterba (2019). That is, R-squared measures <code class="reqn">R^2_1(RB)</code>
and <code class="reqn">R^2_2(RB)</code> by Raudenbush and Bryk (2002) are equivalent to <code class="reqn">R^{2(f_1v)}_w</code>
and <code class="reqn">R^{2(f_2)}_b</code>, R-squared measures <code class="reqn">R^2_1(SB)</code> and <code class="reqn">R^2_2(SB)</code>
are equivalent to <code class="reqn">R^{2(f)}_t</code> and <code class="reqn">R^{2(f_2)}_b</code>, and R-squared measures
<code class="reqn">R^2_m(NS)</code> and <code class="reqn">R^2_c(NS)</code> by Nakagawa and Schielzeth (2013) as extended
by Johnson (2014) are equivalent to <code class="reqn">R^{2(f)}_t</code> and <code class="reqn">R^{2(fvm)}_t</code>
(see Rights and Sterba, Table 3).
</p>
<p>Note that none of these measures provide an <code class="reqn">R^2</code> for the random slope
variance explained by cross-level interactions, a quantity that is frequently
of interest (Hoffman &amp; Walters, 2022).
</p>


<h3>Value</h3>

<p>Returns an object of class <code>misty.object</code>, which is a list with following
entries:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>call</code></td>
<td>
<p>function call</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>type</code></td>
<td>
<p>type of analysis</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>matrix or data frame specified in <code>data</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>plot</code></td>
<td>
<p>ggplot2 object for plotting the results</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>args</code></td>
<td>
<p>specification of function arguments</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>result</code></td>
<td>
<p>list with result tables, i.e., <code>rb</code> for the R2 measures
by Raudenbush and Bryk (2002), <code>sb</code> for the R2 measures
by Snijders and Bosker (1994), <code>ns</code> for the R2 measures
by Nakagawa and Schielzeth (2013), and <code>rs</code> for the R2
measures by Rights and Sterba (2019)</p>
</td>
</tr>
</table>
<h3>Note</h3>

<p>This function is based on the <code>multilevelR2()</code> function from the <span class="pkg">mitml</span>
package by Simon Grund, Alexander Robitzsch and Oliver Luedtke (2021), and a
copy of the function <code>r2mlm</code> in the <span class="pkg">r2mlm</span> package by Mairead Shaw,
Jason Rights, Sonya Sterba, and Jessica Flake.
</p>


<h3>Author(s)</h3>

<p>Simon Grund, Alexander Robitzsch, Oliver Luedtk, Mairead Shaw, Jason D. Rights,
Sonya K. Sterba, Jessica K. Flake, and Takuya Yanagida
</p>


<h3>References</h3>

<p>Enders, C. K., &amp; Tofighi, D. (2007). Centering predictor variables in
cross-sectional multilevel models: A new look at an old issue.
<em>Psychological Methods, 12</em>, 121-138. https://doi.org/10.1037/1082-989X.12.2.121
</p>
<p>Hoffmann, L., &amp; Walter, W. R. (2022). Catching up on multilevel modeling.
<em>Annual Review of Psychology, 73</em>, 629-658. https://doi.org/10.1146/annurev-psych-020821-103525
</p>
<p>Hox, J., Moerbeek, M., &amp; van de Schoot, R. (2018). <em>Multilevel Analysis:
Techniques and Applications</em> (3rd ed.) Routledge.
</p>
<p>Johnson, P. C. D. (2014). Extension of Nakagawa &amp; Schielzethâ€™s R2 GLMM to random
slopes models. <em>Methods in Ecology and Evolution, 5</em>(9), 944-946.
https://doi.org/10.1111/2041-210X.12225
</p>
<p>LaHuis, D. M., Hartman, M. J., Hakoyama, S., &amp; Clark, P. C. (2014). Explained
variance measures for multilevel models. <em>Organizational Research Methods, 17</em>,
433-451. https://doi.org/10.1177/1094428114541701
</p>
<p>Nakagawa, S., &amp; Schielzeth, H. (2013). A general and simple method for obtaining
R2 from generalized linear mixed-effects models. <em>Methods in Ecology and Evolution, 4</em>(2),
133-142. https://doi.org/10.1111/j.2041-210x.2012.00261.x
</p>
<p>Raudenbush, S. W., &amp; Bryk, A. S., (2002). <em>Hierarchical linear models: Applications
and data analysis methods</em>. Sage.
</p>
<p>Rights, J. D., Preacher, K. J., &amp; Cole, D. A. (2020). The danger of conflating
level-specific effects of control variables when primary interest lies in level-2
effects. <em>British Journal of Mathematical and Statistical Psychology, 73</em>(Suppl 1),
194-211. https://doi.org/10.1111/bmsp.12194
</p>
<p>Rights, J. D., &amp; Sterba, S. K. (2019). Quantifying explained variance in multilevel
models: An integrative framework for defining R-squared measures. <em>Psychological Methods, 24</em>,
309-338. https://doi.org/10.1037/met0000184
</p>
<p>Roberts, K. J., Monaco, J. P., Stovall, H., &amp; Foster, V. (2011). Explained variance
in multilevel models (pp. 219-230). In J. J. Hox &amp; J. K. Roberts (Eds.), <em>Handbook
of Advanced Multilevel Analysis</em>. Routledge.
</p>
<p>Snijders, T. A. B., &amp; Bosker, R. (1994). Modeled variance in two-level models.
<em>Sociological methods and research, 22</em>, 342-363. https://doi.org/10.1177/0049124194022003004
</p>
<p>Snijders, T. A. B., &amp; Bosker, R. J. (2012). <em>Multilevel analysis: An introduction
to basic and advanced multilevel modeling</em> (2nd ed.). Sage.
</p>
<p>Yaremych, H. E., Preacher, K. J., &amp; Hedeker, D. (2021). Centering categorical
predictors in multilevel models: Best practices and interpretation. <em>Psychological
Methods</em>. Advance online publication. https://doi.org/10.1037/met0000434
</p>


<h3>See Also</h3>

<p><code>multilevel.cor</code>, <code>multilevel.descript</code>,
<code>multilevel.icc</code>, <code>multilevel.indirect</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Not run: 
# Load misty, lme4, nlme, and ggplot2 package
library(misty)
library(lme4)
library(nlme)
library(ggplot2)

# Load data set "Demo.twolevel" in the lavaan package
data("Demo.twolevel", package = "lavaan")

#----------------------------------------------------------------------------
#'
# Cluster mean centering, center() from the misty package
Demo.twolevel$x2.c &lt;- center(Demo.twolevel$x2, type = "CWC",
                             cluster = Demo.twolevel$cluster)

# Compute group means, cluster.scores() from the misty package
Demo.twolevel$x2.b &lt;- cluster.scores(Demo.twolevel$x2,
                                     cluster = Demo.twolevel$cluster)

# Estimate multilevel model using the lme4 package
mod1a &lt;- lmer(y1 ~ x2.c + x2.b + w1 + (1 + x2.c | cluster), data = Demo.twolevel,
              REML = FALSE, control = lmerControl(optimizer = "bobyqa"))

# Estimate multilevel model using the nlme package
mod1b &lt;- lme(y1 ~ x2.c + x2.b + w1, random = ~ 1 + x2.c | cluster, data = Demo.twolevel,
             method = "ML")

#----------------------------------------------------------------------------
#'
# Example 1a: R-squared measures according to Rights and Sterba (2019)
multilevel.r2(mod1a)
#'
# Example 1b: R-squared measures according to Rights and Sterba (2019)
multilevel.r2(mod1b)
#'
# Example 1a: Write Results into a text file
multilevel.r2(mod1a, write = "ML-R2.txt")

#-------------------------------------------------------------------------------

# Example 2: Bar chart showing the decomposition of scaled total, within-cluster,
# and between-cluster outcome variance
multilevel.r2(mod1a, plot = TRUE)

# Bar chart in gray scale
multilevel.r2(mod1a, plot = TRUE, gray = TRUE)

# Save bar chart, ggsave() from the ggplot2 package
ggsave("Proportion_of_Variance.png", dpi = 600, width = 5.5, height = 5.5)

#-------------------------------------------------------------------------------

# Example 3: Estimate multilevel model without random slopes
# Note. R-squared measures by Raudenbush and Bryk (2002), and  Snijders and
# Bosker (2012) should be computed based on the random intercept model
mod2 &lt;- lmer(y1 ~ x2.c + x2.b + w1 + (1 | cluster), data = Demo.twolevel,
             REML = FALSE, control = lmerControl(optimizer = "bobyqa"))

# Print all available R-squared measures
multilevel.r2(mod2, print = "all")

#-------------------------------------------------------------------------------

# Example 4: Draw bar chart manually
mod1a.r2 &lt;- multilevel.r2(mod1a, output = FALSE)

# Prepare data frame for ggplot()
df &lt;- data.frame(var = factor(rep(c("Total", "Within", "Between"), each = 5),
                              level = c("Total", "Within", "Between")),
                 part = factor(c("Fixed Slopes (Within)", "Fixed Slopes (Between)",
                                 "Slope Variation (Within)", "Intercept Variation (Between)",
                                 "Residual (Within)"),
                 level = c("Residual (Within)", "Intercept Variation (Between)",
                           "Slope Variation (Within)", "Fixed Slopes (Between)",
                           "Fixed Slopes (Within)")),
                 y = as.vector(mod1a.r2$result$rs$decomp))

# Draw bar chart in line with the default setting of multilevel.r2()
ggplot(df, aes(x = var, y = y, fill = part)) +
  theme_bw() +
  geom_bar(stat = "identity") +
  scale_fill_manual(values = c("#E69F00", "#009E73", "#CC79A7", "#0072B2", "#D55E00")) +
  scale_y_continuous(name = "Proportion of Variance", breaks = seq(0, 1, by = 0.1)) +
  theme(axis.title.x = element_blank(),
        axis.ticks.x = element_blank(),
        legend.title = element_blank(),
        legend.position = "bottom",
        legend.box.margin = margin(-10, 6, 6, 6)) +
  guides(fill = guide_legend(nrow = 2, reverse = TRUE))

## End(Not run)
</code></pre>


</div>