<div class="container">

<table style="width: 100%;"><tr>
<td>findLabels</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Mixed Membership Post-Processing</h2>

<h3>Description</h3>

<p><code>findLabels</code> finds the optimal permutation of labels that minimizes
the weighted squared difference between the arrays of subpopulation parameters from a fitted mixed membership
model, <code class="reqn">\theta</code> and a given comparison model.
</p>


<h3>Usage</h3>

<pre><code class="language-R">findLabels(model, comparison, exhaustive = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>model</code></td>
<td>
<p>the fitted <code>mixedMemModel</code> object.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>comparison</code></td>
<td>
<p>an array of the same dimensions as model$theta which contains the subpopulation parameters from another model.
<code>findLabels</code> will return a permutation of the labels of <code>model</code> which match to <code>comparison</code> most closely.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>exhaustive</code></td>
<td>
<p>a boolean for whether an exhaustive search should be performed. If false, a greedy algorithim is used instead.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Mixed Membership models are invariant to permutations of the sub-population labels; swapping the names of each sub-population yields an equivalent model.
The ordering of the labels in a fitted model is dependent on the initialization points of the variational EM algorithim. The function <code>findLabels</code> selects a
permutation of the sub-population labels that best matches a given comparison model by minimizing the weighted squared difference between the
<code class="reqn">\theta</code> arrays. The weights are determined by the relative frequencies of each group.
</p>
<p><code class="reqn">Loss = \sum_j \sum_k \alpha_k/\alpha_0 [\sum_v (\hat\theta_{k,v} - \theta_{k,v})^2]</code>
where <code class="reqn">\alpha_0 = \sum_k \alpha_k</code>
</p>
<p>If K, number of sub-populations, is small, the method searches through all K! permutations of the sub-population labels and
select the permutation which minimizes the loss. If K is large, a greedy algorithim can be used instead. This
algorithm selects the best match for each fitted sub-population starting with the group with the largest fitted
relative frequency.
</p>


<h3>Value</h3>

<p><code>findLabels</code> returns a list with two objects: <code>perm</code> and <code>loss</code>. <code>perm</code> is the optimal permutation of the labels with respect to the squared error loss.
<code>loss</code> is the calculated value of the weighted squared error loss (shown above) for the optimal permutation.
</p>


<h3>See Also</h3>

<p>permuteLabels
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Not run: 
# See mixedMemModel documentation for how to generate data and instantiate a mixedMemModel object
# After the data as been generated, we initialize the array of sub-population parameters (theta)
# according to a permutation of the true labeling
set.seed(123)
perm = sample.int(K, size = K, replace = FALSE)
theta1 = theta_truth[,perm,]
test_model &lt;- mixedMemModel(Total = Total, J = J,Rj = Rj, Nijr= Nijr, K = K, Vj = Vj,dist = dist,
 obs = obs, alpha = alpha, theta = theta1)
out &lt;- mmVarFit(test_model)
opt.perm &lt;- findLabels(out, theta_truth)
opt.perm

# produce mixedMemModel object with sub-population labels permuted to best match
# the comparison model
out = permuteLabels(out, opt.perm$perm)

## End(Not run)
</code></pre>


</div>