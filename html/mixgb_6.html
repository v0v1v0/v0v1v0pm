<div class="container">

<table style="width: 100%;"><tr>
<td>mixgb_cv</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Use cross-validation to find the optimal <code>nrounds</code>
</h2>

<h3>Description</h3>

<p>Use cross-validation to find the optimal <code>nrounds</code> for an <code>Mixgb</code> imputer. Note that this method relies on the complete cases of a dataset to obtain the optimal <code>nrounds</code>.
</p>


<h3>Usage</h3>

<pre><code class="language-R">mixgb_cv(
  data,
  nfold = 5,
  nrounds = 100,
  early_stopping_rounds = 10,
  response = NULL,
  select_features = NULL,
  xgb.params = list(max_depth = 3, gamma = 0, eta = 0.3, min_child_weight = 1,
    subsample = 0.7, colsample_bytree = 1, colsample_bylevel = 1, colsample_bynode = 1,
    tree_method = "auto", gpu_id = 0, predictor = "auto"),
  stringsAsFactors = FALSE,
  verbose = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>A data.frame or a data.table with missing values.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nfold</code></td>
<td>
<p>The number of subsamples which are randomly partitioned and of equal size. Default: 5</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nrounds</code></td>
<td>
<p>The max number of iterations in XGBoost training. Default: 100</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>early_stopping_rounds</code></td>
<td>
<p>An integer value <code>k</code>. Training will stop if the validation performance has not improved for <code>k</code> rounds.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>response</code></td>
<td>
<p>The name or the column index of a response variable. Default: <code>NULL</code> (Randomly select an incomplete variable).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>select_features</code></td>
<td>
<p>The names or the indices of selected features. Default: <code>NULL</code> (Select all the other variables in the dataset).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>xgb.params</code></td>
<td>
<p>A list of XGBoost parameters. For more details, please check <a href="https://xgboost.readthedocs.io/en/stable/parameter.html">XGBoost documentation on parameters</a>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>stringsAsFactors</code></td>
<td>
<p>A logical value indicating whether all character vectors in the dataset should be converted to factors.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>
<p>A logical value. Whether to print out cross-validation results during the process.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Extra arguments to be passed to XGBoost.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>A list of the optimal <code>nrounds</code>, <code>evaluation.log</code> and the chosen <code>response</code>.
</p>


<h3>Examples</h3>

<pre><code class="language-R">params &lt;- list(max_depth = 3, subsample = 0.7, nthread = 2)
cv.results &lt;- mixgb_cv(data = nhanes3, xgb.params = params)
cv.results$best.nrounds

imputed.data &lt;- mixgb(data = nhanes3, m = 3, xgb.params = params, nrounds = cv.results$best.nrounds)
</code></pre>


</div>