<div class="container">

<table style="width: 100%;"><tr>
<td>gpcm</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Gaussian Parsimonious Clustering Models</h2>

<h3>Description</h3>

<p>Carries out model-based clustering or classification using some or all of the 14 parsimonious Gaussian clustering models (GPCM).</p>


<h3>Usage</h3>

<pre><code class="language-R">gpcm(data=NULL, G=1:3, mnames=NULL,
		start=2, label=NULL, 
		veo=FALSE, da=c(1.0),
		nmax=1000, atol=1e-8, mtol=1e-8, mmax=10, burn=5,
		pprogress=FALSE, pwarning=TRUE, stochastic = FALSE, seed=123) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>

<p>A matrix or data frame such that rows correspond to observations and columns correspond to variables. Note that this function currently only works with multivariate data p &gt; 1. 
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>G</code></td>
<td>

<p>A sequence of integers giving the number of components to be used.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mnames</code></td>
<td>

<p>The models (i.e., covariance structures) to be used. If <code>NULL</code> then all 14 are fitted. 
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>start</code></td>
<td>

<p>If <code>0</code> then the random soft function is used for initialization.
If <code>1</code> then the random hard function is used for initialization.
If <code>2</code> then the kmeans function is used for initialization. 
If <code>&gt;2</code> then multiple random soft starts are used for initialization. 
If <code>is.matrix</code> then matrix is used as an initialization matrix as along as it has non-negative elements. Note: only models with the same number of columns of this matrix will be fit.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>label</code></td>
<td>

<p>If <code>NULL</code> then the data has no known groups.
If <code>is.integer</code> then some of the observations have known groups. If <code>label[i]=k</code> then observation belongs to group  <code>k</code>. If <code>label[i]=0</code> then observation has no known group. See Examples. 
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>veo</code></td>
<td>

<p>Stands for "Variables exceed observations". If <code>TRUE</code> then if the number variables in the model exceeds the number of observations the model is still fitted.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>da</code></td>
<td>

<p>Stands for Determinstic Annealing. A vector of doubles. 
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nmax</code></td>
<td>

<p>The maximum number of iterations each EM algorithm is allowed to use. 
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>atol</code></td>
<td>

<p>A number specifying the epsilon value for the convergence criteria used in the EM algorithms. For each algorithm, the criterion is based on the difference between the log-likelihood at an iteration and an asymptotic estimate of the log-likelihood at that iteration. This asymptotic estimate is based on the Aitken acceleration and details are given in the References. 
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mtol</code></td>
<td>

<p>A number specifying the epsilon value for the convergence criteria used in the M-step in the GEM algorithms.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mmax</code></td>
<td>

<p>The maximum number of iterations each M-step is allowed in the GEM algorithms.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>burn</code></td>
<td>

<p>The burn in period for imputing data. (Missing observations are removed and a model is estimated seperately before placing an imputation step within the EM.)
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pprogress</code></td>
<td>

<p>If <code>TRUE</code> print the progress of the function.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pwarning</code></td>
<td>

<p>If <code>TRUE</code> print the warnings.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>stochastic</code></td>
<td>

<p>If <code>TRUE</code> , it will run stochastic E step variant. 
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>seed</code></td>
<td>

<p>The seed for the run, default is 123
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The data <code>x</code> are either clustered or classified using Gaussian mixture models with some or all of the 14 parsimonious covariance structures described in Celeux &amp; Govaert (1995). The algorithms given by Celeux &amp; Govaert (1995) is used for 12 of the 14 models; the "EVE" and "VVE" models use the algorithms given in Browne &amp; McNicholas (2014). Starting values are very important to the successful operation of these algorithms and so care must be taken in the interpretation of results. 
</p>


<h3>Value</h3>

<p>An object of class <code>gpcm</code> is a list with components:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>map</code></td>
<td>
<p>A vector of integers indicating the maximum <em>a posteriori</em> classifications for the best model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>model_objs</code></td>
<td>
<p>A list of all estimated models with parameters returned from the C++ call.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>best_model</code></td>
<td>
<p>A class of gpcm_best containing; the number of groups for the best model, the covariance structure, and Bayesian Information Criterion (BIC) value.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>loglik</code></td>
<td>
<p>The log-likelihood values from fitting the best model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>z</code></td>
<td>
<p>A matrix giving the raw values upon which <code>map</code> is based.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>BIC</code></td>
<td>
<p>A G by mnames by 3 dimensional array with values pertaining to BIC calculations. (legacy)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>gpar</code></td>
<td>
<p>A list object for each cluster pertaining to parameters. (legacy)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>startobject</code></td>
<td>
<p>The type of object inputted into <code>start</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>row_tags</code></td>
<td>
<p>If there were NAs in the original dataset, a vector of indices referencing the row of the imputed vectors is given.</p>
</td>
</tr>
</table>
<h4>Best Model</h4>

<p>An object of class <code>gpcm_best</code> is a list with components:
</p>

<table>
<tr style="vertical-align: top;">
<td><code>model_type</code></td>
<td>
<p>A string containg summarized information about the type of model estimated (Covariance structure and number of groups).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>model_obj</code></td>
<td>
<p>An internal list containing all parameters returned from the C++ call. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>BIC</code></td>
<td>
<p>Bayesian Index Criterion (positive scale, bigger is better).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>loglik</code></td>
<td>
<p>Log liklihood from the estimated model. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nparam</code></td>
<td>
<p>Number of a parameters in the mode.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>startobject</code></td>
<td>
<p>The type of object inputted into <code>start</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>G</code></td>
<td>
<p>An integer representing the number of groups.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cov_type</code></td>
<td>
<p>A string representing the type of covariance matrix (see 14 models).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>status</code></td>
<td>
<p>Convergence status of EM algorithm according to Aitken's Acceleration</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>labs</code></td>
<td>
<p>A vector of integers indicating the maximum <em>a posteriori</em> classifications for the best model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>row_tags</code></td>
<td>
<p>If there were NAs in the original dataset, a vector of indices referencing the row of the imputed vectors is given.</p>
</td>
</tr>
</table>
<h4>Internal Objects</h4>

<p>All classes contain an internal list called <code>model_obj</code> or <code>model_objs</code> with the following components:
</p>

<table>
<tr style="vertical-align: top;">
<td><code>zigs</code></td>
<td>
<p> a posteori matrix </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>G</code></td>
<td>
<p>An integer representing the number of groups.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sigs</code></td>
<td>
<p>A vector of covariance matrices for each group</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mus</code></td>
<td>
<p>A vector of mean vectors for each group</p>
</td>
</tr>
</table>
<h3>Note</h3>

<p>Dedicated <code>print</code>, <code>plot</code> and <code>summary</code> functions are available for objects of class <code>gpcm</code>.
</p>


<h3>Author(s)</h3>

<p>Nik Pocuca, Ryan P. Browne and Paul D. McNicholas.
</p>
<p>Maintainer: Paul D. McNicholas &lt;mcnicholas@math.mcmaster.ca&gt;
</p>


<h3>References</h3>

<p>McNicholas, P.D. (2016), <em>Mixture Model-Based Classification</em>. Boca Raton: Chapman &amp; Hall/CRC Press
</p>
<p>Browne, R.P. and McNicholas, P.D. (2014). Estimating common principal components in high dimensions. <em>Advances in Data Analysis and Classification</em> <b>8</b>(2), 217-226.
</p>
<p>Celeux, G., Govaert, G. (1995). Gaussian parsimonious clustering models. <em>Pattern Recognition</em> <b>28</b>(5), 781-793.
</p>


<h3>Examples</h3>

<pre><code class="language-R">	## Not run: 

data("x2")
### use kmeans to find starting values
ax0 = gpcm(x2, G=1:5, mnames=c("VVV", "EVE"),start=2, pprogress=TRUE, atol=1e-2)
summary(ax0)
ax0

### use random soft initializations. 
ax6 = gpcm(x2, G=1:5, mnames=c("VVV", "EVE"),start= 0)
summary(ax6)
ax6

### use deterministic annealing for starting values
axDA = gpcm(x2, G=1:5, mnames=c("VVV", "EVE"), start=0,da=c(0.3,0.5,0.8,1.0))
summary(axDA)
axDA

### estimate all 14 covariance structures 
ax = gpcm(x2, G=1:5, mnames=NULL, start=0)
summary(ax)
ax

### model based classification
x2.label = numeric(nrow(x2))
x2.label[c(10,50, 110, 150, 210, 250)] = c(1,1,2,2,3,3)
axl = gpcm(x2, G=3, mnames=c("VVV", "EVE"), label=x2.label)
summary(axl)

plot(x2, col = axl$map + 1)
	
## End(Not run)
</code></pre>


</div>