<div class="container">

<table style="width: 100%;"><tr>
<td>mize_step</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>One Step of Optimization</h2>

<h3>Description</h3>

<p>Performs one iteration of optimization using a specified optimizer.
</p>


<h3>Usage</h3>

<pre><code class="language-R">mize_step(opt, par, fg)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>opt</code></td>
<td>
<p>Optimizer, created by <code>make_mize</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>par</code></td>
<td>
<p>Vector of initial values for the function to be optimized over.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fg</code></td>
<td>
<p>Function and gradient list. See the documentation of
<code>mize</code>.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>This function returns both the (hopefully) optimized vector of parameters, and
an updated version of the optimizer itself. This is intended to be used when
you want more control over the optimization process compared to the more black
box approach of the <code>mize</code> function. In return for having to
manually call this function every time you want the next iteration of
optimization, you gain the ability to do your own checks for convergence,
logging and so on, as well as take other action between iterations, e.g.
visualization.
</p>
<p>Normally calling this function should return a more optimized vector of
parameters than the input, or at  least leave the parameters unchanged if no
improvement was found, although this is determined by how the optimizer was
configured by <code>make_mize</code>. It is very possible to create an
optimizer that can cause a solution to diverge. It is the responsibility of
the caller to check that the result of the optimization step has actually
reduced the value returned from function being optimized.
</p>
<p>Details of the <code>fg</code> list can be found in the 'Details' section of
<code>mize</code>.
</p>


<h3>Value</h3>

<p>Result of the current optimization step, a list with components:
</p>

<ul>
<li>
<p><code>opt</code>. Updated version of the optimizer passed to the <code>opt</code>
argument Should be passed as the <code>opt</code> argument in the next iteration.
</p>
</li>
<li>
<p><code>par</code>. Updated version of the parameters passed to the
<code>par</code> argument. Should be passed as the <code>par</code> argument in the next
iteration.
</p>
</li>
<li>
<p><code>nf</code>. Running total number of function evaluations carried out
since iteration 1.
</p>
</li>
<li>
<p><code>ng</code>. Running total number of gradient evaluations carried out
since iteration 1.
</p>
</li>
<li>
<p><code>f</code>. Optional. The new value of the function, evaluated at the
returned value of <code>par</code>. Only present if calculated as part of the
optimization step (e.g. during a line search calculation).
</p>
</li>
<li>
<p><code>g</code>. Optional. The gradient vector, evaluated at the returned
value of <code>par</code>. Only present if the gradient was calculated as part of
the optimization step (e.g. during a line search calculation.)</p>
</li>
</ul>
<h3>See Also</h3>

<p><code>make_mize</code> to create a value to pass to <code>opt</code>,
<code>mize_init</code> to initialize <code>opt</code> before passing it to this
function for the first time. <code>mize</code> creates an optimizer and
carries out a full optimization with it.
</p>


<h3>Examples</h3>

<pre><code class="language-R">rosenbrock_fg &lt;- list(
  fn = function(x) {
    100 * (x[2] - x[1] * x[1])^2 + (1 - x[1])^2
  },
  gr = function(x) {
    c(
      -400 * x[1] * (x[2] - x[1] * x[1]) - 2 * (1 - x[1]),
      200 * (x[2] - x[1] * x[1])
    )
  }
)
rb0 &lt;- c(-1.2, 1)

opt &lt;- make_mize(
  method = "SD", line_search = "const", step0 = 0.0001,
  par = rb0, fg = rosenbrock_fg
)
par &lt;- rb0
for (iter in 1:3) {
  res &lt;- mize_step(opt, par, rosenbrock_fg)
  par &lt;- res$par
  opt &lt;- res$opt
}
</code></pre>


</div>