<div class="container">

<table style="width: 100%;"><tr>
<td>mlLda</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Supervised classification using linear discriminant analysis</h2>

<h3>Description</h3>

<p>Unified (formula-based) interface version of the linear discriminant
analysis algorithm provided by <code>MASS::lda()</code>.
</p>


<h3>Usage</h3>

<pre><code class="language-R">mlLda(train, ...)

ml_lda(train, ...)

## S3 method for class 'formula'
mlLda(formula, data, ..., subset, na.action)

## Default S3 method:
mlLda(train, response, ...)

## S3 method for class 'mlLda'
predict(
  object,
  newdata,
  type = c("class", "membership", "both", "projection"),
  prior = object$prior,
  dimension = NULL,
  method = c("plug-in", "predictive", "debiased", "cv"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>train</code></td>
<td>
<p>a matrix or data frame with predictors.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>further arguments passed to <code>MASS::lda()</code> or its  <code>predict()</code>
method (see the corresponding help page).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>formula</code></td>
<td>
<p>a formula with left term being the factor variable to predict
and the right term with the list of independent, predictive variables,
separated with a plus sign. If the data frame provided contains only the
dependent and independent variables, one can use the <code>class ~ .</code> short
version (that one is strongly encouraged). Variables with minus sign are
eliminated. Calculations on variables are possible according to usual
formula convention (possibly protected by using <code>I()</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>a data.frame to use as a training set.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>subset</code></td>
<td>
<p>index vector with the cases to define the training set in use
(this argument must be named, if provided).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>na.action</code></td>
<td>
<p>function to specify the action to be taken if <code>NA</code>s are
found. For <code>ml_lda()</code> <code>na.fail</code> is used by default. The calculation is
stopped if there is any <code>NA</code> in the data. Another option is <code>na.omit</code>,
where cases with missing values on any required variable are dropped (this
argument must be named, if provided). For the <code>predict()</code> method, the
default, and most suitable option, is <code>na.exclude</code>. In that case, rows with
<code>NA</code>s in <code style="white-space: pre;">⁠newdata=⁠</code> are excluded from prediction, but reinjected in the
final results so that the number of items is still the same (and in the
same order as <code style="white-space: pre;">⁠newdata=⁠</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>response</code></td>
<td>
<p>a vector of factor for the classification.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>object</code></td>
<td>
<p>an <strong>mlLda</strong> object</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>newdata</code></td>
<td>
<p>a new dataset with same conformation as the training set (same
variables, except may by the class for classification or dependent variable
for regression). Usually a test set, or a new dataset to be predicted.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>type</code></td>
<td>
<p>the type of prediction to return. <code>"class"</code> by default, the
predicted classes. Other options are <code>"membership"</code> the membership (a
number between 0 and 1) to the different classes, or <code>"both"</code> to return
classes and memberships. The <code>type = "projection"</code> returns a projection
of the individuals in the plane represented by the <code style="white-space: pre;">⁠dimension= ⁠</code>
discriminant components.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>prior</code></td>
<td>
<p>the prior probabilities of class membership. By default, the
prior are obtained from the object and, if they where not changed,
correspond to the proportions observed in the training set.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>dimension</code></td>
<td>
<p>the number of the predictive space to use. If <code>NULL</code> (the
default) a reasonable value is used. If this is less than min(p, ng-1),
only the first <code>dimension</code> discriminant components are used (except for
<code>method = "predictive"</code>), and only those dimensions are returned in x.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p><code>"plug-in"</code>, <code>"predictive"</code>, <code>"debiased"</code>, or <code>"cv"</code>.
<code>"plug-in"</code> (default) the usual unbiased parameter estimates are used.
With <code>"predictive"</code>, the parameters are integrated out using a vague prior.
With <code>"debiased"</code>, an unbiased estimator of the log posterior probabilities
is used. With <code>"cv"</code>, cross-validation is used instead. If you specify
<code>method = "cv"</code> then <code>cvpredict()</code> is used and you cannot provide
<code style="white-space: pre;">⁠newdata=⁠</code> in that case.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p><code>ml_lda()</code>/<code>mlLda()</code> creates an <strong>mlLda</strong>, <strong>mlearning</strong> object
containing the classifier and a lot of additional metadata used by the
functions and methods you can apply to it like <code>predict()</code> or
<code>cvpredict()</code>. In case you want to program new functions or extract
specific components, inspect the "unclassed" object using <code>unclass()</code>.
</p>


<h3>See Also</h3>

<p><code>mlearning()</code>, <code>cvpredict()</code>, <code>confusion()</code>, also <code>MASS::lda()</code> that
actually does the classification.
</p>


<h3>Examples</h3>

<pre><code class="language-R"># Prepare data: split into training set (2/3) and test set (1/3)
data("iris", package = "datasets")
train &lt;- c(1:34, 51:83, 101:133)
iris_train &lt;- iris[train, ]
iris_test &lt;- iris[-train, ]
# One case with missing data in train set, and another case in test set
iris_train[1, 1] &lt;- NA
iris_test[25, 2] &lt;- NA

iris_lda &lt;- ml_lda(data = iris_train, Species ~ .)
iris_lda
summary(iris_lda)
plot(iris_lda, col = as.numeric(response(iris_lda)) + 1)
# Prediction using a test set
predict(iris_lda, newdata = iris_test) # class (default type)
predict(iris_lda, type = "membership") # posterior probability
predict(iris_lda, type = "both") # both class and membership in a list
# Type projection
predict(iris_lda, type = "projection") # Projection on the LD axes
# Add test set items to the previous plot
points(predict(iris_lda, newdata = iris_test, type = "projection"),
  col = as.numeric(predict(iris_lda, newdata = iris_test)) + 1, pch = 19)
# predict() and confusion() should be used on a separate test set
# for unbiased estimation (or using cross-validation, bootstrap, ...)
# Wrong, cf. biased estimation (so-called, self-consistency)
confusion(iris_lda)
# Estimation using a separate test set
confusion(predict(iris_lda, newdata = iris_test), iris_test$Species)

# Another dataset (binary predictor... not optimal for lda, just for test)
data("HouseVotes84", package = "mlbench")
house_lda &lt;- ml_lda(data = HouseVotes84, na.action = na.omit, Class ~ .)
summary(house_lda)
confusion(house_lda) # Self-consistency (biased metrics)
print(confusion(house_lda), error.col = FALSE) # Without error column

# More complex formulas
# Exclude one or more variables
iris_lda2 &lt;- ml_lda(data = iris, Species ~ . - Sepal.Width)
summary(iris_lda2)
# With calculation
iris_lda3 &lt;- ml_lda(data = iris, Species ~ log(Petal.Length) +
  log(Petal.Width) + I(Petal.Length/Sepal.Length))
summary(iris_lda3)

# Factor levels with missing items are allowed
ir2 &lt;- iris[-(51:100), ] # No Iris versicolor in the training set
iris_lda4 &lt;- ml_lda(data = ir2, Species ~ .)
summary(iris_lda4) # missing class
# Missing levels are reinjected in class or membership by predict()
predict(iris_lda4, type = "both")
# ... but, of course, the classifier is wrong for Iris versicolor
confusion(predict(iris_lda4, newdata = iris), iris$Species)

# Simpler interface, but more memory-effective
iris_lda5 &lt;- ml_lda(train = iris[, -5], response = iris$Species)
summary(iris_lda5)
</code></pre>


</div>