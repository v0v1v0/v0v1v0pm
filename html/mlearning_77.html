<div class="container">

<table style="width: 100%;"><tr>
<td>mlearning</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Machine learning model for (un)supervised classification or regression</h2>

<h3>Description</h3>

<p>An <strong>mlearning</strong> object provides an unified (formula-based) interface to
several machine learning algorithms. They share the same interface and very
similar arguments. They conform to the formula-based approach, of say,
<code>stats::lm()</code> in base R, but with a coherent handling of missing data and
missing class levels. An optimized version exists for the simplified <code>y ~ .</code>
formula. Finally, cross-validation is also built-in.
</p>


<h3>Usage</h3>

<pre><code class="language-R">mlearning(
  formula,
  data,
  method,
  model.args,
  call = match.call(),
  ...,
  subset,
  na.action = na.fail
)

## S3 method for class 'mlearning'
print(x, ...)

## S3 method for class 'mlearning'
summary(object, ...)

## S3 method for class 'summary.mlearning'
print(x, ...)

## S3 method for class 'mlearning'
plot(x, y, ...)

## S3 method for class 'mlearning'
predict(
  object,
  newdata,
  type = c("class", "membership", "both"),
  method = c("direct", "cv"),
  na.action = na.exclude,
  ...
)

cvpredict(object, ...)

## S3 method for class 'mlearning'
cvpredict(
  object,
  type = c("class", "membership", "both"),
  cv.k = 10,
  cv.strat = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>formula</code></td>
<td>
<p>a formula with left term being the factor variable to predict
(for supervised classification), a vector of numbers (for regression) or
nothing (for unsupervised classification) and the right term with the list
of independent, predictive variables, separated with a plus sign. If the
data frame provided contains only the dependent and independent variables,
one can use the <code>class ~ .</code> short version (that one is strongly encouraged).
Variables with minus sign are eliminated. Calculations on variables are
possible according to usual formula convention (possibly protected by using
<code>I()</code>). Supervised classification, regression or unsupervised classification
are not available for all algorithms. Check respective help pages.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>a data.frame to use as a training set.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p><code>"direct"</code> (default) or <code>"cv"</code>. <code>"direct"</code> predicts new cases
in <code style="white-space: pre;">⁠newdata=⁠</code> if this argument is provided, or the cases in the training
set if not. Take care that not providing <code style="white-space: pre;">⁠newdata=⁠</code> means that you just
calculate the <strong>self-consistency</strong> of the classifier but cannot use the
metrics derived from these results for the assessment of its performances.
Either use a different dataset in <code style="white-space: pre;">⁠newdata=⁠</code> or use the alternate
cross-validation ("cv") technique. If you specify <code>method = "cv"</code> then
<code>cvpredict()</code> is used and you cannot provide <code style="white-space: pre;">⁠newdata=⁠</code> in that case. Other
methods may be provided by the various algorithms (check their help pages)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>model.args</code></td>
<td>
<p>arguments for formula modeling with substituted data and
subset... Not to be used by the end-user.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>call</code></td>
<td>
<p>the function call. Not to be used by the end-user.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>further arguments (depends on the method).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>subset</code></td>
<td>
<p>index vector with the cases to define the training set in use
(this argument must be named, if provided).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>na.action</code></td>
<td>
<p>function to specify the action to be taken if <code>NA</code>s are
found. For <code>ml_qda()</code> <code>na.fail</code> is used by default. The calculation is
stopped if there is any <code>NA</code> in the data. Another option is <code>na.omit</code>,
where cases with missing values on any required variable are dropped (this
argument must be named, if provided). For the <code>predict()</code> method, the
default, and most suitable option, is <code>na.exclude</code>. In that case, rows with
<code>NA</code>s in <code style="white-space: pre;">⁠newdata=⁠</code> are excluded from prediction, but reinjected in the
final results so that the number of items is still the same (and in the
same order as <code style="white-space: pre;">⁠newdata=⁠</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x, object</code></td>
<td>
<p>an <strong>mlearning</strong> object</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>a second <strong>mlearning</strong> object or nothing (not used in several plots)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>newdata</code></td>
<td>
<p>a new dataset with same conformation as the training set (same
variables, except may by the class for classification or dependent variable
for regression). Usually a test set, or a new dataset to be predicted.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>type</code></td>
<td>
<p>the type of prediction to return. <code>"class"</code> by default, the
predicted classes. Other options are <code>"membership"</code> the membership (a
number between 0 and 1) to the different classes, or <code>"both"</code> to return
classes and memberships. Other types may be provided for some algorithms
(read respective help pages).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cv.k</code></td>
<td>
<p>k for k-fold cross-validation, cf <code>ipred::errorest()</code>.
By default, 10.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cv.strat</code></td>
<td>
<p>is the subsampling stratified or not in cross-validation,
cf <code>ipred::errorest()</code>. <code>TRUE</code> by default.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>an <strong>mlearning</strong> object for <code>mlearning()</code>. Methods return their own
results that can be a <strong>mlearning</strong>, <strong>data.frame</strong>, <strong>vector</strong>, etc.
</p>


<h3>See Also</h3>

<p><code>ml_lda()</code>, <code>ml_qda()</code>, <code>ml_naive_bayes()</code>, <code>ml_nnet()</code>,
<code>ml_rpart()</code>, <code>ml_rforest()</code>, <code>ml_svm()</code>, <code>confusion()</code> and <code>prior()</code>. Also
<code>ipred::errorest()</code> that internally computes the cross-validation
in <code>cvpredict()</code>.
</p>


<h3>Examples</h3>

<pre><code class="language-R"># mlearning() should not be calle directly. Use the mlXXX() functions instead
# for instance, for Random Forest, use ml_rforest()/mlRforest()
# A typical classification involves several steps:
#
# 1) Prepare data: split into training set (2/3) and test set (1/3)
#    Data cleaning (elimination of unwanted variables), transformation of
#    others (scaling, log, ratios, numeric to factor, ...) may be necessary
#    here. Apply the same treatments on the training and test sets
data("iris", package = "datasets")
train &lt;- c(1:34, 51:83, 101:133) # Also random or stratified sampling
iris_train &lt;- iris[train, ]
iris_test &lt;- iris[-train, ]

# 2) Train the classifier, use of the simplified formula class ~ . encouraged
#    so, you may have to prepare the train/test sets to keep only relevant
#    variables and to possibly transform them before use
iris_rf &lt;- ml_rforest(data = iris_train, Species ~ .)
iris_rf
summary(iris_rf)
train(iris_rf)
response(iris_rf)

# 3) Find optimal values for the parameters of the model
#    This is usally done iteratively. Just an example with ntree where a plot
#    exists to help finding optimal value
plot(iris_rf)
# For such a relatively simple case, 50 trees are enough, retrain with it
iris_rf &lt;- ml_rforest(data = iris_train, Species ~ ., ntree = 50)
summary(iris_rf)

# 4) Study the classifier performances. Several metrics and tools exists
#    like ROC curves, AUC, etc. Tools provided here are the confusion matrix
#    and the metrics that are calculated on it.
predict(iris_rf) # Default type is class
predict(iris_rf, type = "membership")
predict(iris_rf, type = "both")
# Confusion matrice and metrics using 10-fols cross-validation
iris_rf_conf &lt;- confusion(iris_rf, method = "cv")
iris_rf_conf
summary(iris_rf_conf)
# Note you may want to manipulate priors too, see ?prior

# 5) Go back to step #1 and refine the process until you are happy with the
#    results. Then, you can use the classifier to predict unknown items.
</code></pre>


</div>