<div class="container">

<table style="width: 100%;"><tr>
<td>mlLvq</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Supervised classification using learning vector quantization</h2>

<h3>Description</h3>

<p>Unified (formula-based) interface version of the learning vector quantization
algorithms provided by <code>class::olvq1()</code>, <code>class::lvq1()</code>, <code>class::lvq2()</code>,
and <code>class::lvq3()</code>.
</p>


<h3>Usage</h3>

<pre><code class="language-R">mlLvq(train, ...)

ml_lvq(train, ...)

## S3 method for class 'formula'
mlLvq(
  formula,
  data,
  k.nn = 5,
  size,
  prior,
  algorithm = "olvq1",
  ...,
  subset,
  na.action
)

## Default S3 method:
mlLvq(train, response, k.nn = 5, size, prior, algorithm = "olvq1", ...)

## S3 method for class 'mlLvq'
summary(object, ...)

## S3 method for class 'summary.mlLvq'
print(x, ...)

## S3 method for class 'mlLvq'
predict(
  object,
  newdata,
  type = "class",
  method = c("direct", "cv"),
  na.action = na.exclude,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>train</code></td>
<td>
<p>a matrix or data frame with predictors.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>further arguments passed to the classification method or its
<code>predict()</code> method (not used here for now).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>formula</code></td>
<td>
<p>a formula with left term being the factor variable to predict
and the right term with the list of independent, predictive variables,
separated with a plus sign. If the data frame provided contains only the
dependent and independent variables, one can use the <code>class ~ .</code> short
version (that one is strongly encouraged). Variables with minus sign are
eliminated. Calculations on variables are possible according to usual formula
convention (possibly protected by using <code>I()</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>a data.frame to use as a training set.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>k.nn</code></td>
<td>
<p>k used for k-NN number of neighbor considered. Default is 5.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>size</code></td>
<td>
<p>the size of the codebook. Defaults to
min(round(0.4 \* nc \* (nc - 1 + p/2),0), n) where nc is the number of
classes.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>prior</code></td>
<td>
<p>probabilities to represent classes in the codebook (default
values are the proportions in the training set).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>algorithm</code></td>
<td>
<p><code>"olvq1"</code> (by default, the optimized 'lvq1' version), or
<code>"lvq1"</code>, <code>"lvq2"</code>, <code>"lvq3"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>subset</code></td>
<td>
<p>index vector with the cases to define the training set in use
(this argument must be named, if provided).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>na.action</code></td>
<td>
<p>function to specify the action to be taken if <code>NA</code>s are
found. For [ml_lvq)] <code>na.fail</code> is used by default. The calculation is
stopped if there is any <code>NA</code> in the data. Another option is <code>na.omit</code>,
where cases with missing values on any required variable are dropped (this
argument must be named, if provided). For the <code>predict()</code> method, the
default, and most suitable option, is <code>na.exclude</code>. In that case, rows with
<code>NA</code>s in <code style="white-space: pre;">⁠newdata=⁠</code> are excluded from prediction, but reinjected in the
final results so that the number of items is still the same (and in the
same order as <code style="white-space: pre;">⁠newdata=⁠</code>).
</p>
<p>[ml_lvq)]: R:ml_lvq)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>response</code></td>
<td>
<p>a vector of factor of the classes.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x, object</code></td>
<td>
<p>an <strong>mlLvq</strong> object</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>newdata</code></td>
<td>
<p>a new dataset with same conformation as the training set (same
variables, except may by the class for classification or dependent variable
for regression). Usually a test set, or a new dataset to be predicted.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>type</code></td>
<td>
<p>the type of prediction to return. For this method, only <code>"class"</code>
is accepted, and it is the default. It returns the predicted classes.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p><code>"direct"</code> (default) or <code>"cv"</code>. <code>"direct"</code> predicts new cases in
<code style="white-space: pre;">⁠newdata=⁠</code> if this argument is provided, or the cases in the training set
if not. Take care that not providing <code style="white-space: pre;">⁠newdata=⁠</code> means that you just
calculate the <strong>self-consistency</strong> of the classifier but cannot use the
metrics derived from these results for the assessment of its performances.
Either use a different dataset in <code style="white-space: pre;">⁠newdata=⁠</code> or use the alternate
cross-validation ("cv") technique. If you specify <code>method = "cv"</code> then
<code>cvpredict()</code> is used and you cannot provide <code style="white-space: pre;">⁠newdata=⁠</code> in that case.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p><code>ml_lvq()</code>/<code>mlLvq()</code> creates an <strong>mlLvq</strong>, <strong>mlearning</strong> object
containing the classifier and a lot of additional metadata used by the
functions and methods you can apply to it like <code>predict()</code> or
<code>cvpredict()</code>. In case you want to program new functions or extract
specific components, inspect the "unclassed" object using <code>unclass()</code>.
</p>


<h3>See Also</h3>

<p><code>mlearning()</code>, <code>cvpredict()</code>, <code>confusion()</code>, also <code>class::olvq1()</code>,
<code>class::lvq1()</code>, <code>class::lvq2()</code>, and <code>class::lvq3()</code> that actually do the
classification.
</p>


<h3>Examples</h3>

<pre><code class="language-R"># Prepare data: split into training set (2/3) and test set (1/3)
data("iris", package = "datasets")
train &lt;- c(1:34, 51:83, 101:133)
iris_train &lt;- iris[train, ]
iris_test &lt;- iris[-train, ]
# One case with missing data in train set, and another case in test set
iris_train[1, 1] &lt;- NA
iris_test[25, 2] &lt;- NA

iris_lvq &lt;- ml_lvq(data = iris_train, Species ~ .)
summary(iris_lvq)
predict(iris_lvq) # This object only returns classes
#' # Self-consistency, do not use for assessing classifier performances!
confusion(iris_lvq)
# Use an independent test set instead
confusion(predict(iris_lvq, newdata = iris_test), iris_test$Species)
</code></pre>


</div>