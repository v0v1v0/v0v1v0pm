<div class="container">

<table style="width: 100%;"><tr>
<td>metric</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>metric</h2>

<h3>Description</h3>

<p>Returns a metric function which can be used for the experiments
(especially the cross-validation experiments) to compute the performance.
</p>


<h3>Usage</h3>

<pre><code class="language-R">metric(name)
</code></pre>


<h3>Arguments</h3>

<table><tr style="vertical-align: top;">
<td><code>name</code></td>
<td>
<p>A metric name. Accepted names are the names of the metric
function exported from the <code>mlr3measures</code> R package.</p>
</td>
</tr></table>
<h3>Details</h3>

<p>This function is a utility function to select performance metrics from the
<code>mlr3measures</code> R package and to reformat them into a form that is required
by the <code>mlexperiments</code> R package. For <code>mlexperiments</code> it is required that
a metric function takes the two arguments <code>ground_truth</code>, and <code>predictions</code>,
as well as additional names arguments that are necessary to compute the
performance, which are provided via the ellipsis argument (...).
When using the performance metric with an experiment of class
<code>"MLCrossValidation"</code>, such arguments can be defined as a list provided to
the field <code>performance_metric_args</code> of the R6 class.
The main purpose of <code>mlexperiments::metric()</code> is convenience and to
re-use already existing implementations of the metrics. However, custom
functions can be provided easily to compute the performance of the
experiments, simply by providing a function that takes the above mentioned
arguments and returns one performance metric value.
</p>


<h3>Value</h3>

<p>Returns a function that can be used as function to calculate the
performance metric throughout the experiments.
</p>


<h3>Examples</h3>

<pre><code class="language-R">metric("auc")

</code></pre>


</div>