<div class="container">

<table style="width: 100%;"><tr>
<td>mlflow_rfunc_serve</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Serve an RFunc MLflow Model</h2>

<h3>Description</h3>

<p>Serves an RFunc MLflow model as a local REST API server. This interface provides similar
functionality to “mlflow models serve“ cli command, however, it can only be used to deploy
models that include RFunc flavor. The deployed server supports standard mlflow models interface
with /ping and /invocation endpoints. In addition, R function models also support deprecated
/predict endpoint for generating predictions. The /predict endpoint will be removed in a future
version of mlflow.
</p>


<h3>Usage</h3>

<pre><code class="language-R">mlflow_rfunc_serve(
  model_uri,
  host = "127.0.0.1",
  port = 8090,
  daemonized = FALSE,
  browse = !daemonized,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>model_uri</code></td>
<td>
<p>The location, in URI format, of the MLflow model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>host</code></td>
<td>
<p>Address to use to serve model, as a string.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>port</code></td>
<td>
<p>Port to use to serve model, as numeric.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>daemonized</code></td>
<td>
<p>Makes 'httpuv' server daemonized so R interactive sessions
are not blocked to handle requests. To terminate a daemonized server, call
'httpuv::stopDaemonizedServer()' with the handle returned from this call.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>browse</code></td>
<td>
<p>Launch browser with serving landing page?</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Optional arguments passed to 'mlflow_predict()'.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The URI scheme must be supported by MLflow - i.e. there has to be an MLflow artifact
repository corresponding to the scheme of the URI. The content is expected to point to a
directory containing MLmodel. The following are examples of valid model uris:
</p>
<p>- “file:///absolute/path/to/local/model“
- “file:relative/path/to/local/model“
- “s3://my_bucket/path/to/model“
- “runs:/&lt;mlflow_run_id&gt;/run-relative/path/to/model“
- “models:/&lt;model_name&gt;/&lt;model_version&gt;“
- “models:/&lt;model_name&gt;/&lt;stage&gt;“
</p>
<p>For more information about supported URI schemes, see the Artifacts Documentation at
https://www.mlflow.org/docs/latest/tracking.html#artifact-stores.
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Not run: 
library(mlflow)

# save simple model with constant prediction
mlflow_save_model(function(df) 1, "mlflow_constant")

# serve an existing model over a web interface
mlflow_rfunc_serve("mlflow_constant")

# request prediction from server
httr::POST("http://127.0.0.1:8090/predict/")

## End(Not run)
</code></pre>


</div>