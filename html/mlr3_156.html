<div class="container">

<table style="width: 100%;"><tr>
<td>MeasureSimilarity</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Similarity Measure</h2>

<h3>Description</h3>

<p>This measure specializes Measure for measures quantifying the similarity of
sets of selected features.
To calculate similarity measures, the Learner must have the property
<code>"selected_features"</code>.
</p>

<ul>
<li> <p><code>task_type</code> is set to <code>NA_character_</code>.
</p>
</li>
<li> <p><code>average</code> is set to <code>"custom"</code>.
</p>
</li>
</ul>
<p>Predefined measures can be found in the dictionary
mlr_measures, prefixed with <code>"sim."</code>.
</p>


<h3>Super class</h3>

<p><code>mlr3::Measure</code> -&gt; <code>MeasureSimilarity</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-MeasureSimilarity-new"><code>MeasureSimilarity$new()</code></a>
</p>
</li>
<li> <p><a href="#method-MeasureSimilarity-clone"><code>MeasureSimilarity$clone()</code></a>
</p>
</li>
</ul>
<details open><summary>Inherited methods</summary><ul>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Measure" data-id="aggregate"><a href="../../mlr3/html/Measure.html#method-Measure-aggregate"><code>mlr3::Measure$aggregate()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Measure" data-id="format"><a href="../../mlr3/html/Measure.html#method-Measure-format"><code>mlr3::Measure$format()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Measure" data-id="help"><a href="../../mlr3/html/Measure.html#method-Measure-help"><code>mlr3::Measure$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Measure" data-id="print"><a href="../../mlr3/html/Measure.html#method-Measure-print"><code>mlr3::Measure$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Measure" data-id="score"><a href="../../mlr3/html/Measure.html#method-Measure-score"><code>mlr3::Measure$score()</code></a></span></li>
</ul></details><hr>
<a id="method-MeasureSimilarity-new"></a>



<h4>Method <code>new()</code>
</h4>

<p>Creates a new instance of this R6 class.
</p>


<h5>Usage</h5>

<div class="r"><pre>MeasureSimilarity$new(
  id,
  param_set = ps(),
  range,
  minimize = NA,
  average = "macro",
  aggregator = NULL,
  properties = character(),
  predict_type = NA_character_,
  predict_sets = "test",
  task_properties = character(),
  packages = character(),
  label = NA_character_,
  man = NA_character_
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>id</code></dt>
<dd>
<p>(<code>character(1)</code>)<br>
Identifier for the new instance.</p>
</dd>
<dt><code>param_set</code></dt>
<dd>
<p>(paradox::ParamSet)<br>
Set of hyperparameters.</p>
</dd>
<dt><code>range</code></dt>
<dd>
<p>(<code>numeric(2)</code>)<br>
Feasible range for this measure as <code>c(lower_bound, upper_bound)</code>.
Both bounds may be infinite.</p>
</dd>
<dt><code>minimize</code></dt>
<dd>
<p>(<code>logical(1)</code>)<br>
Set to <code>TRUE</code> if good predictions correspond to small values,
and to <code>FALSE</code> if good predictions correspond to large values.
If set to <code>NA</code> (default), tuning this measure is not possible.</p>
</dd>
<dt><code>average</code></dt>
<dd>
<p>(<code>character(1)</code>)<br>
How to average multiple Predictions from a ResampleResult.
</p>
<p>The default, <code>"macro"</code>, calculates the individual performances scores for each Prediction and then uses the
function defined in <code style="white-space: pre;">⁠$aggregator⁠</code> to average them to a single number.
</p>
<p>If set to <code>"micro"</code>, the individual Prediction objects are first combined into a single new Prediction object which is then used to assess the performance.
The function in <code style="white-space: pre;">⁠$aggregator⁠</code> is not used in this case.</p>
</dd>
<dt><code>aggregator</code></dt>
<dd>
<p>(<code style="white-space: pre;">⁠function()⁠</code>)<br>
Function to aggregate over multiple iterations. The role of this function depends on
the value of field <code>"average"</code>:
</p>

<ul>
<li> <p><code>"macro"</code>: A numeric vector of scores (one per iteration) is passed.
The aggregate function defaults to <code>mean()</code> in this case.
</p>
</li>
<li> <p><code>"micro"</code>: The <code>aggregator</code> function is not used.
Instead, predictions from multiple iterations are first combined and then
scored in one go.
</p>
</li>
<li> <p><code>"custom"</code>: A ResampleResult is passed to the aggregate function.
</p>
</li>
</ul>
</dd>
<dt><code>properties</code></dt>
<dd>
<p>(<code>character()</code>)<br>
Properties of the measure.
Must be a subset of mlr_reflections$measure_properties.
Supported by <code>mlr3</code>:
</p>

<ul>
<li> <p><code>"requires_task"</code> (requires the complete Task),
</p>
</li>
<li> <p><code>"requires_learner"</code> (requires the trained Learner),
</p>
</li>
<li> <p><code>"requires_model"</code> (requires the trained Learner, including the fitted
model),
</p>
</li>
<li> <p><code>"requires_train_set"</code> (requires the training indices from the Resampling), and
</p>
</li>
<li> <p><code>"na_score"</code> (the measure is expected to occasionally return <code>NA</code> or <code>NaN</code>).
</p>
</li>
<li> <p><code>"primary_iters"</code> (the measure explictly handles resamplings that only use a subset
of their iterations for the point estimate).
</p>
</li>
<li> <p><code>"requires_no_prediction"</code> (No prediction is required; This usually means that the
measure extracts some information from the learner state.).
</p>
</li>
</ul>
</dd>
<dt><code>predict_type</code></dt>
<dd>
<p>(<code>character(1)</code>)<br>
Required predict type of the Learner.
Possible values are stored in mlr_reflections$learner_predict_types.</p>
</dd>
<dt><code>predict_sets</code></dt>
<dd>
<p>(<code>character()</code>)<br>
Prediction sets to operate on, used in <code>aggregate()</code> to extract the matching <code>predict_sets</code> from the ResampleResult.
Multiple predict sets are calculated by the respective Learner during <code>resample()</code>/<code>benchmark()</code>.
Must be a non-empty subset of <code style="white-space: pre;">⁠{"train", "test", "internal_valid"}⁠</code>.
If multiple sets are provided, these are first combined to a single prediction object.
Default is <code>"test"</code>.</p>
</dd>
<dt><code>task_properties</code></dt>
<dd>
<p>(<code>character()</code>)<br>
Required task properties, see Task.</p>
</dd>
<dt><code>packages</code></dt>
<dd>
<p>(<code>character()</code>)<br>
Set of required packages.
A warning is signaled by the constructor if at least one of the packages is not installed,
but loaded (not attached) later on-demand via <code>requireNamespace()</code>.</p>
</dd>
<dt><code>label</code></dt>
<dd>
<p>(<code>character(1)</code>)<br>
Label for the new instance.</p>
</dd>
<dt><code>man</code></dt>
<dd>
<p>(<code>character(1)</code>)<br>
String in the format <code style="white-space: pre;">⁠[pkg]::[topic]⁠</code> pointing to a manual page for this object.
The referenced help package can be opened via method <code style="white-space: pre;">⁠$help()⁠</code>.</p>
</dd>
</dl>
</div>


<hr>
<a id="method-MeasureSimilarity-clone"></a>



<h4>Method <code>clone()</code>
</h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>MeasureSimilarity$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt>
<dd>
<p>Whether to make a deep clone.</p>
</dd>
</dl>
</div>




<h3>See Also</h3>


<ul>
<li>
<p> Chapter in the <a href="https://mlr3book.mlr-org.com/">mlr3book</a>:
<a href="https://mlr3book.mlr-org.com/chapters/chapter2/data_and_basic_modeling.html#sec-eval">https://mlr3book.mlr-org.com/chapters/chapter2/data_and_basic_modeling.html#sec-eval</a>
</p>
</li>
<li>
<p> Package <a href="https://CRAN.R-project.org/package=mlr3measures"><span class="pkg">mlr3measures</span></a> for the scoring functions.
Dictionary of Measures: mlr_measures
<code>as.data.table(mlr_measures)</code> for a table of available Measures in the running session (depending on the loaded packages).
</p>
</li>
<li>
<p> Extension packages for additional task types:
</p>

<ul>
<li> <p><a href="https://CRAN.R-project.org/package=mlr3proba"><span class="pkg">mlr3proba</span></a> for probabilistic supervised regression and survival analysis.
</p>
</li>
<li> <p><a href="https://CRAN.R-project.org/package=mlr3cluster"><span class="pkg">mlr3cluster</span></a> for unsupervised clustering.
</p>
</li>
</ul>
</li>
</ul>
<p>Other Measure: 
<code>Measure</code>,
<code>MeasureClassif</code>,
<code>MeasureRegr</code>,
<code>mlr_measures</code>,
<code>mlr_measures_aic</code>,
<code>mlr_measures_bic</code>,
<code>mlr_measures_classif.costs</code>,
<code>mlr_measures_debug_classif</code>,
<code>mlr_measures_elapsed_time</code>,
<code>mlr_measures_internal_valid_score</code>,
<code>mlr_measures_oob_error</code>,
<code>mlr_measures_regr.rsq</code>,
<code>mlr_measures_selected_features</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">task = tsk("penguins")
learners = list(
  lrn("classif.rpart", maxdepth = 1, id = "r1"),
  lrn("classif.rpart", maxdepth = 2, id = "r2")
)
resampling = rsmp("cv", folds = 3)
grid = benchmark_grid(task, learners, resampling)
bmr = benchmark(grid, store_models = TRUE)
bmr$aggregate(msrs(c("classif.ce", "sim.jaccard")))
</code></pre>


</div>