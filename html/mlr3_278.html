<div class="container">

<table style="width: 100%;"><tr>
<td>ResampleResult</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Container for Results of <code>resample()</code>
</h2>

<h3>Description</h3>

<p>This is the result container object returned by <code>resample()</code>.
</p>
<p>Note that all stored objects are accessed by reference.
Do not modify any object without cloning it first.
</p>
<p>ResampleResults can be visualized via <a href="https://CRAN.R-project.org/package=mlr3viz"><span class="pkg">mlr3viz</span></a>'s <code>autoplot()</code> function.
</p>


<h3>S3 Methods</h3>


<ul>
<li> <p><code>as.data.table(rr, reassemble_learners = TRUE, convert_predictions = TRUE, predict_sets = "test")</code><br>
ResampleResult -&gt; <code>data.table::data.table()</code><br>
Returns a tabular view of the internal data.
</p>
</li>
<li> <p><code>c(...)</code><br>
(ResampleResult, ...) -&gt; BenchmarkResult<br>
Combines multiple objects convertible to BenchmarkResult into a new BenchmarkResult.
</p>
</li>
</ul>
<h3>Active bindings</h3>

<div class="r6-active-bindings">

<dl>
<dt><code>task_type</code></dt>
<dd>
<p>(<code>character(1)</code>)<br>
Task type of objects in the <code>ResampleResult</code>, e.g. <code>"classif"</code> or <code>"regr"</code>.
This is <code>NA</code> for empty ResampleResults.</p>
</dd>
<dt><code>uhash</code></dt>
<dd>
<p>(<code>character(1)</code>)<br>
Unique hash for this object.</p>
</dd>
<dt><code>iters</code></dt>
<dd>
<p>(<code>integer(1)</code>)<br>
Number of resampling iterations stored in the <code>ResampleResult</code>.</p>
</dd>
<dt><code>task</code></dt>
<dd>
<p>(Task)<br>
The task <code>resample()</code> operated on.</p>
</dd>
<dt><code>learner</code></dt>
<dd>
<p>(Learner)<br>
Learner prototype <code>resample()</code> operated on.
For a list of <strong>trained</strong> learners, see methods <code style="white-space: pre;">⁠$learners()⁠</code>.</p>
</dd>
<dt><code>resampling</code></dt>
<dd>
<p>(Resampling)<br>
Instantiated Resampling object which stores the splits into training and test.</p>
</dd>
<dt><code>learners</code></dt>
<dd>
<p>(list of Learner)<br>
List of trained learners, sorted by resampling iteration.</p>
</dd>
<dt><code>warnings</code></dt>
<dd>
<p>(<code>data.table::data.table()</code>)<br>
A table with all warning messages.
Column names are <code>"iteration"</code> and <code>"msg"</code>.
Note that there can be multiple rows per resampling iteration if multiple warnings have been recorded.</p>
</dd>
<dt><code>errors</code></dt>
<dd>
<p>(<code>data.table::data.table()</code>)<br>
A table with all error messages.
Column names are <code>"iteration"</code> and <code>"msg"</code>.
Note that there can be multiple rows per resampling iteration if multiple errors have been recorded.</p>
</dd>
</dl>
</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-ResampleResult-new"><code>ResampleResult$new()</code></a>
</p>
</li>
<li> <p><a href="#method-ResampleResult-format"><code>ResampleResult$format()</code></a>
</p>
</li>
<li> <p><a href="#method-ResampleResult-print"><code>ResampleResult$print()</code></a>
</p>
</li>
<li> <p><a href="#method-ResampleResult-help"><code>ResampleResult$help()</code></a>
</p>
</li>
<li> <p><a href="#method-ResampleResult-prediction"><code>ResampleResult$prediction()</code></a>
</p>
</li>
<li> <p><a href="#method-ResampleResult-predictions"><code>ResampleResult$predictions()</code></a>
</p>
</li>
<li> <p><a href="#method-ResampleResult-score"><code>ResampleResult$score()</code></a>
</p>
</li>
<li> <p><a href="#method-ResampleResult-obs_loss"><code>ResampleResult$obs_loss()</code></a>
</p>
</li>
<li> <p><a href="#method-ResampleResult-aggregate"><code>ResampleResult$aggregate()</code></a>
</p>
</li>
<li> <p><a href="#method-ResampleResult-filter"><code>ResampleResult$filter()</code></a>
</p>
</li>
<li> <p><a href="#method-ResampleResult-discard"><code>ResampleResult$discard()</code></a>
</p>
</li>
<li> <p><a href="#method-ResampleResult-marshal"><code>ResampleResult$marshal()</code></a>
</p>
</li>
<li> <p><a href="#method-ResampleResult-unmarshal"><code>ResampleResult$unmarshal()</code></a>
</p>
</li>
<li> <p><a href="#method-ResampleResult-clone"><code>ResampleResult$clone()</code></a>
</p>
</li>
</ul>
<hr>
<a id="method-ResampleResult-new"></a>



<h4>Method <code>new()</code>
</h4>

<p>Creates a new instance of this R6 class.
An alternative construction method is provided by <code>as_resample_result()</code>.
</p>


<h5>Usage</h5>

<div class="r"><pre>ResampleResult$new(data = ResultData$new(), view = NULL)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>data</code></dt>
<dd>
<p>(ResultData | <code>data.table()</code>)<br>
An object of type ResultData, either extracted from another ResampleResult, another
BenchmarkResult, or manually constructed with <code>as_result_data()</code>.</p>
</dd>
<dt><code>view</code></dt>
<dd>
<p>(<code>character()</code>)<br>
Single <code>uhash</code> of the ResultData to operate on.
Used internally for optimizations.</p>
</dd>
</dl>
</div>


<hr>
<a id="method-ResampleResult-format"></a>



<h4>Method <code>format()</code>
</h4>

<p>Helper for print outputs.
</p>


<h5>Usage</h5>

<div class="r"><pre>ResampleResult$format(...)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>...</code></dt>
<dd>
<p>(ignored).</p>
</dd>
</dl>
</div>


<hr>
<a id="method-ResampleResult-print"></a>



<h4>Method <code>print()</code>
</h4>

<p>Printer.
</p>


<h5>Usage</h5>

<div class="r"><pre>ResampleResult$print(...)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>...</code></dt>
<dd>
<p>(ignored).</p>
</dd>
</dl>
</div>


<hr>
<a id="method-ResampleResult-help"></a>



<h4>Method <code>help()</code>
</h4>

<p>Opens the corresponding help page referenced by field <code style="white-space: pre;">⁠$man⁠</code>.
</p>


<h5>Usage</h5>

<div class="r"><pre>ResampleResult$help()</pre></div>


<hr>
<a id="method-ResampleResult-prediction"></a>



<h4>Method <code>prediction()</code>
</h4>

<p>Combined Prediction of all individual resampling iterations, and all provided predict sets.
Note that, per default, most performance measures do not operate on this object directly,
but instead on the prediction objects from the resampling iterations separately, and then combine
the performance scores with the aggregate function of the respective Measure (macro averaging).
</p>
<p>If you calculate the performance on this prediction object directly, this is called micro averaging.
</p>


<h5>Usage</h5>

<div class="r"><pre>ResampleResult$prediction(predict_sets = "test")</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>predict_sets</code></dt>
<dd>
<p>(<code>character()</code>)<br>
Subset of <code style="white-space: pre;">⁠{"train", "test"}⁠</code>.</p>
</dd>
</dl>
</div>



<h5>Returns</h5>

<p>Prediction or empty <code>list()</code> if no predictions are available.
</p>


<hr>
<a id="method-ResampleResult-predictions"></a>



<h4>Method <code>predictions()</code>
</h4>

<p>List of prediction objects, sorted by resampling iteration.
If multiple sets are given, these are combined to a single one for each iteration.
</p>
<p>If you evaluate the performance on all of the returned prediction objects and then average them, this
is called macro averaging. For micro averaging, operate on the combined prediction object as returned by
<code style="white-space: pre;">⁠$prediction()⁠</code>.
</p>


<h5>Usage</h5>

<div class="r"><pre>ResampleResult$predictions(predict_sets = "test")</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>predict_sets</code></dt>
<dd>
<p>(<code>character()</code>)<br>
Subset of <code style="white-space: pre;">⁠{"train", "test", "internal_valid"}⁠</code>.</p>
</dd>
</dl>
</div>



<h5>Returns</h5>

<p>List of Prediction objects, one per element in <code>predict_sets</code>.
Or list of empty <code>list()</code>s if no predictions are available.
</p>


<hr>
<a id="method-ResampleResult-score"></a>



<h4>Method <code>score()</code>
</h4>

<p>Returns a table with one row for each resampling iteration, including all involved objects:
Task, Learner, Resampling, iteration number (<code>integer(1)</code>), and (if enabled)
one Prediction for each predict set of the Learner.
Additionally, a column with the individual (per resampling iteration) performance is added
for each Measure in <code>measures</code>, named with the id of the respective measure id.
If <code>measures</code> is <code>NULL</code>, <code>measures</code> defaults to the return value of <code>default_measures()</code>.
</p>


<h5>Usage</h5>

<div class="r"><pre>ResampleResult$score(
  measures = NULL,
  ids = TRUE,
  conditions = FALSE,
  predictions = TRUE
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>measures</code></dt>
<dd>
<p>(Measure | list of Measure)<br>
Measure(s) to calculate.</p>
</dd>
<dt><code>ids</code></dt>
<dd>
<p>(<code>logical(1)</code>)<br>
If <code>ids</code> is <code>TRUE</code>, extra columns with the ids of objects (<code>"task_id"</code>, <code>"learner_id"</code>, <code>"resampling_id"</code>)
are added to the returned table.
These allow to subset more conveniently.</p>
</dd>
<dt><code>conditions</code></dt>
<dd>
<p>(<code>logical(1)</code>)<br>
Adds condition messages (<code>"warnings"</code>, <code>"errors"</code>) as extra
list columns of character vectors to the returned table</p>
</dd>
<dt><code>predictions</code></dt>
<dd>
<p>(<code>logical(1)</code>)<br>
Additionally return prediction objects, one column for each <code>predict_set</code> of the learner.
Columns are named <code>"prediction_train"</code>, <code>"prediction_test"</code> and <code>"prediction_internal_valid"</code>,
if present.</p>
</dd>
</dl>
</div>



<h5>Returns</h5>

<p><code>data.table::data.table()</code>.
</p>


<hr>
<a id="method-ResampleResult-obs_loss"></a>



<h4>Method <code>obs_loss()</code>
</h4>

<p>Calculates the observation-wise loss via the loss function set in the
Measure's field <code>obs_loss</code>.
Returns a <code>data.table()</code> with the columns of the matching Prediction object plus
one additional numeric column for each measure, named with the respective measure id.
If there is no observation-wise loss function for the measure, the column is filled with
<code>NA</code> values.
Note that some measures such as RMSE, do have an <code style="white-space: pre;">⁠$obs_loss⁠</code>, but they require an
additional transformation after aggregation, in this example taking the square-root.
</p>


<h5>Usage</h5>

<div class="r"><pre>ResampleResult$obs_loss(measures = NULL, predict_sets = "test")</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>measures</code></dt>
<dd>
<p>(Measure | list of Measure)<br>
Measure(s) to calculate.</p>
</dd>
<dt><code>predict_sets</code></dt>
<dd>
<p>(<code>character()</code>)<br>
The predict sets.</p>
</dd>
</dl>
</div>


<hr>
<a id="method-ResampleResult-aggregate"></a>



<h4>Method <code>aggregate()</code>
</h4>

<p>Calculates and aggregates performance values for all provided measures, according to the
respective aggregation function in Measure.
If <code>measures</code> is <code>NULL</code>, <code>measures</code> defaults to the return value of <code>default_measures()</code>.
</p>


<h5>Usage</h5>

<div class="r"><pre>ResampleResult$aggregate(measures = NULL)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>measures</code></dt>
<dd>
<p>(Measure | list of Measure)<br>
Measure(s) to calculate.</p>
</dd>
</dl>
</div>



<h5>Returns</h5>

<p>Named <code>numeric()</code>.
</p>


<hr>
<a id="method-ResampleResult-filter"></a>



<h4>Method <code>filter()</code>
</h4>

<p>Subsets the ResampleResult, reducing it to only keep the iterations specified in <code>iters</code>.
</p>


<h5>Usage</h5>

<div class="r"><pre>ResampleResult$filter(iters)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>iters</code></dt>
<dd>
<p>(<code>integer()</code>)<br>
Resampling iterations to keep.</p>
</dd>
</dl>
</div>



<h5>Returns</h5>

<p>Returns the object itself, but modified <strong>by reference</strong>.
You need to explicitly <code style="white-space: pre;">⁠$clone()⁠</code> the object beforehand if you want to keeps
the object in its previous state.
</p>


<hr>
<a id="method-ResampleResult-discard"></a>



<h4>Method <code>discard()</code>
</h4>

<p>Shrinks the ResampleResult by discarding parts of the internally stored data.
Note that certain operations might stop work, e.g. extracting
importance values from learners or calculating measures requiring the task's data.
</p>


<h5>Usage</h5>

<div class="r"><pre>ResampleResult$discard(backends = FALSE, models = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>backends</code></dt>
<dd>
<p>(<code>logical(1)</code>)<br>
If <code>TRUE</code>, the DataBackend is removed from all stored Tasks.</p>
</dd>
<dt><code>models</code></dt>
<dd>
<p>(<code>logical(1)</code>)<br>
If <code>TRUE</code>, the stored model is removed from all Learners.</p>
</dd>
</dl>
</div>



<h5>Returns</h5>

<p>Returns the object itself, but modified <strong>by reference</strong>.
You need to explicitly <code style="white-space: pre;">⁠$clone()⁠</code> the object beforehand if you want to keeps
the object in its previous state.
</p>


<hr>
<a id="method-ResampleResult-marshal"></a>



<h4>Method <code>marshal()</code>
</h4>

<p>Marshals all stored models.
</p>


<h5>Usage</h5>

<div class="r"><pre>ResampleResult$marshal(...)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>...</code></dt>
<dd>
<p>(any)<br>
Additional arguments passed to <code>marshal_model()</code>.</p>
</dd>
</dl>
</div>


<hr>
<a id="method-ResampleResult-unmarshal"></a>



<h4>Method <code>unmarshal()</code>
</h4>

<p>Unmarshals all stored models.
</p>


<h5>Usage</h5>

<div class="r"><pre>ResampleResult$unmarshal(...)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>...</code></dt>
<dd>
<p>(any)<br>
Additional arguments passed to <code>unmarshal_model()</code>.</p>
</dd>
</dl>
</div>


<hr>
<a id="method-ResampleResult-clone"></a>



<h4>Method <code>clone()</code>
</h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>ResampleResult$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt>
<dd>
<p>Whether to make a deep clone.</p>
</dd>
</dl>
</div>




<h3>See Also</h3>


<ul>
<li> <p><code>as_benchmark_result()</code> to convert to a BenchmarkResult.
</p>
</li>
<li>
<p> Chapter in the <a href="https://mlr3book.mlr-org.com/">mlr3book</a>:
<a href="https://mlr3book.mlr-org.com/chapters/chapter3/evaluation_and_benchmarking.html#sec-resampling">https://mlr3book.mlr-org.com/chapters/chapter3/evaluation_and_benchmarking.html#sec-resampling</a>
</p>
</li>
<li>
<p> Package <a href="https://CRAN.R-project.org/package=mlr3viz"><span class="pkg">mlr3viz</span></a> for some generic visualizations.
</p>
</li>
</ul>
<p>Other resample: 
<code>resample()</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">task = tsk("penguins")
learner = lrn("classif.rpart")
resampling = rsmp("cv", folds = 3)
rr = resample(task, learner, resampling)
print(rr)

# combined predictions and predictions for each fold separately
rr$prediction()
rr$predictions()

# folds scored separately, then aggregated (macro)
rr$aggregate(msr("classif.acc"))

# predictions first combined, then scored (micro)
rr$prediction()$score(msr("classif.acc"))

# check for warnings and errors
rr$warnings
rr$errors
</code></pre>


</div>