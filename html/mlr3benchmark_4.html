<div class="container">

<table style="width: 100%;"><tr>
<td>autoplot.BenchmarkAggr</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Plots for BenchmarkAggr</h2>

<h3>Description</h3>

<p>Generates plots for BenchmarkAggr, all assume that there are multiple, independent, tasks.
Choices depending on the argument <code>type</code>:
</p>

<ul>
<li> <p><code>"mean"</code> (default): Assumes there are at least two independent tasks. Plots the sample mean
of the measure for all learners with error bars computed with the standard error of the mean.
</p>
</li>
<li> <p><code>"box"</code>: Boxplots for each learner calculated over all tasks for a given measure.
</p>
</li>
<li> <p><code>"fn"</code>: Plots post-hoc Friedman-Nemenyi by first calling BenchmarkAggr<code style="white-space: pre;">⁠$friedman_posthoc⁠</code>
and plotting significant pairs in coloured squares and leaving non-significant pairs blank,
useful for simply visualising pair-wise comparisons.
</p>
</li>
<li> <p><code>"cd"</code>: Critical difference plots (Demsar, 2006). Learners are drawn on the x-axis according
to their average rank with the best performing on the left and decreasing performance going
right. Any learners not connected by a horizontal bar are significantly different in performance.
Critical differences are calculated as:
</p>
<p style="text-align: center;"><code class="reqn">CD = q_{\alpha} \sqrt{\left(\frac{k(k+1)}{6N}\right)}</code>
</p>

<p>Where <code class="reqn">q_\alpha</code> is based on the studentized range statistic.
See references for further details.
It's recommended to crop white space using external tools, or function <code>image_trim()</code> from package <a href="https://CRAN.R-project.org/package=magick"><span class="pkg">magick</span></a>.
</p>
</li>
</ul>
<h3>Usage</h3>

<pre><code class="language-R">## S3 method for class 'BenchmarkAggr'
autoplot(
  object,
  type = c("mean", "box", "fn", "cd"),
  meas = NULL,
  level = 0.95,
  p.value = 0.05,
  minimize = TRUE,
  test = "nem",
  baseline = NULL,
  style = 1L,
  ratio = 1/7,
  col = "red",
  friedman_global = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>object</code></td>
<td>
<p>(BenchmarkAggr)<br>
The benchmark aggregation object.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>type</code></td>
<td>
<p><code>(character(1))</code> <br> Type of plot, see description.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>meas</code></td>
<td>
<p><code>(character(1))</code> <br> Measure to plot, should be in <code>obj$measures</code>, can be <code>NULL</code> if
only one measure is in <code>obj</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>level</code></td>
<td>
<p><code>(numeric(1))</code> <br> Confidence level for error bars for <code>type = "mean"</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>p.value</code></td>
<td>
<p><code>(numeric(1))</code> <br> What value should be considered significant for
<code>type = "cd"</code> and <code>type = "fn"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>minimize</code></td>
<td>
<p><code>(logical(1))</code> <br>
For <code>type = "cd"</code>, indicates if the measure is optimally minimized. Default is <code>TRUE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>test</code></td>
<td>
<p>(<code style="white-space: pre;">⁠character(1))⁠</code>) <br>
For <code>type = "cd"</code>, critical differences are either computed between all learners
(<code>test = "nemenyi"</code>), or to a baseline (<code>test = "bd"</code>). Bonferroni-Dunn usually yields higher
power than Nemenyi as it only compares algorithms to one baseline. Default is <code>"nemenyi"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>baseline</code></td>
<td>
<p><code>(character(1))</code> <br>
For <code>type = "cd"</code> and <code>test = "bd"</code> a baseline learner to compare the other learners to,
should be in <code style="white-space: pre;">⁠$learners⁠</code>, if <code>NULL</code> then differences are compared to the best performing
learner.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>style</code></td>
<td>
<p><code>(integer(1))</code> <br>
For <code>type = "cd"</code> two ggplot styles are shipped with the package (<code>style = 1</code> or <code>style = 2</code>),
otherwise the data can be accessed via the returned ggplot.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ratio</code></td>
<td>
<p>(<code>numeric(1)</code>) <br>
For <code>type = "cd"</code> and <code>style = 1</code>, passed to <code>ggplot2::coord_fixed()</code>, useful for quickly
specifying the aspect ratio of the plot, best used with <code>ggsave()</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>col</code></td>
<td>
<p>(<code>character(1)</code>)<br>
For <code>type = "fn"</code>, specifies color to fill significant tiles, default is <code>"red"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>friedman_global</code></td>
<td>
<p>(<code>logical(1)</code>)<br>
Should a friedman global test be performed for<code>type = "cd"</code> and <code>type = "fn"</code>?
If <code>FALSE</code>, a warning is issued in case the corresponding friedman posthoc test fails instead of an error.
Default is <code>TRUE</code> (raises an error if global test fails).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p><code>ANY</code> <br> Additional arguments, currently unused.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>The generated plot.
</p>


<h3>References</h3>

<p>Demšar J (2006).
“Statistical Comparisons of Classifiers over Multiple Data Sets.”
<em>Journal of Machine Learning Research</em>, <b>7</b>(1), 1-30.
<a href="https://jmlr.org/papers/v7/demsar06a.html">https://jmlr.org/papers/v7/demsar06a.html</a>.
</p>


<h3>Examples</h3>

<pre><code class="language-R">if (requireNamespaces(c("mlr3learners", "mlr3", "rpart", "xgboost"))) {
library(mlr3)
library(mlr3learners)
library(ggplot2)

set.seed(1)
task = tsks(c("iris", "sonar", "wine", "zoo"))
learns = lrns(c("classif.featureless", "classif.rpart", "classif.xgboost"))
bm = benchmark(benchmark_grid(task, learns, rsmp("cv", folds = 3)))
obj = as_benchmark_aggr(bm)

# mean and error bars
autoplot(obj, type = "mean", level = 0.95)

if (requireNamespace("PMCMRplus", quietly = TRUE)) {
  # critical differences
  autoplot(obj, type = "cd",style = 1)
  autoplot(obj, type = "cd",style = 2)

  # post-hoc friedman-nemenyi
  autoplot(obj, type = "fn")
}

}

</code></pre>


</div>