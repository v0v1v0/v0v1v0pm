<div class="container">

<table style="width: 100%;"><tr>
<td>BenchmarkAggr</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Aggregated Benchmark Result Object</h2>

<h3>Description</h3>

<p>An R6 class for aggregated benchmark results.
</p>


<h3>Details</h3>

<p>This class is used to easily carry out and guide analysis of models after aggregating
the results after resampling. This can either be constructed using <a href="https://CRAN.R-project.org/package=mlr3"><span class="pkg">mlr3</span></a> objects,
for example the result of mlr3::BenchmarkResult<code style="white-space: pre;">⁠$aggregate⁠</code> or via as_benchmark_aggr,
or by passing in a custom dataset of results. Custom datasets must include at the very least,
a character column for learner ids, a character column for task ids, and numeric columns for
one or more measures.
</p>
<p>Currently supported for multiple independent datasets only.
</p>


<h3>Active bindings</h3>

<div class="r6-active-bindings">

<dl>
<dt><code>data</code></dt>
<dd>
<p>(data.table::data.table) <br> Aggregated data.</p>
</dd>
<dt><code>learners</code></dt>
<dd>
<p><code>(character())</code> <br> Unique learner names.</p>
</dd>
<dt><code>tasks</code></dt>
<dd>
<p><code>(character())</code> <br> Unique task names.</p>
</dd>
<dt><code>measures</code></dt>
<dd>
<p><code>(character())</code> <br> Unique measure names.</p>
</dd>
<dt><code>nlrns</code></dt>
<dd>
<p><code>(integer())</code> <br> Number of learners.</p>
</dd>
<dt><code>ntasks</code></dt>
<dd>
<p><code>(integer())</code> <br> Number of tasks.</p>
</dd>
<dt><code>nmeas</code></dt>
<dd>
<p><code>(integer())</code> <br> Number of measures.</p>
</dd>
<dt><code>nrow</code></dt>
<dd>
<p><code>(integer())</code> <br> Number of rows.</p>
</dd>
<dt><code>col_roles</code></dt>
<dd>
<p>(<code>character()</code>) <br>
Column roles, currently cannot be changed after construction.</p>
</dd>
</dl>
</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-BenchmarkAggr-new"><code>BenchmarkAggr$new()</code></a>
</p>
</li>
<li> <p><a href="#method-BenchmarkAggr-print"><code>BenchmarkAggr$print()</code></a>
</p>
</li>
<li> <p><a href="#method-BenchmarkAggr-summary"><code>BenchmarkAggr$summary()</code></a>
</p>
</li>
<li> <p><a href="#method-BenchmarkAggr-rank_data"><code>BenchmarkAggr$rank_data()</code></a>
</p>
</li>
<li> <p><a href="#method-BenchmarkAggr-friedman_test"><code>BenchmarkAggr$friedman_test()</code></a>
</p>
</li>
<li> <p><a href="#method-BenchmarkAggr-friedman_posthoc"><code>BenchmarkAggr$friedman_posthoc()</code></a>
</p>
</li>
<li> <p><a href="#method-BenchmarkAggr-subset"><code>BenchmarkAggr$subset()</code></a>
</p>
</li>
<li> <p><a href="#method-BenchmarkAggr-clone"><code>BenchmarkAggr$clone()</code></a>
</p>
</li>
</ul>
<hr>
<a id="method-BenchmarkAggr-new"></a>



<h4>Method <code>new()</code>
</h4>

<p>Creates a new instance of this R6 class.
</p>


<h5>Usage</h5>

<div class="r"><pre>BenchmarkAggr$new(
  dt,
  task_id = "task_id",
  learner_id = "learner_id",
  independent = TRUE,
  strip_prefix = TRUE,
  ...
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>dt</code></dt>
<dd>
<p><code>(matrix(1))</code> <br>'
<code>matrix</code> like object coercable to data.table::data.table, should
include column names "task_id" and "learner_id", and at least one measure (numeric).
If ids are not already factors then coerced internally.</p>
</dd>
<dt><code>task_id</code></dt>
<dd>
<p>(<code>character(1)</code>) <br>
String specifying name of task id column.</p>
</dd>
<dt><code>learner_id</code></dt>
<dd>
<p>(<code>character(1)</code>)<br>
String specifying name of learner id column.</p>
</dd>
<dt><code>independent</code></dt>
<dd>
<p><code>(logical(1))</code> <br>
Are tasks independent of one another? Affects which tests can be used for analysis.</p>
</dd>
<dt><code>strip_prefix</code></dt>
<dd>
<p>(<code>logical(1)</code>) <br>
If <code>TRUE</code> (default) then mlr prefixes, e.g. <code>regr.</code>, <code>classif.</code>, are automatically
stripped from the <code>learner_id</code>.</p>
</dd>
<dt><code>...</code></dt>
<dd>
<p><code>ANY</code> <br>
Additional arguments, currently unused.</p>
</dd>
</dl>
</div>


<hr>
<a id="method-BenchmarkAggr-print"></a>



<h4>Method <code>print()</code>
</h4>

<p>Prints the internal data via data.table::print.data.table.
</p>


<h5>Usage</h5>

<div class="r"><pre>BenchmarkAggr$print(...)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>...</code></dt>
<dd>
<p><code>ANY</code> <br> Passed to data.table::print.data.table.</p>
</dd>
</dl>
</div>


<hr>
<a id="method-BenchmarkAggr-summary"></a>



<h4>Method <code>summary()</code>
</h4>

<p>Prints the internal data via data.table::print.data.table.
</p>


<h5>Usage</h5>

<div class="r"><pre>BenchmarkAggr$summary(...)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>...</code></dt>
<dd>
<p><code>ANY</code> <br> Passed to data.table::print.data.table.</p>
</dd>
</dl>
</div>


<hr>
<a id="method-BenchmarkAggr-rank_data"></a>



<h4>Method <code>rank_data()</code>
</h4>

<p>Ranks the aggregated data given some measure.
</p>


<h5>Usage</h5>

<div class="r"><pre>BenchmarkAggr$rank_data(meas = NULL, minimize = TRUE, task = NULL, ...)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>meas</code></dt>
<dd>
<p><code>(character(1))</code> <br>
Measure to rank the data against, should be in <code style="white-space: pre;">⁠$measures⁠</code>. Can be <code>NULL</code> if only one measure
in data.</p>
</dd>
<dt><code>minimize</code></dt>
<dd>
<p><code>(logical(1))</code> <br>
Should the measure be minimized? Default is <code>TRUE</code>.</p>
</dd>
<dt><code>task</code></dt>
<dd>
<p><code>(character(1))</code> <br>
If <code>NULL</code> then returns a matrix of ranks where columns are tasks and rows are
learners, otherwise returns a one-column matrix of a specified task, should
be in <code style="white-space: pre;">⁠$tasks⁠</code>.</p>
</dd>
<dt><code>...</code></dt>
<dd>
<p><code>ANY</code> <code>ANY</code> <br> Passed to <code>data.table::frank()</code>.</p>
</dd>
</dl>
</div>


<hr>
<a id="method-BenchmarkAggr-friedman_test"></a>



<h4>Method <code>friedman_test()</code>
</h4>

<p>Computes Friedman test over all tasks, assumes datasets are independent.
</p>


<h5>Usage</h5>

<div class="r"><pre>BenchmarkAggr$friedman_test(meas = NULL, p.adjust.method = NULL)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>meas</code></dt>
<dd>
<p><code>(character(1))</code> <br>
Measure to rank the data against, should be in <code style="white-space: pre;">⁠$measures⁠</code>. If no measure is provided
then returns a matrix of tests for all measures.</p>
</dd>
<dt><code>p.adjust.method</code></dt>
<dd>
<p><code>(character(1))</code> <br>
Passed to p.adjust if <code>meas = NULL</code> for multiple testing correction. If <code>NULL</code>
then no correction applied.</p>
</dd>
</dl>
</div>


<hr>
<a id="method-BenchmarkAggr-friedman_posthoc"></a>



<h4>Method <code>friedman_posthoc()</code>
</h4>

<p>Posthoc Friedman Nemenyi tests. Computed with
PMCMRplus::frdAllPairsNemenyiTest. If global <code style="white-space: pre;">⁠$friedman_test⁠</code> is non-significant then
this is returned and no post-hocs computed. Also returns critical difference
</p>


<h5>Usage</h5>

<div class="r"><pre>BenchmarkAggr$friedman_posthoc(
  meas = NULL,
  p.value = 0.05,
  friedman_global = TRUE
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>meas</code></dt>
<dd>
<p><code>(character(1))</code> <br>
Measure to rank the data against, should be in <code style="white-space: pre;">⁠$measures⁠</code>. Can be <code>NULL</code> if only one measure
in data.</p>
</dd>
<dt><code>p.value</code></dt>
<dd>
<p><code>(numeric(1))</code> <br>
p.value for which the global test will be considered significant.</p>
</dd>
<dt><code>friedman_global</code></dt>
<dd>
<p>(<code>logical(1)</code>)<br>
Should a friedman global test be performed before conducting the posthoc
test? If <code>FALSE</code>, a warning is issued in case the corresponding friedman
global test fails instead of an error. Default is <code>TRUE</code> (raises an
error if global test fails).</p>
</dd>
</dl>
</div>


<hr>
<a id="method-BenchmarkAggr-subset"></a>



<h4>Method <code>subset()</code>
</h4>

<p>Subsets the data by given tasks or learners.
Returns data as data.table::data.table.
</p>


<h5>Usage</h5>

<div class="r"><pre>BenchmarkAggr$subset(task = NULL, learner = NULL)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>task</code></dt>
<dd>
<p>(<code>character()</code>) <br>
Task(s) to subset the data by.</p>
</dd>
<dt><code>learner</code></dt>
<dd>
<p>(<code>character()</code>) <br>
Learner(s) to subset the data by.</p>
</dd>
</dl>
</div>


<hr>
<a id="method-BenchmarkAggr-clone"></a>



<h4>Method <code>clone()</code>
</h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>BenchmarkAggr$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt>
<dd>
<p>Whether to make a deep clone.</p>
</dd>
</dl>
</div>




<h3>References</h3>

<p>'r format_bib("demsar_2006")
</p>


<h3>Examples</h3>

<pre><code class="language-R"># Not restricted to mlr3 objects
df = data.frame(tasks = factor(rep(c("A", "B"), each = 5),
                               levels = c("A", "B")),
                learners = factor(paste0("L", 1:5)),
                RMSE = runif(10), MAE = runif(10))
as_benchmark_aggr(df, task_id = "tasks", learner_id = "learners")

if (requireNamespaces(c("mlr3", "rpart"))) {
  library(mlr3)
  task = tsks(c("boston_housing", "mtcars"))
  learns = lrns(c("regr.featureless", "regr.rpart"))
  bm = benchmark(benchmark_grid(task, learns, rsmp("cv", folds = 2)))

  # coercion
  as_benchmark_aggr(bm)
}
</code></pre>


</div>