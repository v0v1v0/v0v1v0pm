<div class="container">

<table style="width: 100%;"><tr>
<td>MeasureFairness</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Base Measure for Fairness</h2>

<h3>Description</h3>

<p>This measure extends <code>mlr3::Measure()</code> with statistical group fairness:
A common approach to quantifying a model's fairness is to compute the difference between a
protected and an unprotected group according w.r.t. some performance metric, e.g.
<code style="white-space: pre;">⁠classification error⁠</code> (mlr_measures_classif.ce) or <code style="white-space: pre;">⁠false positive rate⁠</code>
(mlr_measures_classif.fpr).
The operation for comparison (e.g., difference or quotient) can be specified using the <code>operation</code>
parameter, e.g. <code>groupdiff_absdiff()</code> or <code>groupdiff_tau()</code>.
</p>
<p>Composite measures encompasing multiple fairness metrics can be built using
MeasureFairnessComposite.
</p>
<p>Some popular predefined measures can be found in the dictionary mlr_measures.
</p>


<h3>Protected Attributes</h3>

<p>The protected attribute is specified as a <code>col_role</code> in the corresponding <code>Task()</code>:<br><code style="white-space: pre;">⁠&lt;Task&gt;$col_roles$pta = "name_of_attribute"⁠</code> <br>
This also allows specifying more than one protected attribute,
in which case fairness will be considered on the level of intersecting groups defined by all columns
selected as a predicted attribute.
</p>


<h3>Super class</h3>

<p><code>mlr3::Measure</code> -&gt; <code>MeasureFairness</code>
</p>


<h3>Public fields</h3>

<div class="r6-fields">

<dl>
<dt><code>base_measure</code></dt>
<dd>
<p>(<code>Measure()</code>)<br>
The base measure to be used by the fairness measures,
e.g. mlr_measures_classif.fpr for the false positive rate.</p>
</dd>
<dt><code>operation</code></dt>
<dd>
<p>(<code style="white-space: pre;">⁠function()⁠</code>)<br>
The operation used to compute the difference. A function with args 'x' and 'y' that returns
a single value. Defaults to <code>abs(x - y)</code>.</p>
</dd>
</dl>
</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-MeasureFairness-new"><code>MeasureFairness$new()</code></a>
</p>
</li>
<li> <p><a href="#method-MeasureFairness-clone"><code>MeasureFairness$clone()</code></a>
</p>
</li>
</ul>
<details open><summary>Inherited methods</summary><ul>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Measure" data-id="aggregate"><a href="../../mlr3/html/Measure.html#method-Measure-aggregate"><code>mlr3::Measure$aggregate()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Measure" data-id="format"><a href="../../mlr3/html/Measure.html#method-Measure-format"><code>mlr3::Measure$format()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Measure" data-id="help"><a href="../../mlr3/html/Measure.html#method-Measure-help"><code>mlr3::Measure$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Measure" data-id="print"><a href="../../mlr3/html/Measure.html#method-Measure-print"><code>mlr3::Measure$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Measure" data-id="score"><a href="../../mlr3/html/Measure.html#method-Measure-score"><code>mlr3::Measure$score()</code></a></span></li>
</ul></details><hr>
<a id="method-MeasureFairness-new"></a>



<h4>Method <code>new()</code>
</h4>

<p>Creates a new instance of this R6 class.
</p>


<h5>Usage</h5>

<div class="r"><pre>MeasureFairness$new(
  id = NULL,
  base_measure,
  operation = groupdiff_absdiff,
  minimize = TRUE,
  range = c(-Inf, Inf)
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>id</code></dt>
<dd>
<p>(<code>character</code>)<br>
The measure's id. Set to 'fairness.&lt;base_measure_id&gt;' if ommited.</p>
</dd>
<dt><code>base_measure</code></dt>
<dd>
<p>(<code>Measure()</code>)<br>
The base metric evaluated within each subgroup.</p>
</dd>
<dt><code>operation</code></dt>
<dd>
<p>(<code>function</code>)<br>
The operation used to compute the difference. A function that returns
a single value given input: computed metric for each subgroup.
Defaults to groupdiff_absdiff.</p>
</dd>
<dt><code>minimize</code></dt>
<dd>
<p>(<code>logical()</code>)<br>
Should the measure be minimized? Defaults to <code>TRUE</code>.</p>
</dd>
<dt><code>range</code></dt>
<dd>
<p>(<code>numeric(2)</code>)<br>
Range of the resulting measure. Defaults to <code>c(-Inf, Inf)</code>.</p>
</dd>
</dl>
</div>


<hr>
<a id="method-MeasureFairness-clone"></a>



<h4>Method <code>clone()</code>
</h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>MeasureFairness$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt>
<dd>
<p>Whether to make a deep clone.</p>
</dd>
</dl>
</div>




<h3>See Also</h3>

<p>MeasureFairnessComposite
</p>


<h3>Examples</h3>

<pre><code class="language-R">library("mlr3")
# Create MeasureFairness to measure the Predictive Parity.
t = tsk("adult_train")
learner = lrn("classif.rpart", cp = .01)
learner$train(t)
measure = msr("fairness", base_measure = msr("classif.ppv"))
predictions = learner$predict(t)
predictions$score(measure, task = t)
</code></pre>


</div>