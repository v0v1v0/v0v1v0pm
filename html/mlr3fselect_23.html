<div class="container">

<table style="width: 100%;"><tr>
<td>FSelectInstanceBatchMultiCrit</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Class for Multi Criteria Feature Selection</h2>

<h3>Description</h3>

<p>The FSelectInstanceBatchMultiCrit specifies a feature selection problem for a FSelector.
The function <code>fsi()</code> creates a FSelectInstanceBatchMultiCrit and the function <code>fselect()</code> creates an instance internally.
</p>


<h3>Resources</h3>

<p>There are several sections about feature selection in the <a href="https://mlr3book.mlr-org.com">mlr3book</a>.
</p>

<ul><li>
<p> Learn about <a href="https://mlr3book.mlr-org.com/chapters/chapter6/feature_selection.html#sec-multicrit-featsel">multi-objective optimization</a>.
</p>
</li></ul>
<p>The <a href="https://mlr-org.com/gallery.html">gallery</a> features a collection of case studies and demos about optimization.
</p>


<h3>Analysis</h3>

<p>For analyzing the feature selection results, it is recommended to pass the archive to <code>as.data.table()</code>.
The returned data table is joined with the benchmark result which adds the mlr3::ResampleResult for each feature set.
</p>
<p>The archive provides various getters (e.g. <code style="white-space: pre;">⁠$learners()⁠</code>) to ease the access.
All getters extract by position (<code>i</code>) or unique hash (<code>uhash</code>).
For a complete list of all getters see the methods section.
</p>
<p>The benchmark result (<code style="white-space: pre;">⁠$benchmark_result⁠</code>) allows to score the feature sets again on a different measure.
Alternatively, measures can be supplied to <code>as.data.table()</code>.
</p>


<h3>Super classes</h3>

<p><code>bbotk::OptimInstance</code> -&gt; <code>bbotk::OptimInstanceBatch</code> -&gt; <code>bbotk::OptimInstanceBatchMultiCrit</code> -&gt; <code>FSelectInstanceBatchMultiCrit</code>
</p>


<h3>Active bindings</h3>

<div class="r6-active-bindings">

<dl>
<dt><code>result_feature_set</code></dt>
<dd>
<p>(list of <code>character()</code>)<br>
Feature sets for task subsetting.</p>
</dd>
</dl>
</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-FSelectInstanceBatchMultiCrit-new"><code>FSelectInstanceBatchMultiCrit$new()</code></a>
</p>
</li>
<li> <p><a href="#method-FSelectInstanceBatchMultiCrit-assign_result"><code>FSelectInstanceBatchMultiCrit$assign_result()</code></a>
</p>
</li>
<li> <p><a href="#method-FSelectInstanceBatchMultiCrit-print"><code>FSelectInstanceBatchMultiCrit$print()</code></a>
</p>
</li>
<li> <p><a href="#method-FSelectInstanceBatchMultiCrit-clone"><code>FSelectInstanceBatchMultiCrit$clone()</code></a>
</p>
</li>
</ul>
<details open><summary>Inherited methods</summary><ul>
<li><span class="pkg-link" data-pkg="bbotk" data-topic="OptimInstance" data-id="clear"><a href="../../bbotk/html/OptimInstance.html#method-OptimInstance-clear"><code>bbotk::OptimInstance$clear()</code></a></span></li>
<li><span class="pkg-link" data-pkg="bbotk" data-topic="OptimInstance" data-id="format"><a href="../../bbotk/html/OptimInstance.html#method-OptimInstance-format"><code>bbotk::OptimInstance$format()</code></a></span></li>
<li><span class="pkg-link" data-pkg="bbotk" data-topic="OptimInstanceBatch" data-id="eval_batch"><a href="../../bbotk/html/OptimInstanceBatch.html#method-OptimInstanceBatch-eval_batch"><code>bbotk::OptimInstanceBatch$eval_batch()</code></a></span></li>
<li><span class="pkg-link" data-pkg="bbotk" data-topic="OptimInstanceBatch" data-id="objective_function"><a href="../../bbotk/html/OptimInstanceBatch.html#method-OptimInstanceBatch-objective_function"><code>bbotk::OptimInstanceBatch$objective_function()</code></a></span></li>
</ul></details><hr>
<a id="method-FSelectInstanceBatchMultiCrit-new"></a>



<h4>Method <code>new()</code>
</h4>

<p>Creates a new instance of this R6 class.
</p>


<h5>Usage</h5>

<div class="r"><pre>FSelectInstanceBatchMultiCrit$new(
  task,
  learner,
  resampling,
  measures,
  terminator,
  store_benchmark_result = TRUE,
  store_models = FALSE,
  check_values = FALSE,
  callbacks = NULL
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>task</code></dt>
<dd>
<p>(mlr3::Task)<br>
Task to operate on.</p>
</dd>
<dt><code>learner</code></dt>
<dd>
<p>(mlr3::Learner)<br>
Learner to optimize the feature subset for.</p>
</dd>
<dt><code>resampling</code></dt>
<dd>
<p>(mlr3::Resampling)<br>
Resampling that is used to evaluated the performance of the feature subsets.
Uninstantiated resamplings are instantiated during construction so that all feature subsets are evaluated on the same data splits.
Already instantiated resamplings are kept unchanged.</p>
</dd>
<dt><code>measures</code></dt>
<dd>
<p>(list of mlr3::Measure)<br>
Measures to optimize.
If <code>NULL</code>, <a href="https://CRAN.R-project.org/package=mlr3"><span class="pkg">mlr3</span></a>'s default measure is used.</p>
</dd>
<dt><code>terminator</code></dt>
<dd>
<p>(bbotk::Terminator)<br>
Stop criterion of the feature selection.</p>
</dd>
<dt><code>store_benchmark_result</code></dt>
<dd>
<p>(<code>logical(1)</code>)<br>
Store benchmark result in archive?</p>
</dd>
<dt><code>store_models</code></dt>
<dd>
<p>(<code>logical(1)</code>).
Store models in benchmark result?</p>
</dd>
<dt><code>check_values</code></dt>
<dd>
<p>(<code>logical(1)</code>)<br>
Check the parameters before the evaluation and the results for
validity?</p>
</dd>
<dt><code>callbacks</code></dt>
<dd>
<p>(list of CallbackBatchFSelect)<br>
List of callbacks.</p>
</dd>
</dl>
</div>


<hr>
<a id="method-FSelectInstanceBatchMultiCrit-assign_result"></a>



<h4>Method <code>assign_result()</code>
</h4>

<p>The FSelector object writes the best found feature subsets and estimated performance values here.
For internal use.
</p>


<h5>Usage</h5>

<div class="r"><pre>FSelectInstanceBatchMultiCrit$assign_result(xdt, ydt)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>xdt</code></dt>
<dd>
<p>(<code>data.table::data.table()</code>)<br>
x values as <code>data.table</code>. Each row is one point. Contains the value in
the <em>search space</em> of the FSelectInstanceBatchMultiCrit object. Can contain
additional columns for extra information.</p>
</dd>
<dt><code>ydt</code></dt>
<dd>
<p>(<code>data.table::data.table()</code>)<br>
Optimal outcomes, e.g. the Pareto front.</p>
</dd>
</dl>
</div>


<hr>
<a id="method-FSelectInstanceBatchMultiCrit-print"></a>



<h4>Method <code>print()</code>
</h4>

<p>Printer.
</p>


<h5>Usage</h5>

<div class="r"><pre>FSelectInstanceBatchMultiCrit$print(...)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>...</code></dt>
<dd>
<p>(ignored).</p>
</dd>
</dl>
</div>


<hr>
<a id="method-FSelectInstanceBatchMultiCrit-clone"></a>



<h4>Method <code>clone()</code>
</h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>FSelectInstanceBatchMultiCrit$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt>
<dd>
<p>Whether to make a deep clone.</p>
</dd>
</dl>
</div>




<h3>Examples</h3>

<pre><code class="language-R"># Feature selection on Palmer Penguins data set


task = tsk("penguins")

# Construct feature selection instance
instance = fsi(
  task = task,
  learner = lrn("classif.rpart"),
  resampling = rsmp("cv", folds = 3),
  measures = msrs(c("classif.ce", "time_train")),
  terminator = trm("evals", n_evals = 4)
)

# Choose optimization algorithm
fselector = fs("random_search", batch_size = 2)

# Run feature selection
fselector$optimize(instance)

# Optimal feature sets
instance$result_feature_set

# Inspect all evaluated sets
as.data.table(instance$archive)

</code></pre>


</div>