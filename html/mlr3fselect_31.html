<div class="container">

<table style="width: 100%;"><tr>
<td>mlr_fselectors_random_search</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Feature Selection with Random Search</h2>

<h3>Description</h3>

<p>Feature selection using Random Search Algorithm.
</p>


<h3>Details</h3>

<p>The feature sets are randomly drawn.
The sets are evaluated in batches of size <code>batch_size</code>.
Larger batches mean we can parallelize more, smaller batches imply a more fine-grained checking of termination criteria.
</p>


<h3>Dictionary</h3>

<p>This FSelector can be instantiated with the associated sugar function <code>fs()</code>:
</p>
<div class="sourceCode"><pre>fs("random_search")
</pre></div>


<h3>Control Parameters</h3>


<dl>
<dt><code>max_features</code></dt>
<dd>
<p><code>integer(1)</code><br>
Maximum number of features.
By default, number of features in mlr3::Task.</p>
</dd>
<dt><code>batch_size</code></dt>
<dd>
<p><code>integer(1)</code><br>
Maximum number of feature sets to try in a batch.</p>
</dd>
</dl>
<h3>Super classes</h3>

<p><code>mlr3fselect::FSelector</code> -&gt; <code>mlr3fselect::FSelectorBatch</code> -&gt; <code>FSelectorBatchRandomSearch</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-FSelectorBatchRandomSearch-new"><code>FSelectorBatchRandomSearch$new()</code></a>
</p>
</li>
<li> <p><a href="#method-FSelectorBatchRandomSearch-clone"><code>FSelectorBatchRandomSearch$clone()</code></a>
</p>
</li>
</ul>
<details open><summary>Inherited methods</summary><ul>
<li><span class="pkg-link" data-pkg="mlr3fselect" data-topic="FSelector" data-id="format"><a href="../../mlr3fselect/html/FSelector.html#method-FSelector-format"><code>mlr3fselect::FSelector$format()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3fselect" data-topic="FSelector" data-id="help"><a href="../../mlr3fselect/html/FSelector.html#method-FSelector-help"><code>mlr3fselect::FSelector$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3fselect" data-topic="FSelector" data-id="print"><a href="../../mlr3fselect/html/FSelector.html#method-FSelector-print"><code>mlr3fselect::FSelector$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3fselect" data-topic="FSelectorBatch" data-id="optimize"><a href="../../mlr3fselect/html/FSelectorBatch.html#method-FSelectorBatch-optimize"><code>mlr3fselect::FSelectorBatch$optimize()</code></a></span></li>
</ul></details><hr>
<a id="method-FSelectorBatchRandomSearch-new"></a>



<h4>Method <code>new()</code>
</h4>

<p>Creates a new instance of this R6 class.
</p>


<h5>Usage</h5>

<div class="r"><pre>FSelectorBatchRandomSearch$new()</pre></div>


<hr>
<a id="method-FSelectorBatchRandomSearch-clone"></a>



<h4>Method <code>clone()</code>
</h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>FSelectorBatchRandomSearch$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt>
<dd>
<p>Whether to make a deep clone.</p>
</dd>
</dl>
</div>




<h3>Source</h3>

<p>Bergstra J, Bengio Y (2012).
“Random Search for Hyper-Parameter Optimization.”
<em>Journal of Machine Learning Research</em>, <b>13</b>(10), 281–305.
<a href="https://jmlr.csail.mit.edu/papers/v13/bergstra12a.html">https://jmlr.csail.mit.edu/papers/v13/bergstra12a.html</a>.
</p>


<h3>See Also</h3>

<p>Other FSelector: 
<code>FSelector</code>,
<code>mlr_fselectors</code>,
<code>mlr_fselectors_design_points</code>,
<code>mlr_fselectors_exhaustive_search</code>,
<code>mlr_fselectors_genetic_search</code>,
<code>mlr_fselectors_rfe</code>,
<code>mlr_fselectors_rfecv</code>,
<code>mlr_fselectors_sequential</code>,
<code>mlr_fselectors_shadow_variable_search</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R"># Feature Selection


# retrieve task and load learner
task = tsk("penguins")
learner = lrn("classif.rpart")

# run feature selection on the Palmer Penguins data set
instance = fselect(
  fselector = fs("random_search"),
  task = task,
  learner = learner,
  resampling = rsmp("holdout"),
  measure = msr("classif.ce"),
  term_evals = 10
)

# best performing feature subset
instance$result

# all evaluated feature subsets
as.data.table(instance$archive)

# subset the task and fit the final model
task$select(instance$result_feature_set)
learner$train(task)

</code></pre>


</div>