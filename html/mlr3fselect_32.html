<div class="container">

<table style="width: 100%;"><tr>
<td>mlr_fselectors_rfe</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Feature Selection with Recursive Feature Elimination</h2>

<h3>Description</h3>

<p>Feature selection using the Recursive Feature Elimination (RFE) algorithm.
Recursive feature elimination iteratively removes features with a low importance score.
Only works with mlr3::Learners that can calculate importance scores (see the section on optional extractors in mlr3::Learner).
</p>


<h3>Details</h3>

<p>The learner is trained on all features at the start and importance scores are calculated for each feature.
Then the least important feature is removed and the learner is trained on the reduced feature set.
The importance scores are calculated again and the procedure is repeated until the desired number of features is reached.
The non-recursive option (<code>recursive = FALSE</code>) only uses the importance scores calculated in the first iteration.
</p>
<p>The feature selection terminates itself when <code>n_features</code> is reached.
It is not necessary to set a termination criterion.
</p>
<p>When using a cross-validation resampling strategy, the importance scores of the resampling iterations are aggregated.
The parameter <code>aggregation</code> determines how the importance scores are aggregated.
By default (<code>"rank"</code>), the importance score vector of each fold is ranked and the feature with the lowest average rank is removed.
The option <code>"mean"</code> averages the score of each feature across the resampling iterations and removes the feature with the lowest average score.
Averaging the scores is not appropriate for most importance measures.
</p>


<h3>Archive</h3>

<p>The ArchiveBatchFSelect holds the following additional columns:
</p>

<ul><li> <p><code>"importance"</code> (<code>numeric()</code>)<br>
The importance score vector of the feature subset.
</p>
</li></ul>
<h3>Resources</h3>

<p>The <a href="https://mlr-org.com/gallery.html">gallery</a> features a collection of case studies and demos about optimization.
</p>

<ul><li>
<p> Utilize the built-in feature importance of models with <a href="https://mlr-org.com/gallery/optimization/2023-02-07-recursive-feature-elimination/">Recursive Feature Elimination</a>.
</p>
</li></ul>
<h3>Dictionary</h3>

<p>This FSelector can be instantiated with the associated sugar function <code>fs()</code>:
</p>
<div class="sourceCode"><pre>fs("rfe")
</pre></div>


<h3>Control Parameters</h3>


<dl>
<dt><code>n_features</code></dt>
<dd>
<p><code>integer(1)</code><br>
The minimum number of features to select, by default half of the features.</p>
</dd>
<dt><code>feature_fraction</code></dt>
<dd>
<p><code>double(1)</code><br>
Fraction of features to retain in each iteration.
The default of 0.5 retains half of the features.</p>
</dd>
<dt><code>feature_number</code></dt>
<dd>
<p><code>integer(1)</code><br>
Number of features to remove in each iteration.</p>
</dd>
<dt><code>subset_sizes</code></dt>
<dd>
<p><code>integer()</code><br>
Vector of the number of features to retain in each iteration.
Must be sorted in decreasing order.</p>
</dd>
<dt><code>recursive</code></dt>
<dd>
<p><code>logical(1)</code><br>
If <code>TRUE</code> (default), the feature importance is calculated in each iteration.</p>
</dd>
<dt><code>aggregation</code></dt>
<dd>
<p><code>character(1)</code><br>
The aggregation method for the importance scores of the resampling iterations.
See details.
</p>
</dd>
</dl>
<p>The parameter <code>feature_fraction</code>, <code>feature_number</code> and <code>subset_sizes</code> are mutually exclusive.
</p>


<h3>Super classes</h3>

<p><code>mlr3fselect::FSelector</code> -&gt; <code>mlr3fselect::FSelectorBatch</code> -&gt; <code>FSelectorBatchRFE</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-FSelectorBatchRFE-new"><code>FSelectorBatchRFE$new()</code></a>
</p>
</li>
<li> <p><a href="#method-FSelectorBatchRFE-clone"><code>FSelectorBatchRFE$clone()</code></a>
</p>
</li>
</ul>
<details open><summary>Inherited methods</summary><ul>
<li><span class="pkg-link" data-pkg="mlr3fselect" data-topic="FSelector" data-id="format"><a href="../../mlr3fselect/html/FSelector.html#method-FSelector-format"><code>mlr3fselect::FSelector$format()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3fselect" data-topic="FSelector" data-id="help"><a href="../../mlr3fselect/html/FSelector.html#method-FSelector-help"><code>mlr3fselect::FSelector$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3fselect" data-topic="FSelector" data-id="print"><a href="../../mlr3fselect/html/FSelector.html#method-FSelector-print"><code>mlr3fselect::FSelector$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3fselect" data-topic="FSelectorBatch" data-id="optimize"><a href="../../mlr3fselect/html/FSelectorBatch.html#method-FSelectorBatch-optimize"><code>mlr3fselect::FSelectorBatch$optimize()</code></a></span></li>
</ul></details><hr>
<a id="method-FSelectorBatchRFE-new"></a>



<h4>Method <code>new()</code>
</h4>

<p>Creates a new instance of this R6 class.
</p>


<h5>Usage</h5>

<div class="r"><pre>FSelectorBatchRFE$new()</pre></div>


<hr>
<a id="method-FSelectorBatchRFE-clone"></a>



<h4>Method <code>clone()</code>
</h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>FSelectorBatchRFE$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt>
<dd>
<p>Whether to make a deep clone.</p>
</dd>
</dl>
</div>




<h3>Source</h3>

<p>Guyon I, Weston J, Barnhill S, Vapnik V (2002).
“Gene Selection for Cancer Classification using Support Vector Machines.”
<em>Machine Learning</em>, <b>46</b>(1), 389–422.
ISSN 1573-0565, <a href="https://doi.org/10.1023/A%3A1012487302797">doi:10.1023/A:1012487302797</a>.
</p>


<h3>See Also</h3>

<p>Other FSelector: 
<code>FSelector</code>,
<code>mlr_fselectors</code>,
<code>mlr_fselectors_design_points</code>,
<code>mlr_fselectors_exhaustive_search</code>,
<code>mlr_fselectors_genetic_search</code>,
<code>mlr_fselectors_random_search</code>,
<code>mlr_fselectors_rfecv</code>,
<code>mlr_fselectors_sequential</code>,
<code>mlr_fselectors_shadow_variable_search</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R"># Feature Selection


# retrieve task and load learner
task = tsk("penguins")
learner = lrn("classif.rpart")

# run feature selection on the Palmer Penguins data set
instance = fselect(
  fselector = fs("rfe"),
  task = task,
  learner = learner,
  resampling = rsmp("holdout"),
  measure = msr("classif.ce"),
  store_models = TRUE
)

# best performing feature subset
instance$result

# all evaluated feature subsets
as.data.table(instance$archive)

# subset the task and fit the final model
task$select(instance$result_feature_set)
learner$train(task)

</code></pre>


</div>