<div class="container">

<table style="width: 100%;"><tr>
<td>mlr_fselectors_rfecv</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Feature Selection with Recursive Feature Elimination with Cross Validation</h2>

<h3>Description</h3>

<p>Feature selection using the Recursive Feature Elimination with Cross-Validation (RFE-CV) algorithm.
See FSelectorBatchRFE for a description of the base algorithm.
RFE-CV runs a recursive feature elimination in each iteration of a cross-validation to determine the optimal number of features.
Then a recursive feature elimination is run again on the complete dataset with the optimal number of features as the final feature set size.
The performance of the optimal feature set is calculated on the complete data set and should not be reported as the performance of the final model.
Only works with mlr3::Learners that can calculate importance scores (see the section on optional extractors in mlr3::Learner).
</p>


<h3>Details</h3>

<p>The resampling strategy is changed during the feature selection.
The resampling strategy passed to the instance (<code>resampling</code>) is used to determine the optimal number of features.
Usually, a cross-validation strategy is used and a recursive feature elimination is run in each iteration of the cross-validation.
Internally, mlr3::ResamplingCustom is used to emulate this part of the algorithm.
In the final recursive feature elimination run the resampling strategy is changed to mlr3::ResamplingInsample i.e. the complete data set is used for training and testing.
</p>
<p>The feature selection terminates itself when the optimal number of features is reached.
It is not necessary to set a termination criterion.
</p>


<h3>Archive</h3>

<p>The ArchiveBatchFSelect holds the following additional columns:
</p>

<ul>
<li> <p><code>"iteration"</code> (<code>integer(1)</code>)<br>
The resampling iteration in which the feature subset was evaluated.
</p>
</li>
<li> <p><code>"importance"</code> (<code>numeric()</code>)<br>
The importance score vector of the feature subset.
</p>
</li>
</ul>
<h3>Resources</h3>

<p>The <a href="https://mlr-org.com/gallery.html">gallery</a> features a collection of case studies and demos about optimization.
</p>

<ul><li>
<p> Utilize the built-in feature importance of models with <a href="https://mlr-org.com/gallery/optimization/2023-02-07-recursive-feature-elimination/">Recursive Feature Elimination</a>.
</p>
</li></ul>
<h3>Dictionary</h3>

<p>This FSelector can be instantiated with the associated sugar function <code>fs()</code>:
</p>
<div class="sourceCode"><pre>fs("rfe")
</pre></div>


<h3>Control Parameters</h3>


<dl>
<dt><code>n_features</code></dt>
<dd>
<p><code>integer(1)</code><br>
The number of features to select.
By default half of the features are selected.</p>
</dd>
<dt><code>feature_fraction</code></dt>
<dd>
<p><code>double(1)</code><br>
Fraction of features to retain in each iteration.
The default 0.5 retrains half of the features.</p>
</dd>
<dt><code>feature_number</code></dt>
<dd>
<p><code>integer(1)</code><br>
Number of features to remove in each iteration.</p>
</dd>
<dt><code>subset_sizes</code></dt>
<dd>
<p><code>integer()</code><br>
Vector of number of features to retain in each iteration.
Must be sorted in decreasing order.</p>
</dd>
<dt><code>recursive</code></dt>
<dd>
<p><code>logical(1)</code><br>
If <code>TRUE</code> (default), the feature importance is calculated in each iteration.</p>
</dd>
</dl>
<p>The parameter <code>feature_fraction</code>, <code>feature_number</code> and <code>subset_sizes</code> are mutually exclusive.
</p>


<h3>Super classes</h3>

<p><code>mlr3fselect::FSelector</code> -&gt; <code>mlr3fselect::FSelectorBatch</code> -&gt; <code>FSelectorBatchRFECV</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-FSelectorBatchRFECV-new"><code>FSelectorBatchRFECV$new()</code></a>
</p>
</li>
<li> <p><a href="#method-FSelectorBatchRFECV-clone"><code>FSelectorBatchRFECV$clone()</code></a>
</p>
</li>
</ul>
<details open><summary>Inherited methods</summary><ul>
<li><span class="pkg-link" data-pkg="mlr3fselect" data-topic="FSelector" data-id="format"><a href="../../mlr3fselect/html/FSelector.html#method-FSelector-format"><code>mlr3fselect::FSelector$format()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3fselect" data-topic="FSelector" data-id="help"><a href="../../mlr3fselect/html/FSelector.html#method-FSelector-help"><code>mlr3fselect::FSelector$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3fselect" data-topic="FSelector" data-id="print"><a href="../../mlr3fselect/html/FSelector.html#method-FSelector-print"><code>mlr3fselect::FSelector$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3fselect" data-topic="FSelectorBatch" data-id="optimize"><a href="../../mlr3fselect/html/FSelectorBatch.html#method-FSelectorBatch-optimize"><code>mlr3fselect::FSelectorBatch$optimize()</code></a></span></li>
</ul></details><hr>
<a id="method-FSelectorBatchRFECV-new"></a>



<h4>Method <code>new()</code>
</h4>

<p>Creates a new instance of this R6 class.
</p>


<h5>Usage</h5>

<div class="r"><pre>FSelectorBatchRFECV$new()</pre></div>


<hr>
<a id="method-FSelectorBatchRFECV-clone"></a>



<h4>Method <code>clone()</code>
</h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>FSelectorBatchRFECV$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt>
<dd>
<p>Whether to make a deep clone.</p>
</dd>
</dl>
</div>




<h3>See Also</h3>

<p>Other FSelector: 
<code>FSelector</code>,
<code>mlr_fselectors</code>,
<code>mlr_fselectors_design_points</code>,
<code>mlr_fselectors_exhaustive_search</code>,
<code>mlr_fselectors_genetic_search</code>,
<code>mlr_fselectors_random_search</code>,
<code>mlr_fselectors_rfe</code>,
<code>mlr_fselectors_sequential</code>,
<code>mlr_fselectors_shadow_variable_search</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R"># Feature Selection


# retrieve task and load learner
task = tsk("penguins")
learner = lrn("classif.rpart")

# run feature selection on the Palmer Penguins data set
instance = fselect(
  fselector = fs("rfecv"),
  task = task,
  learner = learner,
  resampling = rsmp("cv", folds = 3),
  measure = msr("classif.ce"),
  store_models = TRUE
)

# best performing feature subset
instance$result

# all evaluated feature subsets
as.data.table(instance$archive)

# subset the task and fit the final model
task$select(instance$result_feature_set)
learner$train(task)

</code></pre>


</div>