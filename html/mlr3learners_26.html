<div class="container">

<table style="width: 100%;"><tr>
<td>mlr_learners_classif.kknn</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>k-Nearest-Neighbor Classification Learner</h2>

<h3>Description</h3>

<p>k-Nearest-Neighbor classification.
Calls <code>kknn::kknn()</code> from package <a href="https://CRAN.R-project.org/package=kknn"><span class="pkg">kknn</span></a>.
</p>


<h3>Initial parameter values</h3>


<ul><li> <p><code>store_model</code>:
</p>

<ul><li>
<p> See note.
</p>
</li></ul>
</li></ul>
<h3>Dictionary</h3>

<p>This mlr3::Learner can be instantiated via the dictionary mlr3::mlr_learners or with the associated sugar function <code>mlr3::lrn()</code>:
</p>
<div class="sourceCode"><pre>mlr_learners$get("classif.kknn")
lrn("classif.kknn")
</pre></div>


<h3>Meta Information</h3>


<ul>
<li>
<p> Task type: “classif”
</p>
</li>
<li>
<p> Predict Types: “response”, “prob”
</p>
</li>
<li>
<p> Feature Types: “logical”, “integer”, “numeric”, “factor”, “ordered”
</p>
</li>
<li>
<p> Required Packages: <a href="https://CRAN.R-project.org/package=mlr3"><span class="pkg">mlr3</span></a>, <a href="https://CRAN.R-project.org/package=mlr3learners"><span class="pkg">mlr3learners</span></a>, <a href="https://CRAN.R-project.org/package=kknn"><span class="pkg">kknn</span></a>
</p>
</li>
</ul>
<h3>Parameters</h3>


<table>
<tr>
<td style="text-align: left;">
   Id </td>
<td style="text-align: left;"> Type </td>
<td style="text-align: left;"> Default </td>
<td style="text-align: left;"> Levels </td>
<td style="text-align: left;"> Range </td>
</tr>
<tr>
<td style="text-align: left;">
   k </td>
<td style="text-align: left;"> integer </td>
<td style="text-align: left;"> 7 </td>
<td style="text-align: left;">  </td>
<td style="text-align: left;"> <code class="reqn">[1, \infty)</code> </td>
</tr>
<tr>
<td style="text-align: left;">
   distance </td>
<td style="text-align: left;"> numeric </td>
<td style="text-align: left;"> 2 </td>
<td style="text-align: left;">  </td>
<td style="text-align: left;"> <code class="reqn">[0, \infty)</code> </td>
</tr>
<tr>
<td style="text-align: left;">
   kernel </td>
<td style="text-align: left;"> character </td>
<td style="text-align: left;"> optimal </td>
<td style="text-align: left;"> rectangular, triangular, epanechnikov, biweight, triweight, cos, inv, gaussian, rank, optimal </td>
<td style="text-align: left;"> - </td>
</tr>
<tr>
<td style="text-align: left;">
   scale </td>
<td style="text-align: left;"> logical </td>
<td style="text-align: left;"> TRUE </td>
<td style="text-align: left;"> TRUE, FALSE </td>
<td style="text-align: left;"> - </td>
</tr>
<tr>
<td style="text-align: left;">
   ykernel </td>
<td style="text-align: left;"> untyped </td>
<td style="text-align: left;"> NULL </td>
<td style="text-align: left;">  </td>
<td style="text-align: left;"> - </td>
</tr>
<tr>
<td style="text-align: left;">
   store_model </td>
<td style="text-align: left;"> logical </td>
<td style="text-align: left;"> FALSE </td>
<td style="text-align: left;"> TRUE, FALSE </td>
<td style="text-align: left;"> - </td>
</tr>
<tr>
<td style="text-align: left;">
</td>
</tr>
</table>
<h3>Super classes</h3>

<p><code>mlr3::Learner</code> -&gt; <code>mlr3::LearnerClassif</code> -&gt; <code>LearnerClassifKKNN</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-LearnerClassifKKNN-new"><code>LearnerClassifKKNN$new()</code></a>
</p>
</li>
<li> <p><a href="#method-LearnerClassifKKNN-clone"><code>LearnerClassifKKNN$clone()</code></a>
</p>
</li>
</ul>
<details><summary>Inherited methods</summary><ul>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="base_learner"><a href="../../mlr3/html/Learner.html#method-Learner-base_learner"><code>mlr3::Learner$base_learner()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="format"><a href="../../mlr3/html/Learner.html#method-Learner-format"><code>mlr3::Learner$format()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="help"><a href="../../mlr3/html/Learner.html#method-Learner-help"><code>mlr3::Learner$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="predict"><a href="../../mlr3/html/Learner.html#method-Learner-predict"><code>mlr3::Learner$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="predict_newdata"><a href="../../mlr3/html/Learner.html#method-Learner-predict_newdata"><code>mlr3::Learner$predict_newdata()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="print"><a href="../../mlr3/html/Learner.html#method-Learner-print"><code>mlr3::Learner$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="reset"><a href="../../mlr3/html/Learner.html#method-Learner-reset"><code>mlr3::Learner$reset()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="train"><a href="../../mlr3/html/Learner.html#method-Learner-train"><code>mlr3::Learner$train()</code></a></span></li>
</ul></details><hr>
<a id="method-LearnerClassifKKNN-new"></a>



<h4>Method <code>new()</code>
</h4>

<p>Creates a new instance of this R6 class.
</p>


<h5>Usage</h5>

<div class="r"><pre>LearnerClassifKKNN$new()</pre></div>


<hr>
<a id="method-LearnerClassifKKNN-clone"></a>



<h4>Method <code>clone()</code>
</h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>LearnerClassifKKNN$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt>
<dd>
<p>Whether to make a deep clone.</p>
</dd>
</dl>
</div>




<h3>Note</h3>

<p>There is no training step for k-NN models, just storing the training data to
process it during the predict step.
Therefore, <code style="white-space: pre;">⁠$model⁠</code> returns a list with the following elements:
</p>

<ul>
<li> <p><code>formula</code>: Formula for calling <code>kknn::kknn()</code> during <code style="white-space: pre;">⁠$predict()⁠</code>.
</p>
</li>
<li> <p><code>data</code>: Training data for calling <code>kknn::kknn()</code> during <code style="white-space: pre;">⁠$predict()⁠</code>.
</p>
</li>
<li> <p><code>pv</code>: Training parameters for calling <code>kknn::kknn()</code> during <code style="white-space: pre;">⁠$predict()⁠</code>.
</p>
</li>
<li> <p><code>kknn</code>: Model as returned by <code>kknn::kknn()</code>, only available <strong>after</strong> <code style="white-space: pre;">⁠$predict()⁠</code> has been called.
This is not stored by default, you must set hyperparameter <code>store_model</code> to <code>TRUE</code>.
</p>
</li>
</ul>
<h3>References</h3>

<p>Hechenbichler, Klaus, Schliep, Klaus (2004).
“Weighted k-nearest-neighbor techniques and ordinal classification.”
Technical Report Discussion Paper 399, SFB 386, Ludwig-Maximilians University Munich.
<a href="https://doi.org/10.5282/ubm/epub.1769">doi:10.5282/ubm/epub.1769</a>.
</p>
<p>Samworth, J R (2012).
“Optimal weighted nearest neighbour classifiers.”
<em>The Annals of Statistics</em>, <b>40</b>(5), 2733–2763.
<a href="https://doi.org/10.1214/12-AOS1049">doi:10.1214/12-AOS1049</a>.
</p>
<p>Cover, Thomas, Hart, Peter (1967).
“Nearest neighbor pattern classification.”
<em>IEEE transactions on information theory</em>, <b>13</b>(1), 21–27.
<a href="https://doi.org/10.1109/TIT.1967.1053964">doi:10.1109/TIT.1967.1053964</a>.
</p>


<h3>See Also</h3>


<ul>
<li>
<p> Chapter in the <a href="https://mlr3book.mlr-org.com/">mlr3book</a>:
<a href="https://mlr3book.mlr-org.com/chapters/chapter2/data_and_basic_modeling.html#sec-learners">https://mlr3book.mlr-org.com/chapters/chapter2/data_and_basic_modeling.html#sec-learners</a>
</p>
</li>
<li>
<p> Package <a href="https://github.com/mlr-org/mlr3extralearners">mlr3extralearners</a> for more learners.
</p>
</li>
<li> <p>Dictionary of Learners: mlr3::mlr_learners
</p>
</li>
<li> <p><code>as.data.table(mlr_learners)</code> for a table of available Learners in the running session (depending on the loaded packages).
</p>
</li>
<li> <p><a href="https://CRAN.R-project.org/package=mlr3pipelines"><span class="pkg">mlr3pipelines</span></a> to combine learners with pre- and postprocessing steps.
</p>
</li>
<li>
<p> Extension packages for additional task types:
</p>

<ul>
<li> <p><a href="https://CRAN.R-project.org/package=mlr3proba"><span class="pkg">mlr3proba</span></a> for probabilistic supervised regression and survival analysis.
</p>
</li>
<li> <p><a href="https://CRAN.R-project.org/package=mlr3cluster"><span class="pkg">mlr3cluster</span></a> for unsupervised clustering.
</p>
</li>
</ul>
</li>
<li> <p><a href="https://CRAN.R-project.org/package=mlr3tuning"><span class="pkg">mlr3tuning</span></a> for tuning of hyperparameters, <a href="https://CRAN.R-project.org/package=mlr3tuningspaces"><span class="pkg">mlr3tuningspaces</span></a>
for established default tuning spaces.
</p>
</li>
</ul>
<p>Other Learner: 
<code>mlr_learners_classif.cv_glmnet</code>,
<code>mlr_learners_classif.glmnet</code>,
<code>mlr_learners_classif.lda</code>,
<code>mlr_learners_classif.log_reg</code>,
<code>mlr_learners_classif.multinom</code>,
<code>mlr_learners_classif.naive_bayes</code>,
<code>mlr_learners_classif.nnet</code>,
<code>mlr_learners_classif.qda</code>,
<code>mlr_learners_classif.ranger</code>,
<code>mlr_learners_classif.svm</code>,
<code>mlr_learners_classif.xgboost</code>,
<code>mlr_learners_regr.cv_glmnet</code>,
<code>mlr_learners_regr.glmnet</code>,
<code>mlr_learners_regr.kknn</code>,
<code>mlr_learners_regr.km</code>,
<code>mlr_learners_regr.lm</code>,
<code>mlr_learners_regr.nnet</code>,
<code>mlr_learners_regr.ranger</code>,
<code>mlr_learners_regr.svm</code>,
<code>mlr_learners_regr.xgboost</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">if (requireNamespace("kknn", quietly = TRUE)) {
# Define the Learner and set parameter values
learner = lrn("classif.kknn")
print(learner)

# Define a Task
task = tsk("sonar")

# Create train and test set
ids = partition(task)

# Train the learner on the training ids
learner$train(task, row_ids = ids$train)

# print the model
print(learner$model)

# importance method
if("importance" %in% learner$properties) print(learner$importance)

# Make predictions for the test rows
predictions = learner$predict(task, row_ids = ids$test)

# Score the predictions
predictions$score()
}
</code></pre>


</div>