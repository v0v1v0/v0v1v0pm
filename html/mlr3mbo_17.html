<div class="container">

<table style="width: 100%;"><tr>
<td>AcqOptimizer</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Acquisition Function Optimizer</h2>

<h3>Description</h3>

<p>Optimizer for AcqFunctions which performs the acquisition function optimization.
Wraps an bbotk::Optimizer and bbotk::Terminator.
</p>


<h3>Parameters</h3>


<dl>
<dt><code>n_candidates</code></dt>
<dd>
<p><code>integer(1)</code><br>
Number of candidate points to propose.
Note that this does not affect how the acquisition function itself is calculated (e.g., setting <code>n_candidates &gt; 1</code> will not
result in computing the q- or multi-Expected Improvement) but rather the top <code>n_candidates</code> are selected from the
bbotk::Archive of the acquisition function bbotk::OptimInstance.
Note that setting <code>n_candidates &gt; 1</code> is usually not a sensible idea but it is still supported for experimental reasons.
Note that in the case of the acquisition function bbotk::OptimInstance being multi-criteria, due to using an AcqFunctionMulti,
selection of the best candidates is performed via non-dominated-sorting.
Default is <code>1</code>.
</p>
</dd>
<dt><code>logging_level</code></dt>
<dd>
<p><code>character(1)</code><br>
Logging level during the acquisition function optimization.
Can be <code>"fatal"</code>, <code>"error"</code>, <code>"warn"</code>, <code>"info"</code>, <code>"debug"</code> or <code>"trace"</code>.
Default is <code>"warn"</code>, i.e., only warnings are logged.
</p>
</dd>
<dt><code>warmstart</code></dt>
<dd>
<p><code>logical(1)</code><br>
Should the acquisition function optimization be warm-started by evaluating the best point(s) present in the bbotk::Archive of
the actual bbotk::OptimInstance (which is contained in the archive of the AcqFunction)?
This is sensible when using a population based acquisition function optimizer, e.g., local search or mutation.
Default is <code>FALSE</code>.
Note that in the case of the bbotk::OptimInstance being multi-criteria, selection of the best point(s) is performed via non-dominated-sorting.
</p>
</dd>
<dt><code>warmstart_size</code></dt>
<dd>
<p><code>integer(1) | "all"</code><br>
Number of best points selected from the bbotk::Archive of the actual bbotk::OptimInstance that are to be used for warm starting.
Can either be an integer or "all" to use all available points.
Only relevant if <code>warmstart = TRUE</code>.
Default is <code>1</code>.
</p>
</dd>
<dt><code>skip_already_evaluated</code></dt>
<dd>
<p><code>logical(1)</code><br>
It can happen that the candidate(s) resulting of the acquisition function optimization were already evaluated on the actual bbotk::OptimInstance.
Should such candidate proposals be ignored and only candidates that were yet not evaluated be considered?
Default is <code>TRUE</code>.
</p>
</dd>
<dt><code>catch_errors</code></dt>
<dd>
<p><code>logical(1)</code><br>
Should errors during the acquisition function optimization be caught and propagated to the <code>loop_function</code> which can then handle
the failed acquisition function optimization appropriately by, e.g., proposing a randomly sampled point for evaluation?
Setting this to <code>FALSE</code> can be helpful for debugging.
Default is <code>TRUE</code>.
</p>
</dd>
</dl>
<h3>Public fields</h3>

<div class="r6-fields">

<dl>
<dt><code>optimizer</code></dt>
<dd>
<p>(bbotk::Optimizer).</p>
</dd>
<dt><code>terminator</code></dt>
<dd>
<p>(bbotk::Terminator).</p>
</dd>
<dt><code>acq_function</code></dt>
<dd>
<p>(AcqFunction).</p>
</dd>
<dt><code>callbacks</code></dt>
<dd>
<p>(<code>NULL</code> | list of mlr3misc::Callback).</p>
</dd>
</dl>
</div>


<h3>Active bindings</h3>

<div class="r6-active-bindings">

<dl>
<dt><code>print_id</code></dt>
<dd>
<p>(<code>character</code>)<br>
Id used when printing.</p>
</dd>
<dt><code>param_set</code></dt>
<dd>
<p>(paradox::ParamSet)<br>
Set of hyperparameters.</p>
</dd>
</dl>
</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-AcqOptimizer-new"><code>AcqOptimizer$new()</code></a>
</p>
</li>
<li> <p><a href="#method-AcqOptimizer-format"><code>AcqOptimizer$format()</code></a>
</p>
</li>
<li> <p><a href="#method-AcqOptimizer-print"><code>AcqOptimizer$print()</code></a>
</p>
</li>
<li> <p><a href="#method-AcqOptimizer-optimize"><code>AcqOptimizer$optimize()</code></a>
</p>
</li>
<li> <p><a href="#method-AcqOptimizer-clone"><code>AcqOptimizer$clone()</code></a>
</p>
</li>
</ul>
<hr>
<a id="method-AcqOptimizer-new"></a>



<h4>Method <code>new()</code>
</h4>

<p>Creates a new instance of this R6 class.
</p>


<h5>Usage</h5>

<div class="r"><pre>AcqOptimizer$new(optimizer, terminator, acq_function = NULL, callbacks = NULL)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>optimizer</code></dt>
<dd>
<p>(bbotk::Optimizer).</p>
</dd>
<dt><code>terminator</code></dt>
<dd>
<p>(bbotk::Terminator).</p>
</dd>
<dt><code>acq_function</code></dt>
<dd>
<p>(<code>NULL</code> | AcqFunction).</p>
</dd>
<dt><code>callbacks</code></dt>
<dd>
<p>(<code>NULL</code> | list of mlr3misc::Callback)</p>
</dd>
</dl>
</div>


<hr>
<a id="method-AcqOptimizer-format"></a>



<h4>Method <code>format()</code>
</h4>

<p>Helper for print outputs.
</p>


<h5>Usage</h5>

<div class="r"><pre>AcqOptimizer$format()</pre></div>



<h5>Returns</h5>

<p>(<code>character(1)</code>).
</p>


<hr>
<a id="method-AcqOptimizer-print"></a>



<h4>Method <code>print()</code>
</h4>

<p>Print method.
</p>


<h5>Usage</h5>

<div class="r"><pre>AcqOptimizer$print()</pre></div>



<h5>Returns</h5>

<p>(<code>character()</code>).
</p>


<hr>
<a id="method-AcqOptimizer-optimize"></a>



<h4>Method <code>optimize()</code>
</h4>

<p>Optimize the acquisition function.
</p>


<h5>Usage</h5>

<div class="r"><pre>AcqOptimizer$optimize()</pre></div>



<h5>Returns</h5>

<p><code>data.table::data.table()</code> with 1 row per candidate.
</p>


<hr>
<a id="method-AcqOptimizer-clone"></a>



<h4>Method <code>clone()</code>
</h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>AcqOptimizer$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt>
<dd>
<p>Whether to make a deep clone.</p>
</dd>
</dl>
</div>




<h3>Examples</h3>

<pre><code class="language-R">if (requireNamespace("mlr3learners") &amp;
    requireNamespace("DiceKriging") &amp;
    requireNamespace("rgenoud")) {
  library(bbotk)
  library(paradox)
  library(mlr3learners)
  library(data.table)

  fun = function(xs) {
    list(y = xs$x ^ 2)
  }
  domain = ps(x = p_dbl(lower = -10, upper = 10))
  codomain = ps(y = p_dbl(tags = "minimize"))
  objective = ObjectiveRFun$new(fun = fun, domain = domain, codomain = codomain)

  instance = OptimInstanceBatchSingleCrit$new(
    objective = objective,
    terminator = trm("evals", n_evals = 5))

  instance$eval_batch(data.table(x = c(-6, -5, 3, 9)))

  learner = default_gp()

  surrogate = srlrn(learner, archive = instance$archive)

  acq_function = acqf("ei", surrogate = surrogate)

  acq_function$surrogate$update()
  acq_function$update()

  acq_optimizer = acqo(
    optimizer = opt("random_search", batch_size = 1000),
    terminator = trm("evals", n_evals = 1000),
    acq_function = acq_function)

  acq_optimizer$optimize()
}
</code></pre>


</div>