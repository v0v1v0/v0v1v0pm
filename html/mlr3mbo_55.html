<div class="container">

<table style="width: 100%;"><tr>
<td>mlr_tuners_mbo</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>TunerBatch using Model Based Optimization</h2>

<h3>Description</h3>

<p><code>TunerMbo</code> class that implements Model Based Optimization (MBO).
This is a minimal interface internally passing on to OptimizerMbo.
For additional information and documentation see OptimizerMbo.
</p>


<h3>Super classes</h3>

<p><code>mlr3tuning::Tuner</code> -&gt; <code>mlr3tuning::TunerBatch</code> -&gt; <code>mlr3tuning::TunerBatchFromOptimizerBatch</code> -&gt; <code>TunerMbo</code>
</p>


<h3>Active bindings</h3>

<div class="r6-active-bindings">

<dl>
<dt><code>loop_function</code></dt>
<dd>
<p>(loop_function | <code>NULL</code>)<br>
Loop function determining the MBO flavor.</p>
</dd>
<dt><code>surrogate</code></dt>
<dd>
<p>(Surrogate | <code>NULL</code>)<br>
The surrogate.</p>
</dd>
<dt><code>acq_function</code></dt>
<dd>
<p>(AcqFunction | <code>NULL</code>)<br>
The acquisition function.</p>
</dd>
<dt><code>acq_optimizer</code></dt>
<dd>
<p>(AcqOptimizer | <code>NULL</code>)<br>
The acquisition function optimizer.</p>
</dd>
<dt><code>args</code></dt>
<dd>
<p>(named <code>list()</code>)<br>
Further arguments passed to the <code>loop_function</code>.
For example, <code>random_interleave_iter</code>.</p>
</dd>
<dt><code>result_assigner</code></dt>
<dd>
<p>(ResultAssigner | <code>NULL</code>)<br>
The result assigner.</p>
</dd>
<dt><code>param_classes</code></dt>
<dd>
<p>(<code>character()</code>)<br>
Supported parameter classes that the optimizer can optimize.
Determined based on the <code>surrogate</code> and the <code>acq_optimizer</code>.
This corresponds to the values given by a paradox::ParamSet's
<code style="white-space: pre;">⁠$class⁠</code> field.</p>
</dd>
<dt><code>properties</code></dt>
<dd>
<p>(<code>character()</code>)<br>
Set of properties of the optimizer.
Must be a subset of <code>bbotk_reflections$optimizer_properties</code>.
MBO in principle is very flexible and by default we assume that the optimizer has all properties.
When fully initialized, properties are determined based on the <code>loop_function</code> and <code>surrogate</code>.</p>
</dd>
<dt><code>packages</code></dt>
<dd>
<p>(<code>character()</code>)<br>
Set of required packages.
A warning is signaled prior to optimization if at least one of the packages is not installed, but loaded (not attached) later on-demand via <code>requireNamespace()</code>.
Required packages are determined based on the <code>acq_function</code>, <code>surrogate</code> and the <code>acq_optimizer</code>.</p>
</dd>
</dl>
</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-TunerMbo-new"><code>TunerMbo$new()</code></a>
</p>
</li>
<li> <p><a href="#method-TunerMbo-print"><code>TunerMbo$print()</code></a>
</p>
</li>
<li> <p><a href="#method-TunerMbo-reset"><code>TunerMbo$reset()</code></a>
</p>
</li>
<li> <p><a href="#method-TunerMbo-clone"><code>TunerMbo$clone()</code></a>
</p>
</li>
</ul>
<details open><summary>Inherited methods</summary><ul>
<li><span class="pkg-link" data-pkg="mlr3tuning" data-topic="Tuner" data-id="format"><a href="../../mlr3tuning/html/Tuner.html#method-Tuner-format"><code>mlr3tuning::Tuner$format()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3tuning" data-topic="Tuner" data-id="help"><a href="../../mlr3tuning/html/Tuner.html#method-Tuner-help"><code>mlr3tuning::Tuner$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3tuning" data-topic="TunerBatchFromOptimizerBatch" data-id="optimize"><a href="../../mlr3tuning/html/TunerBatchFromOptimizerBatch.html#method-TunerBatchFromOptimizerBatch-optimize"><code>mlr3tuning::TunerBatchFromOptimizerBatch$optimize()</code></a></span></li>
</ul></details><hr>
<a id="method-TunerMbo-new"></a>



<h4>Method <code>new()</code>
</h4>

<p>Creates a new instance of this R6 class.
For more information on default values for <code>loop_function</code>, <code>surrogate</code>, <code>acq_function</code> and <code>acq_optimizer</code>, see <code>?mbo_defaults</code>.
</p>
<p>Note that all the parameters below are simply passed to the OptimizerMbo and
the respective fields are simply (settable) active bindings to the fields of the OptimizerMbo.
</p>


<h5>Usage</h5>

<div class="r"><pre>TunerMbo$new(
  loop_function = NULL,
  surrogate = NULL,
  acq_function = NULL,
  acq_optimizer = NULL,
  args = NULL,
  result_assigner = NULL
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>loop_function</code></dt>
<dd>
<p>(loop_function | <code>NULL</code>)<br>
Loop function determining the MBO flavor.</p>
</dd>
<dt><code>surrogate</code></dt>
<dd>
<p>(Surrogate | <code>NULL</code>)<br>
The surrogate.</p>
</dd>
<dt><code>acq_function</code></dt>
<dd>
<p>(AcqFunction | <code>NULL</code>)<br>
The acquisition function.</p>
</dd>
<dt><code>acq_optimizer</code></dt>
<dd>
<p>(AcqOptimizer | <code>NULL</code>)<br>
The acquisition function optimizer.</p>
</dd>
<dt><code>args</code></dt>
<dd>
<p>(named <code>list()</code>)<br>
Further arguments passed to the <code>loop_function</code>.
For example, <code>random_interleave_iter</code>.</p>
</dd>
<dt><code>result_assigner</code></dt>
<dd>
<p>(ResultAssigner | <code>NULL</code>)<br>
The result assigner.</p>
</dd>
</dl>
</div>


<hr>
<a id="method-TunerMbo-print"></a>



<h4>Method <code>print()</code>
</h4>

<p>Print method.
</p>


<h5>Usage</h5>

<div class="r"><pre>TunerMbo$print()</pre></div>



<h5>Returns</h5>

<p>(<code>character()</code>).
</p>


<hr>
<a id="method-TunerMbo-reset"></a>



<h4>Method <code>reset()</code>
</h4>

<p>Reset the tuner.
Sets the following fields to <code>NULL</code>:
<code>loop_function</code>, <code>surrogate</code>, <code>acq_function</code>, <code>acq_optimizer</code>, <code>args</code>, <code>result_assigner</code>
</p>


<h5>Usage</h5>

<div class="r"><pre>TunerMbo$reset()</pre></div>


<hr>
<a id="method-TunerMbo-clone"></a>



<h4>Method <code>clone()</code>
</h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>TunerMbo$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt>
<dd>
<p>Whether to make a deep clone.</p>
</dd>
</dl>
</div>




<h3>Examples</h3>

<pre><code class="language-R">
if (requireNamespace("mlr3learners") &amp;
    requireNamespace("DiceKriging") &amp;
    requireNamespace("rgenoud")) {

  library(mlr3)
  library(mlr3tuning)

  # single-objective
  task = tsk("wine")
  learner = lrn("classif.rpart", cp = to_tune(lower = 1e-4, upper = 1, logscale = TRUE))
  resampling = rsmp("cv", folds = 3)
  measure = msr("classif.acc")

  instance = TuningInstanceBatchSingleCrit$new(
    task = task,
    learner = learner,
    resampling = resampling,
    measure = measure,
    terminator = trm("evals", n_evals = 5))

  tnr("mbo")$optimize(instance)

  # multi-objective
  task = tsk("wine")
  learner = lrn("classif.rpart", cp = to_tune(lower = 1e-4, upper = 1, logscale = TRUE))
  resampling = rsmp("cv", folds = 3)
  measures = msrs(c("classif.acc", "selected_features"))

  instance = TuningInstanceBatchMultiCrit$new(
    task = task,
    learner = learner,
    resampling = resampling,
    measures = measures,
    terminator = trm("evals", n_evals = 5),
    store_models = TRUE) # required due to selected features

  tnr("mbo")$optimize(instance)
}

</code></pre>


</div>