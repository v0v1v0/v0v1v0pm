<div class="container">

<table style="width: 100%;"><tr>
<td>mlr_pipeops_torch_optimizer</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Optimizer Configuration</h2>

<h3>Description</h3>

<p>Configures the optimizer of a deep learning model.
</p>


<h3>Input and Output Channels</h3>

<p>There is one input channel <code>"input"</code> and one output channel <code>"output"</code>.
During <em>training</em>, the channels are of class <code>ModelDescriptor</code>.
During <em>prediction</em>, the channels are of class <code>Task</code>.
</p>


<h3>State</h3>

<p>The state is the value calculated by the public method <code>shapes_out()</code>.
</p>


<h3>Parameters</h3>

<p>The parameters are defined dynamically from the optimizer that is set during construction.
</p>


<h3>Internals</h3>

<p>During training, the optimizer is cloned and added to the <code>ModelDescriptor</code>.
Note that the parameter set of the stored <code>TorchOptimizer</code> is reference-identical to the parameter set of the
pipeop itself.
</p>


<h3>Super class</h3>

<p><code>mlr3pipelines::PipeOp</code> -&gt; <code>PipeOpTorchOptimizer</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-PipeOpTorchOptimizer-new"><code>PipeOpTorchOptimizer$new()</code></a>
</p>
</li>
<li> <p><a href="#method-PipeOpTorchOptimizer-clone"><code>PipeOpTorchOptimizer$clone()</code></a>
</p>
</li>
</ul>
<details open><summary>Inherited methods</summary><ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href="../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help"><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href="../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict"><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href="../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print"><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href="../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train"><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
</ul></details><hr>
<a id="method-PipeOpTorchOptimizer-new"></a>



<h4>Method <code>new()</code>
</h4>

<p>Creates a new instance of this R6 class.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchOptimizer$new(
  optimizer = t_opt("adam"),
  id = "torch_optimizer",
  param_vals = list()
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>optimizer</code></dt>
<dd>
<p>(<code>TorchOptimizer</code> or <code>character(1)</code> or <code>torch_optimizer_generator</code>)<br>
The optimizer (or something convertible via <code>as_torch_optimizer()</code>).</p>
</dd>
<dt><code>id</code></dt>
<dd>
<p>(<code>character(1)</code>)<br>
Identifier of the resulting  object.</p>
</dd>
<dt><code>param_vals</code></dt>
<dd>
<p>(<code>list()</code>)<br>
List of hyperparameter settings, overwriting the hyperparameter settings that would
otherwise be set during construction.</p>
</dd>
</dl>
</div>


<hr>
<a id="method-PipeOpTorchOptimizer-clone"></a>



<h4>Method <code>clone()</code>
</h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchOptimizer$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt>
<dd>
<p>Whether to make a deep clone.</p>
</dd>
</dl>
</div>




<h3>See Also</h3>

<p>Other PipeOp: 
<code>mlr_pipeops_module</code>,
<code>mlr_pipeops_torch_callbacks</code>
</p>
<p>Other Model Configuration: 
<code>ModelDescriptor()</code>,
<code>mlr_pipeops_torch_callbacks</code>,
<code>mlr_pipeops_torch_loss</code>,
<code>model_descriptor_union()</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">
po_opt = po("torch_optimizer", "sgd", lr = 0.01)
po_opt$param_set
mdin = po("torch_ingress_num")$train(list(tsk("iris")))
mdin[[1L]]$optimizer
mdout = po_opt$train(mdin)
mdout[[1L]]$optimizer

</code></pre>


</div>