<div class="container">

<table style="width: 100%;"><tr>
<td>mlr_pipeops_torch_model</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>PipeOp Torch Model</h2>

<h3>Description</h3>

<p>Builds a Torch Learner from a <code>ModelDescriptor</code> and trains it with the given parameter specification.
The task type must be specified during construction.
</p>


<h3>Input and Output Channels</h3>

<p>There is one input channel <code>"input"</code> that takes in <code>ModelDescriptor</code> during traing and a <code>Task</code> of the specified
<code>task_type</code> during prediction.
The output is <code>NULL</code> during training and a <code>Prediction</code> of given <code>task_type</code> during prediction.
</p>


<h3>State</h3>

<p>A trained <code>LearnerTorchModel</code>.
</p>


<h3>Parameters</h3>

<p><strong>General</strong>:
</p>
<p>The parameters of the optimizer, loss and callbacks,
prefixed with <code>"opt."</code>, <code>"loss."</code> and <code>"cb.&lt;callback id&gt;."</code> respectively, as well as:
</p>

<ul>
<li> <p><code>epochs</code> :: <code>integer(1)</code><br>
The number of epochs.
</p>
</li>
<li> <p><code>device</code> :: <code>character(1)</code><br>
The device. One of <code>"auto"</code>, <code>"cpu"</code>, or <code>"cuda"</code> or other values defined in <code>mlr_reflections$torch$devices</code>.
The value is initialized to <code>"auto"</code>, which will select <code>"cuda"</code> if possible, then try <code>"mps"</code> and otherwise
fall back to <code>"cpu"</code>.
</p>
</li>
<li> <p><code>num_threads</code> :: <code>integer(1)</code><br>
The number of threads for intraop pararallelization (if <code>device</code> is <code>"cpu"</code>).
This value is initialized to 1.
</p>
</li>
<li> <p><code>seed</code> :: <code>integer(1)</code> or <code>"random"</code> or <code>NULL</code><br>
The torch seed that is used during training and prediction.
This value is initialized to <code>"random"</code>, which means that a random seed will be sampled at the beginning of the
training phase. This seed (either set or randomly sampled) is available via <code style="white-space: pre;">⁠$model$seed⁠</code> after training
and used during prediction.
Note that by setting the seed during the training phase this will mean that by default (i.e. when <code>seed</code> is
<code>"random"</code>), clones of the learner will use a different seed.
If set to <code>NULL</code>, no seeding will be done.
</p>
</li>
</ul>
<p><strong>Evaluation</strong>:
</p>

<ul>
<li> <p><code>measures_train</code> :: <code>Measure</code> or <code>list()</code> of <code>Measure</code>s.<br>
Measures to be evaluated during training.
</p>
</li>
<li> <p><code>measures_valid</code> :: <code>Measure</code> or <code>list()</code> of <code>Measure</code>s.<br>
Measures to be evaluated during validation.
</p>
</li>
<li> <p><code>eval_freq</code> :: <code>integer(1)</code><br>
How often the train / validation predictions are evaluated using <code>measures_train</code> / <code>measures_valid</code>.
This is initialized to <code>1</code>.
Note that the final model is always evaluated.
</p>
</li>
</ul>
<p><strong>Early Stopping</strong>:
</p>

<ul>
<li> <p><code>patience</code> :: <code>integer(1)</code><br>
This activates early stopping using the validation scores.
If the performance of a model does not improve for <code>patience</code> evaluation steps, training is ended.
Note that the final model is stored in the learner, not the best model.
This is initialized to <code>0</code>, which means no early stopping.
The first entry from <code>measures_valid</code> is used as the metric.
This also requires to specify the <code style="white-space: pre;">⁠$validate⁠</code> field of the Learner, as well as <code>measures_valid</code>.
</p>
</li>
<li> <p><code>min_delta</code> :: <code>double(1)</code><br>
The minimum improvement threshold (<code>&gt;</code>) for early stopping.
Is initialized to 0.
</p>
</li>
</ul>
<p><strong>Dataloader</strong>:
</p>

<ul>
<li> <p><code>batch_size</code> :: <code>integer(1)</code><br>
The batch size (required).
</p>
</li>
<li> <p><code>shuffle</code> :: <code>logical(1)</code><br>
Whether to shuffle the instances in the dataset. Default is <code>FALSE</code>.
This does not impact validation.
</p>
</li>
<li> <p><code>sampler</code> :: <code>torch::sampler</code><br>
Object that defines how the dataloader draw samples.
</p>
</li>
<li> <p><code>batch_sampler</code> :: <code>torch::sampler</code><br>
Object that defines how the dataloader draws batches.
</p>
</li>
<li> <p><code>num_workers</code> :: <code>integer(1)</code><br>
The number of workers for data loading (batches are loaded in parallel).
The default is <code>0</code>, which means that data will be loaded in the main process.
</p>
</li>
<li> <p><code>collate_fn</code> :: <code>function</code><br>
How to merge a list of samples to form a batch.
</p>
</li>
<li> <p><code>pin_memory</code> :: <code>logical(1)</code><br>
Whether the dataloader copies tensors into CUDA pinned memory before returning them.
</p>
</li>
<li> <p><code>drop_last</code> :: <code>logical(1)</code><br>
Whether to drop the last training batch in each epoch during training. Default is <code>FALSE</code>.
</p>
</li>
<li> <p><code>timeout</code> :: <code>numeric(1)</code><br>
The timeout value for collecting a batch from workers.
Negative values mean no timeout and the default is <code>-1</code>.
</p>
</li>
<li> <p><code>worker_init_fn</code> :: <code style="white-space: pre;">⁠function(id)⁠</code><br>
A function that receives the worker id (in <code style="white-space: pre;">⁠[1, num_workers]⁠</code>) and is exectued after seeding
on the worker but before data loading.
</p>
</li>
<li> <p><code>worker_globals</code> :: <code>list()</code> | <code>character()</code><br>
When loading data in parallel, this allows to export globals to the workers.
If this is a character vector, the objects in the global environment with those names
are copied to the workers.
</p>
</li>
<li> <p><code>worker_packages</code> :: <code>character()</code><br>
Which packages to load on the workers.
</p>
</li>
</ul>
<p>Also see <code>torch::dataloder</code> for more information.
</p>


<h3>Internals</h3>

<p>A <code>LearnerTorchModel</code> is created by calling <code>model_descriptor_to_learner()</code> on the
provided <code>ModelDescriptor</code> that is received through the input channel.
Then the parameters are set according to the parameters specified in <code>PipeOpTorchModel</code> and
its '$train()<code style="white-space: pre;">⁠ method is called on the [⁠</code>Task<code style="white-space: pre;">⁠][mlr3::Task] stored in the [⁠</code>ModelDescriptor'].
</p>


<h3>Super classes</h3>

<p><code>mlr3pipelines::PipeOp</code> -&gt; <code>mlr3pipelines::PipeOpLearner</code> -&gt; <code>PipeOpTorchModel</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-PipeOpTorchModel-new"><code>PipeOpTorchModel$new()</code></a>
</p>
</li>
<li> <p><a href="#method-PipeOpTorchModel-clone"><code>PipeOpTorchModel$clone()</code></a>
</p>
</li>
</ul>
<details open><summary>Inherited methods</summary><ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href="../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help"><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href="../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict"><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href="../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print"><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href="../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train"><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
</ul></details><hr>
<a id="method-PipeOpTorchModel-new"></a>



<h4>Method <code>new()</code>
</h4>

<p>Creates a new instance of this R6 class.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchModel$new(task_type, id = "torch_model", param_vals = list())</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>task_type</code></dt>
<dd>
<p>(<code>character(1)</code>)<br>
The task type of the model.</p>
</dd>
<dt><code>id</code></dt>
<dd>
<p>(<code>character(1)</code>)<br>
Identifier of the resulting  object.</p>
</dd>
<dt><code>param_vals</code></dt>
<dd>
<p>(<code>list()</code>)<br>
List of hyperparameter settings, overwriting the hyperparameter settings that would
otherwise be set during construction.</p>
</dd>
</dl>
</div>


<hr>
<a id="method-PipeOpTorchModel-clone"></a>



<h4>Method <code>clone()</code>
</h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchModel$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt>
<dd>
<p>Whether to make a deep clone.</p>
</dd>
</dl>
</div>




<h3>See Also</h3>

<p>Other PipeOps: 
<code>mlr_pipeops_nn_avg_pool1d</code>,
<code>mlr_pipeops_nn_avg_pool2d</code>,
<code>mlr_pipeops_nn_avg_pool3d</code>,
<code>mlr_pipeops_nn_batch_norm1d</code>,
<code>mlr_pipeops_nn_batch_norm2d</code>,
<code>mlr_pipeops_nn_batch_norm3d</code>,
<code>mlr_pipeops_nn_block</code>,
<code>mlr_pipeops_nn_celu</code>,
<code>mlr_pipeops_nn_conv1d</code>,
<code>mlr_pipeops_nn_conv2d</code>,
<code>mlr_pipeops_nn_conv3d</code>,
<code>mlr_pipeops_nn_conv_transpose1d</code>,
<code>mlr_pipeops_nn_conv_transpose2d</code>,
<code>mlr_pipeops_nn_conv_transpose3d</code>,
<code>mlr_pipeops_nn_dropout</code>,
<code>mlr_pipeops_nn_elu</code>,
<code>mlr_pipeops_nn_flatten</code>,
<code>mlr_pipeops_nn_gelu</code>,
<code>mlr_pipeops_nn_glu</code>,
<code>mlr_pipeops_nn_hardshrink</code>,
<code>mlr_pipeops_nn_hardsigmoid</code>,
<code>mlr_pipeops_nn_hardtanh</code>,
<code>mlr_pipeops_nn_head</code>,
<code>mlr_pipeops_nn_layer_norm</code>,
<code>mlr_pipeops_nn_leaky_relu</code>,
<code>mlr_pipeops_nn_linear</code>,
<code>mlr_pipeops_nn_log_sigmoid</code>,
<code>mlr_pipeops_nn_max_pool1d</code>,
<code>mlr_pipeops_nn_max_pool2d</code>,
<code>mlr_pipeops_nn_max_pool3d</code>,
<code>mlr_pipeops_nn_merge</code>,
<code>mlr_pipeops_nn_merge_cat</code>,
<code>mlr_pipeops_nn_merge_prod</code>,
<code>mlr_pipeops_nn_merge_sum</code>,
<code>mlr_pipeops_nn_prelu</code>,
<code>mlr_pipeops_nn_relu</code>,
<code>mlr_pipeops_nn_relu6</code>,
<code>mlr_pipeops_nn_reshape</code>,
<code>mlr_pipeops_nn_rrelu</code>,
<code>mlr_pipeops_nn_selu</code>,
<code>mlr_pipeops_nn_sigmoid</code>,
<code>mlr_pipeops_nn_softmax</code>,
<code>mlr_pipeops_nn_softplus</code>,
<code>mlr_pipeops_nn_softshrink</code>,
<code>mlr_pipeops_nn_softsign</code>,
<code>mlr_pipeops_nn_squeeze</code>,
<code>mlr_pipeops_nn_tanh</code>,
<code>mlr_pipeops_nn_tanhshrink</code>,
<code>mlr_pipeops_nn_threshold</code>,
<code>mlr_pipeops_nn_unsqueeze</code>,
<code>mlr_pipeops_torch_ingress</code>,
<code>mlr_pipeops_torch_ingress_categ</code>,
<code>mlr_pipeops_torch_ingress_ltnsr</code>,
<code>mlr_pipeops_torch_ingress_num</code>,
<code>mlr_pipeops_torch_loss</code>,
<code>mlr_pipeops_torch_model_classif</code>,
<code>mlr_pipeops_torch_model_regr</code>
</p>


</div>