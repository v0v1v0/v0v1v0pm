<div class="container">

<table style="width: 100%;"><tr>
<td>mlr_learners.tab_resnet</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Tabular ResNet</h2>

<h3>Description</h3>

<p>Tabular resnet.
</p>


<h3>Dictionary</h3>

<p>This Learner can be instantiated using the sugar function <code>lrn()</code>:
</p>
<div class="sourceCode"><pre>lrn("classif.tab_resnet", ...)
lrn("regr.tab_resnet", ...)
</pre></div>


<h3>Properties</h3>


<ul>
<li>
<p> Supported task types: 'classif', 'regr'
</p>
</li>
<li>
<p> Predict Types:
</p>

<ul>
<li>
<p> classif: 'response', 'prob'
</p>
</li>
<li>
<p> regr: 'response'
</p>
</li>
</ul>
</li>
<li>
<p> Feature Types: “integer”, “numeric”
</p>
</li>
<li>
<p> Required Packages: <a href="https://CRAN.R-project.org/package=mlr3"><span class="pkg">mlr3</span></a>, <a href="https://CRAN.R-project.org/package=mlr3torch"><span class="pkg">mlr3torch</span></a>, <a href="https://CRAN.R-project.org/package=torch"><span class="pkg">torch</span></a>
</p>
</li>
</ul>
<h3>Parameters</h3>

<p>Parameters from <code>LearnerTorch</code>, as well as:
</p>

<ul>
<li> <p><code>n_blocks</code> :: <code>integer(1)</code><br>
The number of blocks.
</p>
</li>
<li> <p><code>d_block</code> :: <code>integer(1)</code><br>
The input and output dimension of a block.
</p>
</li>
<li> <p><code>d_hidden</code> :: <code>integer(1)</code><br>
The latent dimension of a block.
</p>
</li>
<li> <p><code>d_hidden_multiplier</code> :: <code>integer(1)</code><br>
Alternative way to specify the latent dimension as <code>d_block * d_hidden_multiplier</code>.
</p>
</li>
<li> <p><code>dropout1</code> :: <code>numeric(1)</code><br>
First dropout ratio.
</p>
</li>
<li> <p><code>dropout2</code> :: <code>numeric(1)</code><br>
Second dropout ratio.
</p>
</li>
</ul>
<h3>Super classes</h3>

<p><code>mlr3::Learner</code> -&gt; <code>mlr3torch::LearnerTorch</code> -&gt; <code>LearnerTorchTabResNet</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-LearnerTorchTabResNet-new"><code>LearnerTorchTabResNet$new()</code></a>
</p>
</li>
<li> <p><a href="#method-LearnerTorchTabResNet-clone"><code>LearnerTorchTabResNet$clone()</code></a>
</p>
</li>
</ul>
<details><summary>Inherited methods</summary><ul>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="base_learner"><a href="../../mlr3/html/Learner.html#method-Learner-base_learner"><code>mlr3::Learner$base_learner()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="help"><a href="../../mlr3/html/Learner.html#method-Learner-help"><code>mlr3::Learner$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="predict"><a href="../../mlr3/html/Learner.html#method-Learner-predict"><code>mlr3::Learner$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="predict_newdata"><a href="../../mlr3/html/Learner.html#method-Learner-predict_newdata"><code>mlr3::Learner$predict_newdata()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="reset"><a href="../../mlr3/html/Learner.html#method-Learner-reset"><code>mlr3::Learner$reset()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="train"><a href="../../mlr3/html/Learner.html#method-Learner-train"><code>mlr3::Learner$train()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="LearnerTorch" data-id="dataset"><a href="../../mlr3torch/html/LearnerTorch.html#method-LearnerTorch-dataset"><code>mlr3torch::LearnerTorch$dataset()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="LearnerTorch" data-id="format"><a href="../../mlr3torch/html/LearnerTorch.html#method-LearnerTorch-format"><code>mlr3torch::LearnerTorch$format()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="LearnerTorch" data-id="marshal"><a href="../../mlr3torch/html/LearnerTorch.html#method-LearnerTorch-marshal"><code>mlr3torch::LearnerTorch$marshal()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="LearnerTorch" data-id="print"><a href="../../mlr3torch/html/LearnerTorch.html#method-LearnerTorch-print"><code>mlr3torch::LearnerTorch$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="LearnerTorch" data-id="unmarshal"><a href="../../mlr3torch/html/LearnerTorch.html#method-LearnerTorch-unmarshal"><code>mlr3torch::LearnerTorch$unmarshal()</code></a></span></li>
</ul></details><hr>
<a id="method-LearnerTorchTabResNet-new"></a>



<h4>Method <code>new()</code>
</h4>

<p>Creates a new instance of this R6 class.
</p>


<h5>Usage</h5>

<div class="r"><pre>LearnerTorchTabResNet$new(
  task_type,
  optimizer = NULL,
  loss = NULL,
  callbacks = list()
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>task_type</code></dt>
<dd>
<p>(<code>character(1)</code>)<br>
The task type, either <code style="white-space: pre;">⁠"classif⁠</code>" or <code>"regr"</code>.</p>
</dd>
<dt><code>optimizer</code></dt>
<dd>
<p>(<code>TorchOptimizer</code>)<br>
The optimizer to use for training.
Per default, <em>adam</em> is used.</p>
</dd>
<dt><code>loss</code></dt>
<dd>
<p>(<code>TorchLoss</code>)<br>
The loss used to train the network.
Per default, <em>mse</em> is used for regression and <em>cross_entropy</em> for classification.</p>
</dd>
<dt><code>callbacks</code></dt>
<dd>
<p>(<code>list()</code> of <code>TorchCallback</code>s)<br>
The callbacks. Must have unique ids.</p>
</dd>
</dl>
</div>


<hr>
<a id="method-LearnerTorchTabResNet-clone"></a>



<h4>Method <code>clone()</code>
</h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>LearnerTorchTabResNet$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt>
<dd>
<p>Whether to make a deep clone.</p>
</dd>
</dl>
</div>




<h3>References</h3>

<p>Gorishniy Y, Rubachev I, Khrulkov V, Babenko A (2021).
“Revisiting Deep Learning  for Tabular Data.”
<em>arXiv</em>, <b>2106.11959</b>.
</p>


<h3>See Also</h3>

<p>Other Learner: 
<code>mlr_learners.mlp</code>,
<code>mlr_learners.torch_featureless</code>,
<code>mlr_learners_torch</code>,
<code>mlr_learners_torch_image</code>,
<code>mlr_learners_torch_model</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">
# Define the Learner and set parameter values
learner = lrn("classif.tab_resnet")
learner$param_set$set_values(
  epochs = 1, batch_size = 16, device = "cpu",
  n_blocks = 2, d_block = 10, d_hidden = 20, dropout1 = 0.3, dropout2 = 0.3
)

# Define a Task
task = tsk("iris")

# Create train and test set
ids = partition(task)

# Train the learner on the training ids
learner$train(task, row_ids = ids$train)

# Make predictions for the test rows
predictions = learner$predict(task, row_ids = ids$test)

# Score the predictions
predictions$score()

</code></pre>


</div>