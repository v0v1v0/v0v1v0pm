<div class="container">

<table style="width: 100%;"><tr>
<td>materialize_internal</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Materialize a Lazy Tensor</h2>

<h3>Description</h3>

<p>Convert a <code>lazy_tensor</code> to a <code>torch_tensor</code>.
</p>


<h3>Usage</h3>

<pre><code class="language-R">materialize_internal(x, device = "cpu", cache = NULL, rbind)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>(<code>lazy_tensor()</code>)<br>
The lazy tensor to materialize.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>device</code></td>
<td>
<p>(<code>character(1L)</code>)<br>
The device to put the materialized tensor on (after running the preprocessing graph).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cache</code></td>
<td>
<p>(<code>NULL</code> or <code>environment()</code>)<br>
Whether to cache the (intermediate) results of the materialization.
This can make data loading faster when multiple <code>lazy_tensor</code>s reference the same dataset or graph.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>rbind</code></td>
<td>
<p>(<code>logical(1)</code>)<br>
Whtether to rbind the resulting tensors (<code>TRUE</code>) or return them as a list of tensors (<code>FALSE</code>).</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Materializing a lazy tensor consists of:
</p>

<ol>
<li>
<p> Loading the data from the internal dataset of the <code>DataDescriptor</code>.
</p>
</li>
<li>
<p> Processing these batches in the preprocessing <code>Graph</code>s.
</p>
</li>
<li>
<p> Returning the result of the <code>PipeOp</code> pointed to by the <code>DataDescriptor</code> (<code>pointer</code>).
</p>
</li>
</ol>
<p>When materializing multiple <code>lazy_tensor</code> columns, caching can be useful because:
a) Output(s) from the dataset might be input to multiple graphs.
(in task_dataset this is shoudl rarely be the case because because we try to merge them).
b) Different lazy tensors might be outputs from the same graph.
</p>
<p>For this reason it is possible to provide a cache environment.
The hash key for a) is the hash of the indices and the dataset.
The hash key for b) is the hash of the indices dataset and preprocessing graph.
</p>


<h3>Value</h3>

<p><code>lazy_tensor()</code>
</p>


</div>