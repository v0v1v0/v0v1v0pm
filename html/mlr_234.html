<div class="container">

<table style="width: 100%;"><tr>
<td>makeBaggingWrapper</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Fuse learner with the bagging technique.</h2>

<h3>Description</h3>

<p>Fuses a learner with the bagging method
(i.e., similar to what a <code>randomForest</code> does).
Creates a learner object, which can be
used like any other learner object.
Models can easily be accessed via getLearnerModel.
</p>
<p>Bagging is implemented as follows:
For each iteration a random data subset is sampled (with or without replacement)
and potentially the number of features is also restricted to
a random subset. Note that this is usually handled in a slightly different way
in the random forest where features are sampled at each tree split).
</p>
<p>Prediction works as follows:
For classification we do majority voting to create a discrete label and
probabilities are predicted by considering the proportions of all predicted labels.
For regression the mean value and the standard deviations across predictions is computed.
</p>
<p>Note that the passed base learner must always have <code>predict.type = 'response'</code>,
while the BaggingWrapper can estimate probabilities and standard errors, so it can
be set, e.g., to <code>predict.type = 'prob'</code>. For this reason, when you call
setPredictType, the type is only set for the BaggingWrapper, not passed
down to the inner learner.
</p>


<h3>Usage</h3>

<pre><code class="language-R">makeBaggingWrapper(
  learner,
  bw.iters = 10L,
  bw.replace = TRUE,
  bw.size,
  bw.feats = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>learner</code></td>
<td>
<p>(Learner | <code>character(1)</code>)<br>
The learner.
If you pass a string the learner will be created via makeLearner.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>bw.iters</code></td>
<td>
<p>(<code>integer(1)</code>)<br>
Iterations = number of fitted models in bagging.
Default is 10.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>bw.replace</code></td>
<td>
<p>(<code>logical(1)</code>)<br>
Sample bags with replacement (bootstrapping)?
Default is TRUE.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>bw.size</code></td>
<td>
<p>(<code>numeric(1)</code>)<br>
Percentage size of sampled bags.
Default is 1 for bootstrapping and 0.632 for subsampling.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>bw.feats</code></td>
<td>
<p>(<code>numeric(1)</code>)<br>
Percentage size of randomly selected features in bags.
Default is 1.
At least one feature will always be selected.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>Learner.
</p>


<h3>See Also</h3>

<p>Other wrapper: 
<code>makeClassificationViaRegressionWrapper()</code>,
<code>makeConstantClassWrapper()</code>,
<code>makeCostSensClassifWrapper()</code>,
<code>makeCostSensRegrWrapper()</code>,
<code>makeDownsampleWrapper()</code>,
<code>makeDummyFeaturesWrapper()</code>,
<code>makeExtractFDAFeatsWrapper()</code>,
<code>makeFeatSelWrapper()</code>,
<code>makeFilterWrapper()</code>,
<code>makeImputeWrapper()</code>,
<code>makeMulticlassWrapper()</code>,
<code>makeMultilabelBinaryRelevanceWrapper()</code>,
<code>makeMultilabelClassifierChainsWrapper()</code>,
<code>makeMultilabelDBRWrapper()</code>,
<code>makeMultilabelNestedStackingWrapper()</code>,
<code>makeMultilabelStackingWrapper()</code>,
<code>makeOverBaggingWrapper()</code>,
<code>makePreprocWrapper()</code>,
<code>makePreprocWrapperCaret()</code>,
<code>makeRemoveConstantFeaturesWrapper()</code>,
<code>makeSMOTEWrapper()</code>,
<code>makeTuneWrapper()</code>,
<code>makeUndersampleWrapper()</code>,
<code>makeWeightedClassesWrapper()</code>
</p>


</div>