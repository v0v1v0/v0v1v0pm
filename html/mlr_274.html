<div class="container">

<table style="width: 100%;"><tr>
<td>makeMultilabelDBRWrapper</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Use dependent binary relevance method (DBR) to create a multilabel learner.</h2>

<h3>Description</h3>

<p>Every learner which is implemented in mlr and which supports binary
classification can be converted to a wrapped DBR multilabel learner.
The multilabel classification problem is converted into simple binary classifications
for each label/target on which the binary learner is applied.
For each target, actual information of all binary labels (except the target variable) is used as additional features.
During prediction these labels need are obtained by the binary relevance method using the same binary learner.
</p>
<p>Models can easily be accessed via getLearnerModel.
</p>


<h3>Usage</h3>

<pre><code class="language-R">makeMultilabelDBRWrapper(learner)
</code></pre>


<h3>Arguments</h3>

<table><tr style="vertical-align: top;">
<td><code>learner</code></td>
<td>
<p>(Learner | <code>character(1)</code>)<br>
The learner.
If you pass a string the learner will be created via makeLearner.</p>
</td>
</tr></table>
<h3>Value</h3>

<p>Learner.
</p>


<h3>References</h3>

<p>Montanes, E. et al. (2013)
<em>Dependent binary relevance models for multi-label classification</em>
Artificial Intelligence Center, University of Oviedo at Gijon, Spain.
</p>


<h3>See Also</h3>

<p>Other wrapper: 
<code>makeBaggingWrapper()</code>,
<code>makeClassificationViaRegressionWrapper()</code>,
<code>makeConstantClassWrapper()</code>,
<code>makeCostSensClassifWrapper()</code>,
<code>makeCostSensRegrWrapper()</code>,
<code>makeDownsampleWrapper()</code>,
<code>makeDummyFeaturesWrapper()</code>,
<code>makeExtractFDAFeatsWrapper()</code>,
<code>makeFeatSelWrapper()</code>,
<code>makeFilterWrapper()</code>,
<code>makeImputeWrapper()</code>,
<code>makeMulticlassWrapper()</code>,
<code>makeMultilabelBinaryRelevanceWrapper()</code>,
<code>makeMultilabelClassifierChainsWrapper()</code>,
<code>makeMultilabelNestedStackingWrapper()</code>,
<code>makeMultilabelStackingWrapper()</code>,
<code>makeOverBaggingWrapper()</code>,
<code>makePreprocWrapper()</code>,
<code>makePreprocWrapperCaret()</code>,
<code>makeRemoveConstantFeaturesWrapper()</code>,
<code>makeSMOTEWrapper()</code>,
<code>makeTuneWrapper()</code>,
<code>makeUndersampleWrapper()</code>,
<code>makeWeightedClassesWrapper()</code>
</p>
<p>Other multilabel: 
<code>getMultilabelBinaryPerformances()</code>,
<code>makeMultilabelBinaryRelevanceWrapper()</code>,
<code>makeMultilabelClassifierChainsWrapper()</code>,
<code>makeMultilabelNestedStackingWrapper()</code>,
<code>makeMultilabelStackingWrapper()</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">if (requireNamespace("rpart")) {
d = getTaskData(yeast.task)
# drop some labels so example runs faster
d = d[seq(1, nrow(d), by = 20), c(1:2, 15:17)]
task = makeMultilabelTask(data = d, target = c("label1", "label2"))
lrn = makeLearner("classif.rpart")
lrn = makeMultilabelBinaryRelevanceWrapper(lrn)
lrn = setPredictType(lrn, "prob")
# train, predict and evaluate
mod = train(lrn, task)
pred = predict(mod, task)
performance(pred, measure = list(multilabel.hamloss, multilabel.subset01, multilabel.f1))
# the next call basically has the same structure for any multilabel meta wrapper
getMultilabelBinaryPerformances(pred, measures = list(mmce, auc))
# above works also with predictions from resample!
}
</code></pre>


</div>