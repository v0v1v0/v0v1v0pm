<div class="container">

<table style="width: 100%;"><tr>
<td>performance</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Measure performance of prediction.</h2>

<h3>Description</h3>

<p>Measures the quality of a prediction w.r.t. some performance measure.
</p>


<h3>Usage</h3>

<pre><code class="language-R">performance(
  pred,
  measures,
  task = NULL,
  model = NULL,
  feats = NULL,
  simpleaggr = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>pred</code></td>
<td>
<p>(Prediction)<br>
Prediction object.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>measures</code></td>
<td>
<p>(Measure | list of Measure)<br>
Performance measure(s) to evaluate.
Default is the default measure for the task, see here getDefaultMeasure.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>task</code></td>
<td>
<p>(Task)<br>
Learning task, might be requested by performance measure, usually not needed except for clustering or survival.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>model</code></td>
<td>
<p>(WrappedModel)<br>
Model built on training data, might be requested by performance measure, usually not needed except for survival.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>feats</code></td>
<td>
<p>(data.frame)<br>
Features of predicted data, usually not needed except for clustering.
If the prediction was generated from a <code>task</code>, you can also pass this instead and the features
are extracted from it.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>simpleaggr</code></td>
<td>
<p>(logical)<br>
If TRUE, aggregation of <code>ResamplePrediction</code> objects is skipped. This is used internally for threshold tuning. Default is <code>FALSE</code>.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>(named numeric). Performance value(s), named by measure(s).
</p>


<h3>See Also</h3>

<p>Other performance: 
<code>ConfusionMatrix</code>,
<code>calculateConfusionMatrix()</code>,
<code>calculateROCMeasures()</code>,
<code>estimateRelativeOverfitting()</code>,
<code>makeCostMeasure()</code>,
<code>makeCustomResampledMeasure()</code>,
<code>makeMeasure()</code>,
<code>measures</code>,
<code>setAggregation()</code>,
<code>setMeasurePars()</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">training.set = seq(1, nrow(iris), by = 2)
test.set = seq(2, nrow(iris), by = 2)

task = makeClassifTask(data = iris, target = "Species")
lrn = makeLearner("classif.lda")
mod = train(lrn, task, subset = training.set)
pred = predict(mod, newdata = iris[test.set, ])
performance(pred, measures = mmce)

# Compute multiple performance measures at once
ms = list("mmce" = mmce, "acc" = acc, "timetrain" = timetrain)
performance(pred, measures = ms, task, mod)
</code></pre>


</div>