<div class="container">

<table style="width: 100%;"><tr>
<td>makeTuneControlIrace</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Create control object for hyperparameter tuning with Irace.</h2>

<h3>Description</h3>

<p>Tuning with iterated F-Racing with method irace::irace. All
kinds of parameter types can be handled. We return the best of the final
elite candidates found by irace in the last race. Its estimated performance
is the mean of all evaluations ever done for that candidate. More information
on irace can be found in package vignette: <code>vignette("irace-package", package = "irace")</code>
</p>
<p>For resampling you have to pass a ResampleDesc, not a ResampleInstance.
The resampling strategy is randomly instantiated <code>n.instances</code> times and
these are the instances in the sense of irace (<code>instances</code> element of
<code>tunerConfig</code> in irace::irace). Also note that irace will always store its
tuning results in a file on disk, see the package documentation for details
on this and how to change the file path.
</p>


<h3>Usage</h3>

<pre><code class="language-R">makeTuneControlIrace(
  impute.val = NULL,
  n.instances = 100L,
  show.irace.output = FALSE,
  tune.threshold = FALSE,
  tune.threshold.args = list(),
  log.fun = "default",
  final.dw.perc = NULL,
  budget = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>impute.val</code></td>
<td>
<p>(numeric)<br>
If something goes wrong during optimization (e.g. the learner crashes),
this value is fed back to the tuner, so the tuning algorithm does not abort.
Imputation is only active if <code>on.learner.error</code> is configured not to stop in configureMlr.
It is not stored in the optimization path, an NA and a corresponding error message are
logged instead.
Note that this value is later multiplied by -1 for maximization measures internally, so you
need to enter a larger positive value for maximization here as well.
Default is the worst obtainable value of the performance measure you optimize for when
you aggregate by mean value, or <code>Inf</code> instead.
For multi-criteria optimization pass a vector of imputation values, one for each of your measures,
in the same order as your measures.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n.instances</code></td>
<td>
<p>(<code>integer(1)</code>)<br>
Number of random resampling instances for irace, see details.
Default is 100.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>show.irace.output</code></td>
<td>
<p>(<code>logical(1)</code>)<br>
Show console output of irace while tuning?
Default is <code>FALSE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tune.threshold</code></td>
<td>
<p>(<code>logical(1)</code>)<br>
Should the threshold be tuned for the measure at hand, after each hyperparameter evaluation,
via tuneThreshold?
Only works for classification if the predict type is “prob”.
Default is <code>FALSE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tune.threshold.args</code></td>
<td>
<p>(list)<br>
Further arguments for threshold tuning that are passed down to tuneThreshold.
Default is none.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>log.fun</code></td>
<td>
<p>(<code>function</code> | <code>character(1)</code>)<br>
Function used for logging. If set to “default” (the default), the evaluated design points, the resulting
performances, and the runtime will be reported.
If set to “memory” the memory usage for each evaluation will also be displayed, with <code>character(1)</code> small increase
in run time.
Otherwise <code>character(1)</code> function with arguments <code>learner</code>, <code>resampling</code>, <code>measures</code>,
<code>par.set</code>, <code>control</code>, <code>opt.path</code>, <code>dob</code>, <code>x</code>, <code>y</code>, <code>remove.nas</code>,
<code>stage</code> and <code>prev.stage</code> is expected.
The default displays the performance measures, the time needed for evaluating,
the currently used memory and the max memory ever used before
(the latter two both taken from gc).
See the implementation for details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>final.dw.perc</code></td>
<td>
<p>(<code>boolean</code>)<br>
If a Learner wrapped by a makeDownsampleWrapper is used, you can define the value of <code>dw.perc</code> which is used to train the Learner with the final parameter setting found by the tuning.
Default is <code>NULL</code> which will not change anything.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>budget</code></td>
<td>
<p>(<code>integer(1)</code>)<br>
Maximum budget for tuning. This value restricts the number of function
evaluations. It is passed to <code>maxExperiments</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>(any)<br>
Further control parameters passed to the <code>control</code> arguments of
cmaes::cma_es or GenSA::GenSA, as well as
towards the <code>tunerConfig</code> argument of irace::irace.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>(TuneControlIrace)
</p>


<h3>See Also</h3>

<p>Other tune: 
<code>TuneControl</code>,
<code>getNestedTuneResultsOptPathDf()</code>,
<code>getNestedTuneResultsX()</code>,
<code>getResamplingIndices()</code>,
<code>getTuneResult()</code>,
<code>makeModelMultiplexer()</code>,
<code>makeModelMultiplexerParamSet()</code>,
<code>makeTuneControlCMAES()</code>,
<code>makeTuneControlDesign()</code>,
<code>makeTuneControlGenSA()</code>,
<code>makeTuneControlGrid()</code>,
<code>makeTuneControlMBO()</code>,
<code>makeTuneControlRandom()</code>,
<code>makeTuneWrapper()</code>,
<code>tuneParams()</code>,
<code>tuneThreshold()</code>
</p>


</div>