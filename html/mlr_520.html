<div class="container">

<table style="width: 100%;"><tr>
<td>makeTuneControlRandom</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Create control object for hyperparameter tuning with random search.</h2>

<h3>Description</h3>

<p>Random search. All kinds of parameter types can be handled.
</p>


<h3>Usage</h3>

<pre><code class="language-R">makeTuneControlRandom(
  same.resampling.instance = TRUE,
  maxit = NULL,
  tune.threshold = FALSE,
  tune.threshold.args = list(),
  log.fun = "default",
  final.dw.perc = NULL,
  budget = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>same.resampling.instance</code></td>
<td>
<p>(<code>logical(1)</code>)<br>
Should the same resampling instance be used for all evaluations to reduce variance?
Default is <code>TRUE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>maxit</code></td>
<td>
<p>(<code>integer(1)</code> | NULL)<br>
Number of iterations for random search.
Default is 100.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tune.threshold</code></td>
<td>
<p>(<code>logical(1)</code>)<br>
Should the threshold be tuned for the measure at hand, after each hyperparameter evaluation,
via tuneThreshold?
Only works for classification if the predict type is “prob”.
Default is <code>FALSE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tune.threshold.args</code></td>
<td>
<p>(list)<br>
Further arguments for threshold tuning that are passed down to tuneThreshold.
Default is none.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>log.fun</code></td>
<td>
<p>(<code>function</code> | <code>character(1)</code>)<br>
Function used for logging. If set to “default” (the default), the evaluated design points, the resulting
performances, and the runtime will be reported.
If set to “memory” the memory usage for each evaluation will also be displayed, with <code>character(1)</code> small increase
in run time.
Otherwise <code>character(1)</code> function with arguments <code>learner</code>, <code>resampling</code>, <code>measures</code>,
<code>par.set</code>, <code>control</code>, <code>opt.path</code>, <code>dob</code>, <code>x</code>, <code>y</code>, <code>remove.nas</code>,
<code>stage</code> and <code>prev.stage</code> is expected.
The default displays the performance measures, the time needed for evaluating,
the currently used memory and the max memory ever used before
(the latter two both taken from gc).
See the implementation for details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>final.dw.perc</code></td>
<td>
<p>(<code>boolean</code>)<br>
If a Learner wrapped by a makeDownsampleWrapper is used, you can define the value of <code>dw.perc</code> which is used to train the Learner with the final parameter setting found by the tuning.
Default is <code>NULL</code> which will not change anything.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>budget</code></td>
<td>
<p>(<code>integer(1)</code>)<br>
Maximum budget for tuning. This value restricts the number of function
evaluations. The <code>budget</code> equals the number of iterations (<code>maxit</code>) performed by
the random search algorithm.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>(TuneControlRandom)
</p>


<h3>See Also</h3>

<p>Other tune: 
<code>TuneControl</code>,
<code>getNestedTuneResultsOptPathDf()</code>,
<code>getNestedTuneResultsX()</code>,
<code>getResamplingIndices()</code>,
<code>getTuneResult()</code>,
<code>makeModelMultiplexer()</code>,
<code>makeModelMultiplexerParamSet()</code>,
<code>makeTuneControlCMAES()</code>,
<code>makeTuneControlDesign()</code>,
<code>makeTuneControlGenSA()</code>,
<code>makeTuneControlGrid()</code>,
<code>makeTuneControlIrace()</code>,
<code>makeTuneControlMBO()</code>,
<code>makeTuneWrapper()</code>,
<code>tuneParams()</code>,
<code>tuneThreshold()</code>
</p>


</div>