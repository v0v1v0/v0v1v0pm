<div class="container">

<table style="width: 100%;"><tr>
<td>generateCalibrationData</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Generate classifier calibration data.</h2>

<h3>Description</h3>

<p>A calibrated classifier is one where the predicted probability of a class closely matches the
rate at which that class occurs, e.g. for data points which are assigned a predicted probability
of class A of .8, approximately 80 percent of such points should belong to class A if the classifier
is well calibrated. This is estimated empirically by grouping data points with similar predicted
probabilities for each class, and plotting the rate of each class within each bin against the
predicted probability bins.
</p>


<h3>Usage</h3>

<pre><code class="language-R">generateCalibrationData(obj, breaks = "Sturges", groups = NULL, task.id = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>obj</code></td>
<td>
<p>(list of Prediction | list of ResampleResult | BenchmarkResult)<br>
Single prediction object, list of them, single resample result, list of them, or a benchmark result.
In case of a list probably produced by different learners you want to compare, then
name the list with the names you want to see in the plots, probably
learner shortnames or ids.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>breaks</code></td>
<td>
<p>(<code>character(1)</code> | numeric)<br>
If <code>character(1)</code>, the algorithm to use in generating probability bins.
See hist for details.
If numeric, the cut points for the bins.
Default is “Sturges”.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>groups</code></td>
<td>
<p>(<code>integer(1)</code>)<br>
The number of bins to construct.
If specified, <code>breaks</code> is ignored.
Default is <code>NULL</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>task.id</code></td>
<td>
<p>(<code>character(1)</code>)<br>
Selected task in BenchmarkResult to do plots for, ignored otherwise.
Default is first task.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>CalibrationData. A list containing:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>proportion</code></td>
<td>
<p>data.frame with columns:
</p>

<ul>
<li> <p><code>Learner</code> Name of learner.
</p>
</li>
<li> <p><code>bin</code> Bins calculated according to the <code>breaks</code> or <code>groups</code> argument.
</p>
</li>
<li> <p><code>Class</code> Class labels (for binary classification only the positive class).
</p>
</li>
<li> <p><code>Proportion</code> Proportion of observations from class <code>Class</code> among all
observations with posterior probabilities of class <code>Class</code> within the
interval given in <code>bin</code>.
</p>
</li>
</ul>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>data.frame with columns:
</p>

<ul>
<li> <p><code>Learner</code> Name of learner.
</p>
</li>
<li> <p><code>truth</code> True class label.
</p>
</li>
<li> <p><code>Class</code> Class labels (for binary classification only the positive class).
</p>
</li>
<li> <p><code>Probability</code> Predicted posterior probability of <code>Class</code>.
</p>
</li>
<li> <p><code>bin</code> Bin corresponding to <code>Probability</code>.
</p>
</li>
</ul>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>task</code></td>
<td>
<p>(TaskDesc)<br>
Task description.</p>
</td>
</tr>
</table>
<h3>References</h3>

<p>Vuk, Miha, and Curk, Tomaz. “ROC Curve, Lift Chart, and Calibration Plot.” Metodoloski zvezki. Vol. 3. No. 1 (2006): 89-108.
</p>


<h3>See Also</h3>

<p>Other generate_plot_data: 
<code>generateCritDifferencesData()</code>,
<code>generateFeatureImportanceData()</code>,
<code>generateFilterValuesData()</code>,
<code>generateLearningCurveData()</code>,
<code>generatePartialDependenceData()</code>,
<code>generateThreshVsPerfData()</code>,
<code>plotFilterValues()</code>
</p>
<p>Other calibration: 
<code>plotCalibration()</code>
</p>


</div>