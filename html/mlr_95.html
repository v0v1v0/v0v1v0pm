<div class="container">

<table style="width: 100%;"><tr>
<td>generateCritDifferencesData</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Generate data for critical-differences plot.</h2>

<h3>Description</h3>

<p>Generates data that can be used to plot a
critical differences plot. Computes the critical differences according
to either the
<code>"Bonferroni-Dunn"</code> test or the <code>"Nemenyi"</code> test.<br><code>"Bonferroni-Dunn"</code> usually yields higher power as it does not
compare all algorithms to each other, but all algorithms to a
<code>baseline</code> instead. <br>
Learners are drawn on the y-axis according to their average rank. <br>
For <code>test = "nemenyi"</code> a bar is drawn, connecting all groups of not
significantly different learners.<br>
For <code>test = "bd"</code> an interval is drawn arround the algorithm selected
as a baseline. All learners within this interval are not signifcantly different
from the baseline. <br>
Calculation:
</p>
<p style="text-align: center;"><code class="reqn">CD = q_{\alpha} \sqrt{\left(\frac{k(k+1)}{6N}\right)}</code>
</p>
 <p><br>
Where <code class="reqn">q_\alpha</code> is based on the studentized range statistic.
See references for details.
</p>


<h3>Usage</h3>

<pre><code class="language-R">generateCritDifferencesData(
  bmr,
  measure = NULL,
  p.value = 0.05,
  baseline = NULL,
  test = "bd"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>bmr</code></td>
<td>
<p>(BenchmarkResult)<br>
Benchmark result.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>measure</code></td>
<td>
<p>(Measure)<br>
Performance measure.
Default is the first measure used in the benchmark experiment.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>p.value</code></td>
<td>
<p>(<code>numeric(1)</code>)<br>
P-value for the critical difference. Default: 0.05</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>baseline</code></td>
<td>
<p>(<code>character(1)</code>): (<code>learner.id</code>) <br>
Select a <code>learner.id</code> as baseline for the <code>test = "bd"</code>
("Bonferroni-Dunn") critical differences
diagram. The critical difference interval will then be positioned arround this learner.
Defaults to best performing algorithm. <br>
For <code>test = "nemenyi"</code>, no baseline is needed as it performs <em>all pairwise
comparisons</em>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>test</code></td>
<td>
<p>(<code>character(1)</code>) <br>
Test for which the critical differences are computed. <br>
“bd” for the Bonferroni-Dunn Test, which is comparing all
classifiers to a <code>baseline</code>, thus performing a comparison
of one classifier to all others. <br>
Algorithms not connected by a single line are statistically different
from the baseline. <br>
“nemenyi” for the PMCMRplus::frdAllPairsNemenyiTest
which is comparing all classifiers to each other. The null hypothesis that
there is a difference between the classifiers can not be rejected for all
classifiers that have a single grey bar connecting them.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>(<code>critDifferencesData</code>). List containing:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>(data.frame) containing the info for the descriptive
part of the plot</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>friedman.nemenyi.test</code></td>
<td>
<p>(list) of class <code>pairwise.htest</code> <br>
contains the calculated
PMCMRplus::frdAllPairsNemenyiTest</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cd.info</code></td>
<td>
<p>(list) containing info on the critical difference
and its positioning</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>baseline</code></td>
<td>
<p><code>baseline</code> chosen for plotting</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>p.value</code></td>
<td>
<p>p.value used for the PMCMRplus::frdAllPairsNemenyiTest
and for computation of the critical difference</p>
</td>
</tr>
</table>
<h3>See Also</h3>

<p>Other generate_plot_data: 
<code>generateCalibrationData()</code>,
<code>generateFeatureImportanceData()</code>,
<code>generateFilterValuesData()</code>,
<code>generateLearningCurveData()</code>,
<code>generatePartialDependenceData()</code>,
<code>generateThreshVsPerfData()</code>,
<code>plotFilterValues()</code>
</p>
<p>Other benchmark: 
<code>BenchmarkResult</code>,
<code>batchmark()</code>,
<code>benchmark()</code>,
<code>convertBMRToRankMatrix()</code>,
<code>friedmanPostHocTestBMR()</code>,
<code>friedmanTestBMR()</code>,
<code>getBMRAggrPerformances()</code>,
<code>getBMRFeatSelResults()</code>,
<code>getBMRFilteredFeatures()</code>,
<code>getBMRLearnerIds()</code>,
<code>getBMRLearnerShortNames()</code>,
<code>getBMRLearners()</code>,
<code>getBMRMeasureIds()</code>,
<code>getBMRMeasures()</code>,
<code>getBMRModels()</code>,
<code>getBMRPerformances()</code>,
<code>getBMRPredictions()</code>,
<code>getBMRTaskDescs()</code>,
<code>getBMRTaskIds()</code>,
<code>getBMRTuneResults()</code>,
<code>plotBMRBoxplots()</code>,
<code>plotBMRRanksAsBarChart()</code>,
<code>plotBMRSummary()</code>,
<code>plotCritDifferences()</code>,
<code>reduceBatchmarkResults()</code>
</p>


</div>