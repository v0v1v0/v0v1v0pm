<div class="container">

<table style="width: 100%;"><tr>
<td>generateFeatureImportanceData</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Generate feature importance.</h2>

<h3>Description</h3>

<p>Estimate how important individual features or groups of features are by contrasting prediction performances. For method “permutation.importance” compute the change in performance from permuting the values of a feature (or a group of features) and compare that to the predictions made on the unmcuted data.
</p>


<h3>Usage</h3>

<pre><code class="language-R">generateFeatureImportanceData(
  task,
  method = "permutation.importance",
  learner,
  features = getTaskFeatureNames(task),
  interaction = FALSE,
  measure,
  contrast = function(x, y) x - y,
  aggregation = mean,
  nmc = 50L,
  replace = TRUE,
  local = FALSE,
  show.info = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>task</code></td>
<td>
<p>(Task)<br>
The task.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p>(<code>character(1)</code>)<br>
The method used to compute the feature importance.
The only method available is “permutation.importance”.
Default is “permutation.importance”.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>learner</code></td>
<td>
<p>(Learner | <code>character(1)</code>)<br>
The learner.
If you pass a string the learner will be created via makeLearner.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>features</code></td>
<td>
<p>(character)<br>
The features to compute the importance of.
The default is all of the features contained in the Task.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>interaction</code></td>
<td>
<p>(<code>logical(1)</code>)<br>
Whether to compute the importance of the <code>features</code> argument jointly.
For <code>method = "permutation.importance"</code> this entails permuting the values of
all <code>features</code> together and then contrasting the performance with that of
the performance without the features being permuted.
The default is <code>FALSE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>measure</code></td>
<td>
<p>(Measure)<br>
Performance measure.
Default is the first measure used in the benchmark experiment.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>contrast</code></td>
<td>
<p>(<code>function</code>)<br>
A difference function that takes a numeric vector and returns a numeric vector
of the same length.
The default is element-wise difference between the vectors.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>aggregation</code></td>
<td>
<p>(<code>function</code>)<br>
A function which aggregates the differences.
This function must take a numeric vector and return a numeric vector of length 1.
The default is <code>mean</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nmc</code></td>
<td>
<p>(<code>integer(1)</code>)<br>
The number of Monte-Carlo iterations to use in computing the feature importance.
If <code>nmc == -1</code> and <code>method = "permutation.importance"</code> then all
permutations of the <code>features</code> are used.
The default is 50.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>replace</code></td>
<td>
<p>(<code>logical(1)</code>)<br>
Whether or not to sample the feature values with or without replacement.
The default is <code>TRUE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>local</code></td>
<td>
<p>(<code>logical(1)</code>)<br>
Whether to compute the per-observation importance.
The default is <code>FALSE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>show.info</code></td>
<td>
<p>(<code>logical(1)</code>)<br>
Whether progress output (feature name, time elapsed) should be displayed.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>(<code>FeatureImportance</code>). A named list which contains the computed feature importance and the input arguments.
</p>
<p>Object members:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>res</code></td>
<td>
<p>(data.frame)<br>
Has columns for each feature or combination of features (colon separated) for which the importance is computed.
A row coresponds to importance of the feature specified in the column for the target.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>interaction</code></td>
<td>
<p>(<code>logical(1)</code>)<br>
Whether or not the importance of the <code>features</code> was computed jointly rather than individually.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>measure</code></td>
<td>
<p>(Measure)</p>
</td>
</tr>
</table>
<p><br>
The measure used to compute performance.
</p>
<table>
<tr style="vertical-align: top;">
<td><code>contrast</code></td>
<td>
<p>(<code>function</code>)<br>
The function used to compare the performance of predictions.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>aggregation</code></td>
<td>
<p>(<code>function</code>)<br>
The function which is used to aggregate the contrast between the performance of predictions across Monte-Carlo iterations.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>replace</code></td>
<td>
<p>(<code>logical(1)</code>)<br>
Whether or not, when <code>method = "permutation.importance"</code>, the feature values
are sampled with replacement.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nmc</code></td>
<td>
<p>(<code>integer(1)</code>)<br>
The number of Monte-Carlo iterations used to compute the feature importance.
When <code>nmc == -1</code> and <code>method = "permutation.importance"</code> all permutations are used.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>local</code></td>
<td>
<p>(<code>logical(1)</code>)<br>
Whether observation-specific importance is computed for the <code>features</code>.
</p>
</td>
</tr>
</table>
<h3>References</h3>

<p>Jerome Friedman; Greedy Function Approximation: A Gradient Boosting Machine, Annals of Statistics, Vol. 29, No. 5 (Oct., 2001), pp. 1189-1232.
</p>


<h3>See Also</h3>

<p>Other generate_plot_data: 
<code>generateCalibrationData()</code>,
<code>generateCritDifferencesData()</code>,
<code>generateFilterValuesData()</code>,
<code>generateLearningCurveData()</code>,
<code>generatePartialDependenceData()</code>,
<code>generateThreshVsPerfData()</code>,
<code>plotFilterValues()</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">

lrn = makeLearner("classif.rpart", predict.type = "prob")
fit = train(lrn, iris.task)
imp = generateFeatureImportanceData(iris.task, "permutation.importance",
  lrn, "Petal.Width", nmc = 10L, local = TRUE)

</code></pre>


</div>