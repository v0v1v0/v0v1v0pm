<div class="container">

<table style="width: 100%;"><tr>
<td>roc_scores</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>ROC scores</h2>

<h3>Description</h3>

<p>This function provides a way to identify the worst predictions when measuring Area Under the ROC curve. Simply
put, the worst predictions are the ones with very low or high relative prediction scores (usually probabilities) 
which relate to the positive and negative samples respectively.
</p>


<h3>Usage</h3>

<pre><code class="language-R">roc_scores(preds, actuals)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>preds</code></td>
<td>
<p>vector of predictions (need not be in range [0-1] - only order matters)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>actuals</code></td>
<td>
<p>vector of actuals - either logical or vector of 1s and 0s</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>How it works
</p>

<ul>
<li>
<p>First the relative position (between 0 and 1) of each prediction is determined
</p>
</li>
<li>
<p>Next the mean of actuals is determined
</p>
</li>
<li>
<p>For samples whose position is on the correct side of the overall mean, 0 is given
</p>
</li>
<li>
<p>For samples whose position is on the wrong side of the overall mean, its distance from the mean is given
</p>
</li>
</ul>
<h3>Examples</h3>

<pre><code class="language-R">roc_scores(c(1,2,3,4), actuals=c(1,1,0,0))
roc_scores(c(0.1, 0.2, 0.3, 0.4), actuals=c(TRUE, FALSE, TRUE, FALSE))

</code></pre>


</div>