<div class="container">

<table style="width: 100%;"><tr>
<td>bayesInferSimple</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Perform simple (network) Bayesian inferencing and regression.</h2>

<h3>Description</h3>

<p>Uses simple Bayesian inference to determine the probability or relative
likelihood of a given value. This function can also regress to the most
likely value instead. Simple means that segmented data is used in a way
that is equal to how a Bayesian network works. For a finite set of labels,
this function needs to be called for each, to obtain the probability of
each label (or, for n-1 labels or until a label with &gt;.5 probability is
found). For obtaining the probability of a continuous value, this function
is useful for deciding between picking among a finite set of values. The
empirical CDF may be used to obtain an actual probability for a given
continuous value, otherwise, the empirical PDF is estimated and a relative
likelihood is returned. For regression, set <code>doRegress = TRUE</code> to
obtain the most likely value of the target feature, instead of obtaining
its relative likelihood.
</p>


<h3>Usage</h3>

<pre><code class="language-R">bayesInferSimple(
  df,
  features,
  targetCol,
  selectedFeatureNames = c(),
  retainMinValues = 1,
  doRegress = FALSE,
  doEcdf = FALSE,
  regressor = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>df</code></td>
<td>
<p>data.frame</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>features</code></td>
<td>
<p>data.frame with bayes-features. One of the features needs
to be the label-column.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>targetCol</code></td>
<td>
<p>string with the name of the feature that represents the
label.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>selectedFeatureNames</code></td>
<td>
<p>vector default <code>c()</code>. Vector of strings
that are the names of the features the to-predict label depends on. If an
empty vector is given, then all of the features are used (except for the
label). The order then depends on the features' order.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>retainMinValues</code></td>
<td>
<p>integer to require a minimum amount of data points
when segmenting the data feature by feature.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>doRegress</code></td>
<td>
<p>default FALSE a boolean to indicate whether to do a
regression instead of returning the relative likelihood of a continuous
feature. If the target feature is discrete and regression is requested,
will issue a warning.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>doEcdf</code></td>
<td>
<p>default FALSE a boolean to indicate whether to use the
empirical CDF to return a probability when inferencing a continuous
feature. If false, uses the empirical PDF to return the rel. likelihood.
This parameter does not have any effect when inferring discrete values
or when doing a regression.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>regressor</code></td>
<td>
<p>Function that is given the collected values for
regression and thus finally used to select a most likely value. Defaults
to the built-in estimator for the empirical PDF and returns its argmax.
However, any other function can be used, too, such as min, max, median,
average etc. You may also use this function to obtain the raw values
for further processing. This function is ignored if not doing regression.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>numeric probability (inferring discrete labels) or relative
likelihood (regression, inferring likelihood of continuous value) or most
likely value given the conditional features.
</p>


<h3>Author(s)</h3>

<p>Sebastian Hönel <a href="mailto:sebastian.honel@lnu.se">sebastian.honel@lnu.se</a>
</p>


<h3>References</h3>

<p>Scutari M (2010).
“Learning Bayesian Networks with the <span class="pkg">bnlearn</span> R
      Package.”
<em>Journal of Statistical Software</em>, <b>35</b>(3), 1–22.
doi: <a href="https://doi.org/10.18637/jss.v035.i03">10.18637/jss.v035.i03</a>.
</p>


<h3>Examples</h3>

<pre><code class="language-R">feat1 &lt;- mmb::createFeatureForBayes(
  name = "Petal.Length", value = mean(iris$Petal.Length))
feat2 &lt;- mmb::createFeatureForBayes(
  name = "Petal.Width", value = mean(iris$Petal.Width))
featT &lt;- mmb::createFeatureForBayes(
  name = "Species", iris[1,]$Species, isLabel = TRUE)

# Infer likelihood of featT's label:
feats &lt;- rbind(feat1, feat2, featT)
mmb::bayesInferSimple(df = iris, features = feats, targetCol = featT$name)

# Infer likelihood of feat1's value:
featT$isLabel = FALSE
feat1$isLabel = TRUE
# We do not bind featT this time:
feats &lt;- rbind(feat1, feat2)
mmb::bayesInferSimple(df = iris, features = feats, targetCol = feat1$name)
</code></pre>


</div>