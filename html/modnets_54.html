<div class="container">

<table style="width: 100%;"><tr>
<td>predictNet</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Calculate prediction error from network models</h2>

<h3>Description</h3>

<p>See the prediction error based on different statistics for either GGMs or
SURs. Also can compare and find the change values (such as R-squared change)
between two networks of the same size (i.e., with the same nodes).
</p>


<h3>Usage</h3>

<pre><code class="language-R">predictNet(object, data = NULL, all = FALSE, scale = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>object</code></td>
<td>
<p>Output from <code>fitNetwork</code> or <code>mlGVAR</code>.
If using output from <code>mlGVAR</code>, then one of the two networks
must be provided (i.e., either <code>fixedNets</code> or <code>betweenNet</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>The dataset used to fit the network model, or another network of
the same type and size to be compared with the network specified in the
first argument. If the prediction error for only one network is desired,
and the dataset is included as an element of the relevant object, then this
can be left as <code>NULL</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>all</code></td>
<td>
<p>if <code>TRUE</code> then returns a list containing the observed
outcomes used to fit the models, their predicted values, and the prediction
error for each outcome.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>scale</code></td>
<td>
<p>Logical; determines whether or not to standardize the data
before computing prediction error. This argument will be removed.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>A table showing different measures of prediction error associated
with each node of the network. Or, if two networks are provided, a table
that shows the difference in prediction error for each node across the two
networks. Specifically, this is computed by taking the statistics for
<code>data</code> and subtracting them from those for <code>object</code>.
</p>
<p>If <code>all = TRUE</code>, then the following output is returned: </p>

<dl>
<dt>Y</dt>
<dd>
<p>The observed values of the outcome variables based on the data
provided.</p>
</dd> <dt>preds</dt>
<dd>
<p>The predicted values of the outcomes based on the
models provided.</p>
</dd> <dt>errors</dt>
<dd>
<p>Table containing prediction error
statistics for each node.</p>
</dd> </dl>
<h3>See Also</h3>

<p><code>fitNetwork</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">fit1 &lt;- fitNetwork(ggmDat, covariates = 'M')
fit2 &lt;- fitNetwork(ggmDat, moderators = 'M')

predictNet(fit1)
predictNet(fit1, all = TRUE)

predictNet(fit2, fit1) # Find the differences in prediction error across the two models
</code></pre>


</div>