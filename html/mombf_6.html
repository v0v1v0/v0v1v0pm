<div class="container">

<table style="width: 100%;"><tr>
<td>bestBIC</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Model with best AIC, BIC, EBIC or other general information criteria (getIC)
</h2>

<h3>Description</h3>

<p>Search for the regression model attaining the best value of the
specified information criterion
</p>


<h3>Usage</h3>

<pre><code class="language-R">  bestAIC(...)

  bestBIC(...)

  bestEBIC(...)

  bestIC(..., penalty)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Arguments passed on to <code>modelSelection</code>. The first and
main argument is a model formula, see the examples</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>penalty</code></td>
<td>
<p>General information penalty. For example, since the AIC
penalty is 2, bestIC(...,penalty=2) is the same as bestAIC(...)</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>For details on the information criteria see help(getBIC).
</p>
<p>Function modelSelection returns the log posterior probability of a
model, postProb = log(m_k) + log(prior k), where m_k is the marginal
likelihood of the model and prior k its prior probability.
</p>
<p>When running function modelSelection with priorCoef=bicprior()
and priorDelta=modelunifprior(), the BIC approximation is used for
m_k, that is
</p>
<p>log(m_k) = L_k - 0.5 * p_k log(n)
</p>
<p>and all models are equally likely a priori, log(prior k)= p
log(1/2). Then the BIC can be easily recovered
</p>
<p>BIC_k= -2 * [postProb + p log(2)]
</p>
<p>When using priorCoef=bicprior() and priorDelta=modelbbprior(),
log(prior k)= - log(p+1) - log(p choose p_k), hence
</p>
<p>EBIC_k= -2 * [postProb + log(p+1)].
</p>


<h3>Value</h3>

<p>Object of class <code>icfit</code>. Use (coef, summary,
confint, predict) to get inference for the top model,
and <code>help(icfit-class)</code> for more details on the returned object.
</p>


<h3>Author(s)</h3>

<p>David Rossell
</p>


<h3>See Also</h3>

<p><code>modelSelection</code> to perform model selection
</p>


<h3>Examples</h3>

<pre><code class="language-R">x &lt;- matrix(rnorm(100*3),nrow=100,ncol=3)
theta &lt;- matrix(c(1,1,0),ncol=1)
y &lt;- x %*% theta + rnorm(100)
ybin &lt;- y&gt;0

#BIC for all models (the intercept is also selected in/out)
fit= bestBIC(y ~ x[,1] + x[,2])
fit

#Same, but setting the BIC's log(n) penalty manually
#change the penalty for other General Info Criteria
#n= nrow(x)
#fit= bestIC(y ~ x[,1] + x[,2], penalty=log(n))

summary(fit) #usual GLM summary

coef(fit) #MLE under top model

#confint(fit) #conf int under top model (requires MASS package)



</code></pre>


</div>