<div class="container">

<table style="width: 100%;"><tr>
<td>.mp_tokenize_word</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Tokenize a Word</h2>

<h3>Description</h3>

<p>Tokenize a single "word" (no whitespace). The word can technically contain
punctuation, but typically punctuation has been split off by this point.
</p>


<h3>Usage</h3>

<pre><code class="language-R">.mp_tokenize_word(
  word,
  vocab_split,
  dir = 1,
  allow_compounds = TRUE,
  unk_token = "[UNK]",
  max_chars = 100
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>word</code></td>
<td>
<p>Word to tokenize.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>vocab_split</code></td>
<td>
<p>List of character vectors containing vocabulary words.
Should have components named "prefixes", "words", "suffixes".</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>dir</code></td>
<td>
<p>Integer; if 1 (the default), look for tokens starting at the
beginning of the word. Otherwise, start at the end.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>allow_compounds</code></td>
<td>
<p>Logical; whether to allow multiple whole words in the
breakdown.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>unk_token</code></td>
<td>
<p>Token to represent unknown words.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>max_chars</code></td>
<td>
<p>Maximum length of word recognized.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>This is an adaptation of wordpiece:::.tokenize_word. The main differences are
that it was designed to work with a morphemepiece vocabulary, which can
include prefixes (denoted like "pre##"). As in wordpiece, the algorithm uses
a repeated greedy search for the largest piece from the vocabulary found
within the word, but starting from either the beginning or the end of the
word (controlled by the <code>dir</code> parameter). The input vocabulary must be split
into prefixes, suffixes, and "words".
</p>


<h3>Value</h3>

<p>Input word as a list of tokens.
</p>


</div>