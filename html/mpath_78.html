<div class="container">

<table style="width: 100%;"><tr>
<td>irsvm_fit</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Fit iteratively reweighted support vector machines for robust loss functions</h2>

<h3>Description</h3>

<p><code>irsvm_fit</code> is used to train a subject weighted support vector machine where the weights are provided iteratively from robust loss function with the iteratively reweighted convex optimization (IRCO). It can be used to carry out robust regression and binary classification. This does computing for the wrapper function <code>irsvm</code>.
</p>


<h3>Usage</h3>

<pre><code class="language-R">irsvm_fit(x, y, weights, cfun="ccave", s=NULL, delta=0.0001, type = NULL, 
          kernel="radial", cost=1, epsilon = 0.1, iter=10, reltol=1e-5, 
          trace=FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>a data matrix, a vector, or a sparse '<em>design</em> matrix' (object of class
<code>Matrix</code> provided by the <span class="pkg">Matrix</span> package,
or of class <code>matrix.csr</code>
provided by the <span class="pkg">SparseM</span> package, or of class
<code>simple_triplet_matrix</code> provided by the <span class="pkg">slam</span>
package).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>a response vector with one label for each row/component of
<code>x</code>. Can be either a factor (for classification tasks)
or a numeric vector (for regression).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>weights</code></td>
<td>
<p>the weight of each subject. It should be in the same length of <code>y</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cfun</code></td>
<td>
<p> character, type of convex cap (concave) function.<br>
Valid options are:
</p>

<ul>
<li> <p><code>"hcave"</code>
</p>
</li>
<li> <p><code>"acave"</code>
</p>
</li>
<li> <p><code>"bcave"</code>
</p>
</li>
<li> <p><code>"ccave"</code>
</p>
</li>
<li> <p><code>"dcave"</code>
</p>
</li>
<li> <p><code>"ecave"</code>
</p>
</li>
<li> <p><code>"gcave"</code>
</p>
</li>
<li> <p><code>"tcave"</code>
</p>
</li>
</ul>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>s</code></td>
<td>
<p> tuning parameter of <code>cfun</code>. <code>s &gt; 0</code> and can be equal    to  0 for <code>cfun="tcave"</code>. If <code>s</code> is too close to 0 for <code>cfun="acave", "bcave", "ccave"</code>, the calculated weights can become 0 for all observations, thus crash the program.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>delta</code></td>
<td>
<p>a small positive number provided by user only if                 <code>cfun="gcave"</code> and <code>0 &lt; s &lt;1</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>type</code></td>
<td>
<p><code>irsvm_fit</code> can be used as a classification
machine, or as a regression machine.
Depending of whether <code>y</code> is
a factor or not, the default setting for <code>type</code> is <code>C-classification</code> or <code>eps-regression</code>, respectively, but may be overwritten by setting an explicit value.<br>
Valid options are:
</p>

<ul>
<li> <p><code>C-classification</code>
</p>
</li>
<li> <p><code>nu-classification</code>
</p>
</li>
<li> <p><code>eps-regression</code>
</p>
</li>
<li> <p><code>nu-regression</code>
</p>
</li>
</ul>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>kernel</code></td>
<td>
<p>the kernel used in training and predicting. You
might consider changing some of the following parameters, depending
on the kernel type.<br></p>

<dl>
<dt>linear:</dt>
<dd>
<p><code class="reqn">u'v</code></p>
</dd>
<dt>polynomial:</dt>
<dd>
<p><code class="reqn">(\gamma u'v + coef0)^{degree}</code></p>
</dd>
<dt>radial basis:</dt>
<dd>
<p><code class="reqn">e^(-\gamma |u-v|^2)</code></p>
</dd>
<dt>sigmoid:</dt>
<dd>
<p><code class="reqn">tanh(\gamma u'v + coef0)</code></p>
</dd>
</dl>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cost</code></td>
<td>
<p>cost of constraints violation (default: 1)—it is the
‘C’-constant of the regularization term in the Lagrange formulation. This is proportional to the inverse of <code>lambda</code> in <code>irglmreg</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>epsilon</code></td>
<td>
<p>epsilon in the insensitive-loss function (default: 0.1)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>iter</code></td>
<td>
<p>number of iteration in the IRCO algorithm</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>reltol</code></td>
<td>
<p>convergency criteria in the IRCO algorithm</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>trace</code></td>
<td>
<p>If <code>TRUE</code>, fitting progress is reported</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>additional parameters for function <code>wsvm</code> in package <span class="pkg">WeightSVM</span></p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>A case weighted SVM is fit by the IRCO algorithm, where the loss function is a composite function of <code>cfun</code>o<code>type</code>, plus a <code class="reqn">L\_2</code> penalty.
Additional arguments include <code>degree, gamma, coef0</code>, 
<code>class.weights, cachesize, tolerance, shrinking, propbability, fitted</code>, the same as <code>"wsvm"</code> in package <span class="pkg">WeightSVM</span>.
</p>


<h3>Value</h3>

<p>An object of class <code>"wsvm"</code> (see package <span class="pkg">WeightSVM</span>) containing the fitted model, including:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>SV</code></td>
<td>
<p>The resulting support vectors (possibly scaled).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>index</code></td>
<td>
<p>The index of the resulting support vectors in the data
matrix. Note that this index refers to the preprocessed data (after
the possible effect of <code>na.omit</code> and <code>subset</code>)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>coefs</code></td>
<td>
<p>The corresponding coefficients times the training labels.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>rho</code></td>
<td>
<p>The negative intercept.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sigma</code></td>
<td>
<p>In case of a probabilistic regression model, the scale
parameter of the hypothesized (zero-mean) laplace distribution estimated by
maximum likelihood.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>probA, probB</code></td>
<td>
<p>numeric vectors of length 2, number of
classes, containing the parameters of the logistic distributions fitted to
the decision values of the binary classifiers (1 / (1 + exp(a x + b))).</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Zhu Wang <a href="mailto:zwang145@uthsc.edu">zwang145@uthsc.edu</a>
</p>


<h3>References</h3>

<p>Zhu Wang (2024)
<em>Unified Robust Estimation</em>, <em>Australian &amp; New Zealand Journal of Statistics</em>. 66(1):77-102.
</p>


<h3>See Also</h3>

<p><code>irsvm</code>, <code>print</code>, <code>predict</code>, <code>coef</code> and     <code>plot</code>.</p>


<h3>Examples</h3>

<pre><code class="language-R">data(iris)
 iris &lt;- subset(iris, Species %in% c("setosa", "versicolor"))
 # default with factor response:
  model &lt;- irsvm(Species ~ ., data = iris, kernel="linear", trace=TRUE)
  model &lt;- irsvm(Species ~ ., data = iris)
 # alternatively the traditional interface:
  x &lt;- subset(iris, select = -Species)
  y &lt;- iris$Species
model &lt;- irsvm(x, y)
  # test with train data
  pred &lt;- predict(model, x)
  # (same as:)
  pred &lt;- fitted(model)
 
  # Check accuracy:
  table(pred, y)
 # compute decision values and probabilities:
  pred &lt;- predict(model, x, decision.values = TRUE)
  attr(pred, "decision.values")
 
  # visualize (classes by color, SV by crosses):
  plot(cmdscale(dist(iris[,-5])),
       col = as.integer(iris[,5]),
       pch = c("o","+")[1:100 %in% model$index + 1])
 
  ## try regression mode on two dimensions
 
  # create data
  x &lt;- seq(0.1, 5, by = 0.05)
  y &lt;- log(x) + rnorm(x, sd = 0.2)
 
  # estimate model and predict input values
  m   &lt;- irsvm(x, y)
  new &lt;- predict(m, x)
 
  # visualize
 plot(x, y)
  points(x, log(x), col = 2)
  points(x, new, col = 4) 
</code></pre>


</div>