<div class="container">

<table style="width: 100%;"><tr>
<td>msaenet</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Multi-Step Adaptive Elastic-Net</h2>

<h3>Description</h3>

<p>Multi-Step Adaptive Elastic-Net
</p>


<h3>Usage</h3>

<pre><code class="language-R">msaenet(
  x,
  y,
  family = c("gaussian", "binomial", "poisson", "cox"),
  init = c("enet", "ridge"),
  alphas = seq(0.05, 0.95, 0.05),
  tune = c("cv", "ebic", "bic", "aic"),
  nfolds = 5L,
  rule = c("lambda.min", "lambda.1se"),
  ebic.gamma = 1,
  nsteps = 2L,
  tune.nsteps = c("max", "ebic", "bic", "aic"),
  ebic.gamma.nsteps = 1,
  scale = 1,
  lower.limits = -Inf,
  upper.limits = Inf,
  penalty.factor.init = rep(1, ncol(x)),
  seed = 1001,
  parallel = FALSE,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>Data matrix.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>Response vector if <code>family</code> is <code>"gaussian"</code>,
<code>"binomial"</code>, or <code>"poisson"</code>. If <code>family</code> is
<code>"cox"</code>, a response matrix created by <code>Surv</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>family</code></td>
<td>
<p>Model family, can be <code>"gaussian"</code>,
<code>"binomial"</code>, <code>"poisson"</code>, or <code>"cox"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>init</code></td>
<td>
<p>Type of the penalty used in the initial
estimation step. Can be <code>"enet"</code> or <code>"ridge"</code>.
See <code>glmnet</code> for details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alphas</code></td>
<td>
<p>Vector of candidate <code>alpha</code>s to use in
<code>cv.glmnet</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tune</code></td>
<td>
<p>Parameter tuning method for each estimation step.
Possible options are <code>"cv"</code>, <code>"ebic"</code>, <code>"bic"</code>,
and <code>"aic"</code>. Default is <code>"cv"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nfolds</code></td>
<td>
<p>Fold numbers of cross-validation when <code>tune = "cv"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>rule</code></td>
<td>
<p>Lambda selection criterion when <code>tune = "cv"</code>,
can be <code>"lambda.min"</code> or <code>"lambda.1se"</code>.
See <code>cv.glmnet</code> for details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ebic.gamma</code></td>
<td>
<p>Parameter for Extended BIC penalizing
size of the model space when <code>tune = "ebic"</code>,
default is <code>1</code>. For details, see Chen and Chen (2008).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nsteps</code></td>
<td>
<p>Maximum number of adaptive estimation steps.
At least <code>2</code>, assuming adaptive elastic-net has only
one adaptive estimation step.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tune.nsteps</code></td>
<td>
<p>Optimal step number selection method
(aggregate the optimal model from the each step and compare).
Options include <code>"max"</code> (select the final-step model directly),
or compare these models using <code>"ebic"</code>, <code>"bic"</code>, or <code>"aic"</code>.
Default is <code>"max"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ebic.gamma.nsteps</code></td>
<td>
<p>Parameter for Extended BIC penalizing
size of the model space when <code>tune.nsteps = "ebic"</code>,
default is <code>1</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>scale</code></td>
<td>
<p>Scaling factor for adaptive weights:
<code>weights = coefficients^(-scale)</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lower.limits</code></td>
<td>
<p>Lower limits for coefficients.
Default is <code>-Inf</code>. For details, see <code>glmnet</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>upper.limits</code></td>
<td>
<p>Upper limits for coefficients.
Default is <code>Inf</code>. For details, see <code>glmnet</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>penalty.factor.init</code></td>
<td>
<p>The multiplicative factor for the penalty
applied to each coefficient in the initial estimation step. This is
useful for incorporating prior information about variable weights,
for example, emphasizing specific clinical variables. To make certain
variables more likely to be selected, assign a smaller value.
Default is <code>rep(1, ncol(x))</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>seed</code></td>
<td>
<p>Random seed for cross-validation fold division.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>parallel</code></td>
<td>
<p>Logical. Enable parallel parameter tuning or not,
default is <code>FALSE</code>. To enable parallel tuning, load the
<code>doParallel</code> package and run <code>registerDoParallel()</code>
with the number of CPU cores before calling this function.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>
<p>Should we print out the estimation progress?</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>List of model coefficients, <code>glmnet</code> model object,
and the optimal parameter set.
</p>


<h3>Author(s)</h3>

<p>Nan Xiao &lt;<a href="https://nanx.me">https://nanx.me</a>&gt;
</p>


<h3>References</h3>

<p>Nan Xiao and Qing-Song Xu. (2015). Multi-step adaptive elastic-net:
reducing false positives in high-dimensional variable selection.
<em>Journal of Statistical Computation and Simulation</em> 85(18), 3755â€“3765.
</p>


<h3>Examples</h3>

<pre><code class="language-R">dat &lt;- msaenet.sim.gaussian(
  n = 150, p = 500, rho = 0.6,
  coef = rep(1, 5), snr = 2, p.train = 0.7,
  seed = 1001
)

msaenet.fit &lt;- msaenet(
  dat$x.tr, dat$y.tr,
  alphas = seq(0.2, 0.8, 0.2),
  nsteps = 3L, seed = 1003
)

print(msaenet.fit)
msaenet.nzv(msaenet.fit)
msaenet.fp(msaenet.fit, 1:5)
msaenet.tp(msaenet.fit, 1:5)
msaenet.pred &lt;- predict(msaenet.fit, dat$x.te)
msaenet.rmse(dat$y.te, msaenet.pred)
plot(msaenet.fit)
</code></pre>


</div>