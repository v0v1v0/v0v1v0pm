<div class="container">

<table style="width: 100%;"><tr>
<td>information_gain</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Estimating information gain between two categorical variables.</h2>

<h3>Description</h3>

<p>Information gain (also called mutual information) is a measure of
the mutual dependence between two variables (see
<a href="https://en.wikipedia.org/wiki/Mutual_information">https://en.wikipedia.org/wiki/Mutual_information</a>).
</p>


<h3>Usage</h3>

<pre><code class="language-R">information_gain(x, y)

IG(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>A factor representing a categorical variable.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>A factor representing a categorical variable.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>Information gain estimation based on Sannon entropy for
variables <code>x</code> and <code>y</code>.
</p>


<h3>Examples</h3>

<pre><code class="language-R">information_gain(factor(c(0,1)), factor(c(1,0)))
information_gain(factor(c(0,0,1,1)), factor(c(0,1,1,1)))
information_gain(factor(c(0,0,1,1)), factor(c(0,1,0,1)))
## Not run: 
information_gain(c(0,1), c(1,0))

## End(Not run)
</code></pre>


</div>