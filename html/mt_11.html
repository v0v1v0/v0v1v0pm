<div class="container">

<table style="width: 100%;"><tr>
<td>cl.rate</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Assess Classification Performances
</h2>

<h3>Description</h3>

<p>Assess classification performances.
</p>


<h3>Usage</h3>

<pre><code class="language-R">  cl.rate(obs, pre)
  cl.perf(obs, pre, pos=levels(as.factor(obs))[2])
  cl.roc(stat, label, pos=levels(as.factor(label))[2], plot=TRUE, ...)
  cl.auc(stat, label, pos=levels(as.factor(label))[2])
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>obs</code></td>
<td>

<p>Factor or vector of observed class.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pre</code></td>
<td>

<p>Factor or vector of predicted class.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>stat</code></td>
<td>

<p>Factor or vector of statistics for positives/cases. 
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>label</code></td>
<td>

<p>Factor or vector of label for categorical data.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pos</code></td>
<td>

<p>Characteristic string for positive.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>plot</code></td>
<td>

<p>Logical flag indicating whether ROC should be plotted.  
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p> Further arguments for plotting.  </p>
</td>
</tr>
</table>
<h3>Details</h3>

<p><code>cl.perf</code> gets the classification performances such as accuracy rate and 
false positive rate. <code>cl.roc</code> computes receiver operating characteristics 
(ROC).  <code>cl.auc</code> calculates area under ROC curve. Three functions are only 
for binary class problems.  
</p>


<h3>Value</h3>

<p><code>cl.rate</code> returns a list with components:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>acc</code></td>
<td>
<p> Accuracy rate of classification.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>err</code></td>
<td>
<p> Error rate of classification.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>con.mat</code></td>
<td>
<p> Confusion matrix. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>kappa</code></td>
<td>
<p> Kappa Statistics.</p>
</td>
</tr>
</table>
<p><code>cl.perf</code> returns a list with components:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>acc</code></td>
<td>
<p> Accuracy rate</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tpr</code></td>
<td>
<p> True positive rate</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fpr</code></td>
<td>
<p> False positive rate</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sens</code></td>
<td>
<p> Sensitivity</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>spec</code></td>
<td>
<p> Specificity</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>con.mat</code></td>
<td>
<p> Confusion matrix. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>kappa</code></td>
<td>
<p> Kappa Statistics.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>positive</code></td>
<td>
<p> Positive level.</p>
</td>
</tr>
</table>
<p><code>cl.roc</code> returns a list with components:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>perf</code></td>
<td>
<p>A data frame of <code>acc</code>, <code>tpr</code>,<code>fpr</code>,<code>sens</code>,
<code>spec</code> and <code>cutoff</code> (thresholds).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>auc</code></td>
<td>
<p> Area under ROC curve</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>positive</code></td>
<td>
<p> Positive level.</p>
</td>
</tr>
</table>
<p><code>cl.auc</code> returns a scalar value of AUC.
</p>


<h3>Note</h3>

<p>AUC varies between 0.5 and 1.0 for sensible models; the higher the better. If 
it is less than 0.5, it should be corrected by <code>1 - AUC</code>. Or re-run it by 
using <code>1 - stat</code>. 
</p>


<h3>Author(s)</h3>

<p>Wanchang Lin 
</p>


<h3>References</h3>

<p>Fawcett, F. (2006) <em>An introduction to ROC analysis</em>. 
<em>Pattern Recognition Letters</em>.  vol. 27, 861-874.
</p>


<h3>Examples</h3>

<pre><code class="language-R">
## Measurements of Forensic Glass Fragments
library(MASS)
data(fgl, package = "MASS")    # in MASS package
dat &lt;- subset(fgl, grepl("WinF|WinNF",type))
## dat &lt;- subset(fgl, type %in% c("WinF", "WinNF"))
x   &lt;- subset(dat, select = -type)
y   &lt;- factor(dat$type)

## construct train and test data 
idx   &lt;- sample(1:nrow(x), round((2/3)*nrow(x)), replace = FALSE) 
tr.x  &lt;- x[idx,]
tr.y  &lt;- y[idx]
te.x  &lt;- x[-idx,]        
te.y  &lt;- y[-idx] 

model &lt;- lda(tr.x, tr.y)

## predict the test data results
pred  &lt;- predict(model, te.x)

## classification performances
obs &lt;- te.y
pre &lt;- pred$class   
cl.rate(obs, pre)
cl.perf(obs, pre, pos="WinNF")
## change positive as "WinF"
cl.perf(obs, pre, pos="WinF")

## ROC and AUC
pos  &lt;- "WinNF"            ## or "WinF"
stat &lt;- pred$posterior[,pos]
## levels(obs) &lt;- c(0,1)

cl.auc (stat,obs, pos=pos)
cl.roc (stat,obs, pos=pos)

## test examples for ROC and AUC
label &lt;- rbinom(30,size=1,prob=0.2)
stat  &lt;- rnorm(30)
cl.roc(stat,label, pos=levels(factor(label))[2],plot = TRUE)
cl.auc(stat,label,pos=levels(factor(label))[2])

## if auc is less than 0.5, it should be adjusted by 1 - auc. 
## Or re-run them:
cl.roc(1 - stat,label, pos=levels(factor(label))[2],plot = TRUE)
cl.auc(1 - stat,label,pos=levels(factor(label))[2])

</code></pre>


</div>