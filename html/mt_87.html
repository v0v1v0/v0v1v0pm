<div class="container">

<table style="width: 100%;"><tr>
<td>pcalda</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Classification with PCADA
</h2>

<h3>Description</h3>

<p>Classification with combination of principal component analysis (PCA) and linear discriminant 
analysis (LDA).
</p>


<h3>Usage</h3>

<pre><code class="language-R">pcalda(x, ...)

## Default S3 method:
pcalda(x, y, center = TRUE, scale. = FALSE, ncomp = NULL,
       tune=FALSE,...)

## S3 method for class 'formula'
pcalda(formula, data = NULL, ..., subset, na.action = na.omit)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>formula</code></td>
<td>

<p>A formula of the form <code>groups ~ x1 + x2 + ...</code>  That is, the
response is the grouping factor and the right hand side specifies
the (non-factor) discriminators.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>

<p>Data frame from which variables specified in <code>formula</code> are
preferentially to be taken.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>

<p>A matrix or data frame containing the explanatory variables if no formula is
given as the principal argument.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>

<p>A factor specifying the class for each observation if no formula principal 
argument is given.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>center</code></td>
<td>

<p>A logical value indicating whether <code>x</code> should be shifted to zero 
centred by column-wise.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>scale.</code></td>
<td>

<p>A logical value indicating whether <code>x</code> should be scaled to have unit 
variance by column-wise before the analysis takes place. 
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ncomp</code></td>
<td>

<p>The number of principal components to be used in the classification. If
<code>NULL</code> and <code>tune=TRUE</code>, it is the row number of <code>x</code> minus the 
number of class indicating in <code>y</code>. If <code>NULL</code> and <code>tune=FALSE</code>, 
it is the half of row number of <code>x</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tune</code></td>
<td>

<p>A logical value indicating whether the best number of components should be tuned.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>

<p>Arguments passed to or from other methods.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>subset</code></td>
<td>

<p>An index vector specifying the cases to be used in the training
sample.  
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>na.action</code></td>
<td>

<p>A function to specify the action to be taken if <code>NA</code>s are found. The 
default action is <code>na.omit</code>, which leads to rejection of cases with 
missing values on any required variable. An alternative is <code>na.fail</code>, 
which causes an error if <code>NA</code> cases are found. 
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>A critical issue of applying linear discriminant analysis (LDA) is both the
singularity and instability of the within-class scatter matrix. In practice, 
there are often a large number of features available, but the total number of 
training patterns is limited and commonly less than the dimension of the feature 
space. To tackle this issue, <code>pcalda</code> combines PCA and LDA for 
classification. It uses PCA for dimension reduction. The rotated data resulted 
from PCA will be the input variable to LDA for classification. 
</p>


<h3>Value</h3>

<p>An object of class <code>pcalda</code> containing the following components:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>

<p>The rotated data on discriminant variables.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cl</code></td>
<td>

<p>The observed class labels of training data. 
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pred</code></td>
<td>

<p>The predicted class labels of training data. 
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>posterior</code></td>
<td>

<p>The posterior probabilities for the predicted classes. 
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>conf</code></td>
<td>

<p>The confusion matrix based on training data. 
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>acc</code></td>
<td>

<p>The accuracy rate of training data. 
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ncomp</code></td>
<td>

<p>The number of principal components used for classification. 
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pca.out</code></td>
<td>

<p>The output of PCA.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lda.out</code></td>
<td>

<p>The output of LDA.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>call</code></td>
<td>

<p>The (matched) function call.
</p>
</td>
</tr>
</table>
<h3>Note</h3>

<p>This function may be called giving either a formula and
optional data frame, or a matrix and grouping factor as the first
two arguments. 
</p>


<h3>Author(s)</h3>

<p>Wanchang Lin 
</p>


<h3>See Also</h3>

<p><code>predict.pcalda</code>, <code>plot.pcalda</code>, <code>tune.func</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">data(abr1)
cl   &lt;- factor(abr1$fact$class)
dat  &lt;- abr1$pos

## divide data as training and test data
idx &lt;- sample(1:nrow(dat), round((2/3)*nrow(dat)), replace=FALSE) 

## construct train and test data 
train.dat  &lt;- dat[idx,]
train.t    &lt;- cl[idx]
test.dat   &lt;- dat[-idx,]        
test.t     &lt;- cl[-idx] 

## apply pcalda
model    &lt;- pcalda(train.dat,train.t)
model
summary(model)

## plot
plot(model,dimen=c(1,2),main = "Training data",abbrev = TRUE)
plot(model,main = "Training data",abbrev = TRUE)

## confusion matrix
pred.te  &lt;- predict(model, test.dat)$class
table(test.t,pred.te)

</code></pre>


</div>