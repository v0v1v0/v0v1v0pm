<div class="container">

<table style="width: 100%;"><tr>
<td>RdetR</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Correlation matrix and it's determinat</h2>

<h3>Description</h3>

<p>The function returns the matrix of simple linear correlations between the independent variables of a multiple linear model and its determinant.  
</p>


<h3>Usage</h3>

<pre><code class="language-R">RdetR(X, dummy = FALSE, pos = NULL)</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>A numeric design matrix that should contain more than one regressor (intercept included).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>dummy</code></td>
<td>
<p>A logical value that indicates if there are dummy variables in the design matrix <code>X</code>. By default <code>dummy=FALSE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pos</code></td>
<td>
<p>A numeric vector that indicates the position of the dummy variables, if these exist, in the design matrix <code>X</code>. By default <code>pos=NULL</code>.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The measures calculated by this function ignore completelly the role of the intercept in the linear relations between the independent variables. Thus, these measures only detect the near essential multicollinearity. Although the simple correlations only quantify relation between pairs of variables, the determinant of the matrix of correlations is able to detect broader relations.  Due to the coefficients of simple linear regression are calculated for quantitative variables, if the model contains other kinds of variables (such as dummy variables), they should be omitted in the analysis by using the arguments <code>dummy</code> and <code>pos</code>.
</p>


<h3>Value</h3>

<table>
<tr style="vertical-align: top;">
<td><code>R</code></td>
<td>
<p>Correlation matrix of the independent variables of the multiple linear regression model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>detR</code></td>
<td>
<p>Determinant of <code>R</code>.</p>
</td>
</tr>
</table>
<h3>Note</h3>

<p>Values of the coefficient of simple linear correlation higher than 0.9487 imply worrying near essential multicollinearity between pairs of variables. 
</p>
<p>Values of the determinant of <code>R</code> lower than  <code>0.1013 + 0.00008626*n - 0.01384*k</code>, where <code>n</code> is the number of observations and <code>k</code> the number of indepedent variables (intercept included), indicate worrying near essential multicollinearity.
</p>


<h3>Author(s)</h3>

<p>R. Salmerón (<a href="mailto:romansg@ugr.es">romansg@ugr.es</a>) and C. García (<a href="mailto:cbgarcia@ugr.es">cbgarcia@ugr.es</a>).</p>


<h3>References</h3>

<p>C. García, R. Salmerón and C. B. García (2019). Choice of the ridge factor from the correlation matrix determinant. Journal of Statistical Computation and Simulation, 89 (2), 211-231.
</p>
<p>D. Marquardt and R. Snee (1975). Ridge regression in practice. The American Statistician, 1 (29), 3–20.
</p>
<p>L. R. Klein and A.S. Goldberger (1964). An economic model of the United States, 1929-1952. North Holland Publishing Company, Amsterdan.
</p>
<p>H. Theil (1971). Principles of Econometrics. John Wiley &amp; Sons, New York.
</p>


<h3>See Also</h3>

<p><code>VIF</code>.</p>


<h3>Examples</h3>

<pre><code class="language-R"># Henri Theil's textile consumption data modified
data(theil)
head(theil)
cte = array(1,length(theil[,2]))
theil.X = cbind(cte,theil[,-(1:2)])
RdetR(theil.X, TRUE, pos = 4)

# Klein and Goldberger data on consumption and wage income
data(KG)
head(KG)
cte = array(1,length(KG[,1]))
KG.X = cbind(cte,KG[,-1])
RdetR(KG.X)
</code></pre>


</div>