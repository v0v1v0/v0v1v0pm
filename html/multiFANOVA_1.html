<div class="container">

<table style="width: 100%;"><tr>
<td>multiFANOVA</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Multiple contrast tests for functional data</h2>

<h3>Description</h3>

<p>The function <code>multiFANOVA()</code> calculates the globalizing pointwise Hotelling's <code class="reqn">T^2</code>-test
(GPH) statistic for the global null hypothesis and multiple local null hypotheses.
Respective <code class="reqn">p</code>-values are obtained by a parametric bootstrap strategy.
</p>


<h3>Usage</h3>

<pre><code class="language-R">multiFANOVA(
  x,
  gr_label,
  h,
  n_boot = 1000,
  alpha = 0.05,
  parallel = FALSE,
  n_cores = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>matrix of observations <code class="reqn">n\times j</code> (<code class="reqn">n = n_1 + ... + n_k</code>, <code class="reqn">j</code> is a number of design time points).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>gr_label</code></td>
<td>
<p>a vector with group labels; the integer labels (from 1 to a number of groups) should be used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>h</code></td>
<td>
<p>contrast matrix. For Dunnett’s and Tukey’s contrasts, it can be created by
the <code>contr_mat()</code> function from the package <code>GFDmcv</code> (see examples).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n_boot</code></td>
<td>
<p>number of bootstrap samples.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alpha</code></td>
<td>
<p>significance level.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>parallel</code></td>
<td>
<p>a logical indicating whether to use parallelization.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n_cores</code></td>
<td>
<p>if <code>parallel = TRUE</code>, a number of processes used in parallel computation.
Its default value means that it will be equal to the number of cores of a computer used.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The function <code>multiFANOVA()</code> concerns the tests for the heteroscedastic
contrast testing problem for functional data. The details are presented in Munko et al. (2023),
but here we present some summary of the problem and its solutions implemented in the package.
</p>
<p>Suppose we have <code class="reqn">k</code> independent functional samples <code class="reqn">x_{i1},\dots,x_{in_i}</code>,
which consist of independent and identically distributed stochastic processes defined
on interval <code class="reqn">[a,b]</code> with mean function <code class="reqn">\eta_i</code> and covariance function
<code class="reqn">\gamma_i</code> for each <code class="reqn">i\in\{1,\dots,k\}</code>. Note that the covariance functions
of the different groups may differ from each other, i.e., heteroscedasticity is explicitly allowed.
</p>
<p>We consider the null and alternative hypothesis
</p>
<p style="text-align: center;"><code class="reqn">\mathcal H_0: \mathbf{H}\boldsymbol{\eta}(t) = 0 \text{ for all }
t\in [a,b] \quad \text{vs.} \quad \mathcal H_1: \mathbf{H}\boldsymbol{\eta}(t) \neq
0 \text{ for some } t\in [a,b],</code>
</p>
<p> where <code class="reqn">\mathbf{H} \in \mathbb{R}^{r \times k}</code>
denotes a known contrast matrix, i.e., <code class="reqn">\mathbf{H}\mathbf{1}_k = \mathbf{0}_r</code>,
<code class="reqn">\boldsymbol{\eta} := (\eta_1,\dots,\eta_k)^{\top}</code> is the vector of the mean functions.
The formulation of this testing framework is very general
and contains many special cases like the analysis of variance for functional data
(FANOVA) problem. In detail, we may choose <code class="reqn">\mathbf{H} = \mathbf{P}_k</code> for the one-way FANOVA problem
to test the null hypothesis of no main effect, where <code class="reqn">\mathbf{P}_k:=\mathbf{I}_k-\mathbf{J}_k/k</code>
with <code class="reqn">\mathbf{I}_k \in\mathbb{R}^{k\times k}</code> denoting the unit matrix and
<code class="reqn">\mathbf{J}_k := \mathbf{1}_k\mathbf{1}_k^{\top} \in\mathbb{R}^{k\times k}</code>
denoting the matrix of ones. However, there are different possible choices of the
contrast matrix <code class="reqn">\mathbf{H}</code> which lead to this global null hypothesis.
Many-to-one comparisons can be considered by choosing Dunnett's contrast matrix
<code class="reqn">\mathbf{H} = [-\mathbf{1}_{k-1}, \mathbf{I}_{k-1}]</code>, where the mean
functions <code class="reqn">\eta_2,\dots,\eta_k</code> are compared to the mean function <code class="reqn">\eta_1</code>
of the first group regarding the different contrasts. To compare all pairs
of mean functions <code class="reqn">\eta_{i_1},\eta_{i_2}, i_1,i_2 \in\{1,\dots,k\}</code> with
<code class="reqn">i_1 \neq i_2</code>, the Tukey's contrast matrix:
</p>
<p style="text-align: center;"><code class="reqn">\mathbf{H} = \begin{bmatrix}
 -1 &amp; 1 &amp; 0 &amp; 0 &amp; \cdots &amp; \cdots &amp; 0 \\
 -1 &amp; 0 &amp; 1 &amp; 0 &amp;\cdots &amp; \cdots &amp; 0 \\
 \vdots  &amp; \vdots &amp;\vdots &amp; \vdots &amp; \ddots &amp; \vdots &amp; \vdots  \\
 -1 &amp; 0 &amp; 0 &amp; 0&amp; \cdots &amp; \cdots &amp; 1\\
 0 &amp; -1 &amp; 1 &amp; 0&amp; \cdots &amp; \cdots &amp; 0 \\
 0 &amp; -1 &amp; 0 &amp; 1&amp; \cdots &amp; \cdots &amp; 0 \\
 \vdots  &amp; \vdots &amp; \vdots  &amp; \vdots &amp; \ddots &amp; \vdots &amp; \vdots \\
 0 &amp; 0 &amp; 0 &amp; 0 &amp; \cdots &amp; -1 &amp; 1
 \end{bmatrix}  \in \mathbb{R}^{k(k-1)/2 \times k}</code>
</p>
<p> can be used.
</p>
<p>For this testing problem, we consider the pointwise Hotelling's <code class="reqn">T^2</code>-test statistic
</p>
<p style="text-align: center;"><code class="reqn">\mathrm{TF}_{n,\mathbf{H}}(t):= n(\mathbf{H}\boldsymbol{\widehat\eta}(t))^{\top}
 (\mathbf{H}\mathbf{\widehat \Sigma}(t,t) \mathbf{H}^{\top})^+
 \mathbf{H} \boldsymbol{\widehat\eta}(t)</code>
</p>

<p>for all <code class="reqn">t \in[a,b]</code>, where <code class="reqn">\boldsymbol{\widehat\eta} := (\widehat\eta_1,\dots,\widehat\eta_k)^{\top}</code>
denotes the vector of all mean function estimators, <code class="reqn">\mathbf{A}^+</code> denotes the
Moore-Penrose inverse of the matrix <code class="reqn">\mathbf{A}</code>, and
</p>
<p style="text-align: center;"><code class="reqn">\boldsymbol{\widehat{\Sigma}}(t,s):= \mathrm{diag}\left( \frac{n}{n_1}\widehat{\gamma}_1(t,s),
 \ldots,\frac{n}{n_k}\widehat{\gamma}_k(t,s)\right),</code>
</p>
 <p><code class="reqn">n=n_1+\dots+n_k</code>, <code class="reqn">\widehat{\gamma}_i(t,s)</code>
is the sample covariance function for the <code class="reqn">i</code>-th group, <code class="reqn">i=1,\dots,k</code>.
Based on this pointwise Hotelling's <code class="reqn">T^2</code>-test statistic, we construct the globalizing
pointwise Hotelling's <code class="reqn">T^2</code>-test (GPH) statistic by integrating over the pointwise
Hotelling's <code class="reqn">T^2</code>-test statistic, that is
</p>
<p style="text-align: center;"><code class="reqn">T_{n}(\mathbf{H}) := \int_a^b \mathrm{TF}_{n,\mathbf{H}}(t) \,\mathrm{ d }t.</code>
</p>

<p>We consider the parametric bootstrap test based on this test statistic. However, for better post hoc
analysis, we also consider the multiple contrast testing procedures. The main idea of multiple contrast
tests is to split up the global null hypothesis with matrix
<code class="reqn">\mathbf{H}= [\mathbf{H}_1^{\top}, \dots, \mathbf{H}_r^{\top}]^{\top}</code> into <code class="reqn">r</code> single contrast
tests with contrast vectors <code class="reqn">\mathbf{H}_1, \dots, \mathbf{H}_r \in\mathbb{R}^{k}</code>.
This leads to the multiple testing problem with null hypotheses
</p>
<p style="text-align: center;"><code class="reqn">\mathcal H_{0,{\ell}} : \; \mathbf{H}_{\ell} \boldsymbol{\eta}(t) =
 0 \;\text{ for all }t\in[a,b],	\text{for }\ell\in \{1,\ldots,r\}.</code>
</p>

<p>To verify this family of null hypotheses, we adopt two approaches. First, we simply apply
the above test to each hypothesis <code class="reqn">\mathcal H_{0,{\ell}}</code>, and the resulting <code class="reqn">p</code>-values
are then corrected by the Bonferroni's method. However, this approach, denoted in the package as
GPH, may give conservative test and loss of power. Thus, we also consider the test adopting the
idea for the construction of simultaneous confidence bands proposed by Buhlmann (1998).
This test is denoted by mGPH in the package and is a more powerful solution than the GPH
procedure, which was shown in Munko et al. (2023).
</p>
<p>Note that the value of the test statistic for the mGPH test for global hypotheses is
equals to </p>
<p style="text-align: center;"><code class="reqn">\max_{\ell\in\{1,\ldots,r\}}\frac{T_{n}(\mathbf{H}_{\ell})}{q_{l,\widetilde{\beta}}^{\mathcal{P}}},</code>
</p>

<p>where <code class="reqn">q_{l,\widetilde{\beta}}^{\mathcal{P}}</code> are the quantiles calculated using
the adaptation of the method by Buhlmann (1998). The critical value for it is always 1.
</p>
<p>Please have a look at a summary function designed for this package. It can be used
to simplify the output of <code>multiFANOVA()</code> function.
</p>


<h3>Value</h3>

<p>A list of class <code>multifanova</code> containing the following components:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>res_global</code></td>
<td>
<p>a data frame containing the results for testing the global null hypothesis,
i.e., test statistics and <code class="reqn">p</code>-values.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>res_multi</code></td>
<td>
<p>all results of multiple contrasts tests for particular hypothesis in
a contrast matrix <code>h</code>, i.e., test statistics, critical values and <code class="reqn">p</code>-values.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>k</code></td>
<td>
<p>a number of groups.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>j</code></td>
<td>
<p>a number of design time points.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n</code></td>
<td>
<p>a vector of sample sizes.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>h</code></td>
<td>
<p>an argument <code>h</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>h_boot</code></td>
<td>
<p>an argument <code>n_boot</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alpha</code></td>
<td>
<p>an argument <code>alpha</code>.</p>
</td>
</tr>
</table>
<h3>References</h3>

<p>Buhlmann P. (1998) Sieve bootstrap for smoothing in nonstationary time series.
Annals of Statistics 26, 48-83.
</p>
<p>Dunnett C. (1955) A multiple comparison procedure for comparing several treatments
with a control. Journal of the American Statistical Association 50, 1096-1121.
</p>
<p>Munko M., Ditzhaus M., Pauly M., Smaga L., Zhang J.T. (2023) General multiple tests for functional data. Preprint https://arxiv.org/abs/2306.15259
</p>
<p>Tukey J.W. (1953) The problem of multiple comparisons. Princeton University.
</p>


<h3>Examples</h3>

<pre><code class="language-R"># Some of the examples may run some time.

# Canadian weather data set
# There are three samples of mean temperatures for
# fifteen weather stations in Eastern Canada,
# another fifteen in Western Canada, and
# the remaining five in Northern Canada.
library(fda)
data_set &lt;- t(CanadianWeather$dailyAv[,, "Temperature.C"])
k &lt;- 3
gr_label &lt;- rep(c(1, 2, 3), c(15, 15, 5))
# trajectories of mean temperatures
matplot(t(data_set), type = "l", col = gr_label, lty = 1,
        xlab = "Day", ylab = "Temperature (C)",
        main = "Canadian weather data set")
legend("bottom", legend = c("Eastern Canada", "Western Canada", "Northern Canada"),
       col = 1:3, lty = 1)

# Tukey's contrast matrix
h_tukey &lt;- GFDmcv::contr_mat(k, type = "Tukey")
# testing without parallel computing
res &lt;- multiFANOVA(data_set, gr_label, h_tukey)
summary(res, digits = 3)
# plots for pointwise Hotelling's T^2-test statistics
oldpar &lt;- par(mfrow = c(2, 2), mar = c(2, 2, 2, 0.1))
plot(ph_test_statistic(data_set, gr_label, h_tukey), type = "l",
     ylim = c(0, max(ph_test_statistic(data_set, gr_label, h_tukey))),
     main = "Global hypothesis")
plot(ph_test_statistic(data_set, gr_label, matrix(h_tukey[1, ], 1)), type = "l",
     ylim = c(0, max(ph_test_statistic(data_set, gr_label, h_tukey))),
     main = "Contrast 1")
plot(ph_test_statistic(data_set, gr_label, matrix(h_tukey[2, ], 1)), type = "l",
     ylim = c(0, max(ph_test_statistic(data_set, gr_label, h_tukey))),
     main = "Contrast 2")
plot(ph_test_statistic(data_set, gr_label, matrix(h_tukey[3, ], 1)), type = "l",
     ylim = c(0, max(ph_test_statistic(data_set, gr_label, h_tukey))),
     main = "Contrast 3")
par(oldpar)


# testing with parallel computing
library(doParallel)
res &lt;- multiFANOVA(data_set, gr_label, h_tukey, parallel = TRUE, n_cores = 2)
summary(res, digits = 3)


# Dunnett's contrast matrix
h_dunnett &lt;- GFDmcv::contr_mat(k, type = "Dunnett")
res &lt;- multiFANOVA(data_set, gr_label, h_dunnett)
summary(res, digits = 3)
# plots for pointwise Hotelling's T^2-test statistics
oldpar &lt;- par(mfrow = c(3, 1), mar = c(2, 2, 2, 0.1))
plot(ph_test_statistic(data_set, gr_label, h_dunnett), type = "l",
     ylim = c(0, max(ph_test_statistic(data_set, gr_label, h_dunnett))),
     main = "Global hypothesis")
plot(ph_test_statistic(data_set, gr_label, matrix(h_dunnett[1, ], 1)), type = "l",
     ylim = c(0, max(ph_test_statistic(data_set, gr_label, h_dunnett))),
     main = "Contrast 1")
plot(ph_test_statistic(data_set, gr_label, matrix(h_dunnett[2, ], 1)), type = "l",
     ylim = c(0, max(ph_test_statistic(data_set, gr_label, h_dunnett))),
     main = "Contrast 2")
par(oldpar)

</code></pre>


</div>