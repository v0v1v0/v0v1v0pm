<div class="container">

<table style="width: 100%;"><tr>
<td>multi_roc</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Multi-class classification ROC</h2>

<h3>Description</h3>

<p>This function calculates the Specificity, Sensitivity and AUC of multi-class classifications.
</p>


<h3>Usage</h3>

<pre><code class="language-R">multi_roc(data, force_diag=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>A data frame contain true labels of multiple groups and corresponding predictive scores</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>force_diag</code></td>
<td>
<p>If TRUE, TPR and FPR will be forced to across (0, 0) and (1, 1)</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>A data frame is required for this function as input. This data frame should contains true label (0 - Negative, 1 - Positive) columns named as XX_true (e.g. S1_true, S2_true and S3_true) and predictive scores (continuous) columns named as XX_pred_YY (e.g. S1_pred_SVM, S2_pred_RF), thus this function allows calcluating ROC on mulitiple classifiers.
</p>
<p>Predictive scores could be probabilities among [0, 1] and other continuous values.
For each classifier, the number of columns should be equal to the number of groups of true labels. The order of columns won't affect results.
</p>
<p>Specificity, Sensitivity, AUC for each group and each method will be calculated. Macro/Micro-average AUC for all groups and each method will be calculated.
</p>
<p>Micro-average ROC/AUC was calculated by stacking all groups together, thus converting the multi-class classification into binary classification. Macro-average ROC/AUC was calculated by averaging all groups results (one vs rest) and linear interpolation was used between points of ROC.
</p>
<p>AUC will be calculated using function <code>cal_auc()</code>.
</p>


<h3>Value</h3>

<table>
<tr style="vertical-align: top;">
<td><code>Specificity</code></td>
<td>
<p>A list of specificities for each group, each method and micro-/macro- average</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Sensitivity</code></td>
<td>
<p>A list of sensitivities for each group, each method and micro-/macro- average</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>AUC</code></td>
<td>
<p>A list of AUCs for each group, each method and micro-/macro- average</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Methods</code></td>
<td>
<p>A vector contains the name of different classifiers</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Groups</code></td>
<td>
<p>A vector contains the name of different groups</p>
</td>
</tr>
</table>
<h3>References</h3>

<p><a href="http://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html">http://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html</a>
</p>


<h3>Examples</h3>

<pre><code class="language-R">data(test_data)
roc_test &lt;- multi_roc(test_data)
roc_test$AUC 
</code></pre>


</div>