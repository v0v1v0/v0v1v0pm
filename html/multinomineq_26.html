<div class="container">

<table style="width: 100%;"><tr>
<td>ml_binom</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Maximum-likelihood Estimate</h2>

<h3>Description</h3>

<p>Get ML estimate for product-binomial/multinomial model with linear inequality constraints.
</p>


<h3>Usage</h3>

<pre><code class="language-R">ml_binom(k, n, A, b, map, strategy, n.fit = 3, start, progress = FALSE, ...)

ml_multinom(k, options, A, b, V, n.fit = 3, start, progress = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>k</code></td>
<td>
<p>vector of observed response frequencies.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n</code></td>
<td>
<p>the number of choices per item type.
If <code>k=n=0</code>, Bayesian inference is relies on the prior distribution only.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>A</code></td>
<td>
<p>a matrix with one row for each linear inequality constraint and one
column for each of the free parameters. The parameter space is defined
as all probabilities <code>x</code> that fulfill the order constraints  <code>A*x &lt;= b</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>b</code></td>
<td>
<p>a vector of the same length as the number of rows of <code>A</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>map</code></td>
<td>
<p>optional: numeric vector of the same length as <code>k</code> with integers
mapping the frequencies <code>k</code> to the free parameters/columns of <code>A</code>/<code>V</code>,
thereby allowing for equality constraints (e.g., <code>map=c(1,1,2,2)</code>).
Reversed probabilities <code>1-p</code> are coded by negative integers.
Guessing probabilities of .50 are encoded by zeros. The default assumes
different parameters for each item type: <code>map=1:ncol(A)</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>strategy</code></td>
<td>
<p>a list that defines the predictions of a strategy, see<code>strategy_multiattribute</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n.fit</code></td>
<td>
<p>number of calls to constrOptim.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>start</code></td>
<td>
<p>only relevant if <code>steps</code> is defined or <code>cmin&gt;0</code>:
a vector with starting values in the interior of the polytope.
If missing, an approximate maximum-likelihood estimate is used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>progress</code></td>
<td>
<p>whether a progress bar should be shown (if <code>cpu=1</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>further arguments passed to the function
<code>constrOptim</code>. To ensure high accuracy, the number of
maximum iterations should be sufficiently large (e.g., by setting
<code>control = list(maxit = 1e6, reltol=.Machine$double.eps^.6), outer.iterations = 1000</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>options</code></td>
<td>
<p>number of observable categories/probabilities for each item
type/multinomial distribution, e.g., <code>c(3,2)</code> for a ternary and binary item.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>V</code></td>
<td>
<p>a matrix of vertices (one per row) that define the polytope of
admissible parameters as the convex hull over these points
(if provided, <code>A</code> and <code>b</code> are ignored).
Similar as for <code>A</code>, columns of <code>V</code> omit the last value for each
multinomial condition (e.g., a1,a2,a3,b1,b2 becomes a1,a2,b1).
Note that this method is comparatively slow since it solves linear-programming problems
to test whether a point is inside  a polytope (Fukuda, 2004) or to run the Gibbs sampler.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>First, it is checked whether the unconstrained maximum-likelihood estimator
(e.g., for the binomial: <code>k/n</code>) is inside the constrained parameter space.
Only if this is not the case, nonlinear optimization with convex linear-inequality
constrained is used to estimate (A) the probability parameters <code class="reqn">\theta</code>
for the Ab-representation or (B) the mixture weights <code class="reqn">\alpha</code> for the V-representation.
</p>


<h3>Value</h3>

<p>the list returned by the optimizer <code>constrOptim</code>,
including the input arguments (e.g., <code>k</code>, <code>options</code>, <code>A</code>, <code>V</code>, etc.).
</p>

<ul>
<li>
<p> If the Ab-representation was used, <code>par</code> provides the ML estimate for
the probability vector <code class="reqn">\theta</code>.
</p>
</li>
<li>
<p> If the V-representation was used, <code>par</code> provides the estimates for the
(usually not identifiable) mixture weights <code class="reqn">\alpha</code> that define the convex
hull of the vertices in <code class="reqn">V</code>, while <code>p</code> provides the ML estimates for
the probability parameters. Because the weights must sum to one, the
<code class="reqn">\alpha</code>-parameter for the last row of the matrix <code class="reqn">V</code> is dropped.
If the unconstrained ML estimate is inside the convex hull, the mixture weights
<code class="reqn">\alpha</code> are not estimated and replaced by missings (<code>NA</code>).
</p>
</li>
</ul>
<h3>Examples</h3>

<pre><code class="language-R"># predicted linear order: p1 &lt; p2 &lt; p3 &lt; .50
# (cf. WADDprob in ?strategy_multiattribute)
A &lt;- matrix(
  c(
    1, -1, 0,
    0, 1, -1,
    0, 0, 1
  ),
  ncol = 3, byrow = TRUE
)
b &lt;- c(0, 0, .50)
ml_binom(k = c(4, 1, 23), n = 40, A, b)[1:2]
ml_multinom(
  k = c(4, 36, 1, 39, 23, 17),
  options = c(2, 2, 2), A, b
)[1:2]


# probabilistic strategy:  A,A,A,B  [e1&lt;e2&lt;e3&lt;e4&lt;.50]
strat &lt;- list(
  pattern = c(-1, -2, -3, 4),
  c = .5, ordered = TRUE, prior = c(1, 1)
)
ml_binom(c(7, 3, 1, 19), 20, strategy = strat)[1:2]


# vertex representation (one prediction per row)
V &lt;- matrix(c(
  # strict weak orders
  0, 1, 0, 1, 0, 1, # a &lt; b &lt; c
  1, 0, 0, 1, 0, 1, # b &lt; a &lt; c
  0, 1, 0, 1, 1, 0, # a &lt; c &lt; b
  0, 1, 1, 0, 1, 0, # c &lt; a &lt; b
  1, 0, 1, 0, 1, 0, # c &lt; b &lt; a
  1, 0, 1, 0, 0, 1, # b &lt; c &lt; a

  0, 0, 0, 1, 0, 1, # a ~ b &lt; c
  0, 1, 0, 0, 1, 0, # a ~ c &lt; b
  1, 0, 1, 0, 0, 0, # c ~ b &lt; a
  0, 1, 0, 1, 0, 0, # a &lt; b ~ c
  1, 0, 0, 0, 0, 1, # b &lt; a ~ c
  0, 0, 1, 0, 1, 0, # c &lt; a ~ b

  0, 0, 0, 0, 0, 0 # a ~ b ~ c
), byrow = TRUE, ncol = 6)
ml_multinom(
  k = c(4, 1, 5, 1, 9, 0, 7, 2, 1), n.fit = 1,
  options = c(3, 3, 3), V = V
)
</code></pre>


</div>