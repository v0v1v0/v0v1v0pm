<div class="container">

<table style="width: 100%;"><tr>
<td>mlikCV</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Outer-loop cross-validation for estimating performance of marginal likelihood based <code>multiridge</code>
</h2>

<h3>Description</h3>

<p>Outer-loop cross-validation for estimating performance of marginal likelihood based <code>multiridge</code>.
Outer fold is for testing;  penalty parameter tuning is performed by marginal likelihood estimation</p>


<h3>Usage</h3>

<pre><code class="language-R">mlikCV(penaltiesinit, XXblocks, Y, pairing = NULL, outfold = 5, nrepeatout = 1,
balance = TRUE,fixedfolds = TRUE,  model = NULL, intercept =
ifelse(is(Y, "Surv"), FALSE, TRUE), reltol = 1e-04, trace = FALSE, optmethod1 = "SANN",
optmethod2 = ifelse(length(penaltiesinit) == 1, "Brent", "Nelder-Mead"),
maxItropt1 = 10, maxItropt2 = 25, parallel = FALSE, pref = NULL,
fixedpen = NULL, sigmasq = 1, opt.sigma=ifelse(model=="linear",TRUE, FALSE))
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>penaltiesinit</code></td>
<td>

<p>Numeric vector. Initial values for penaltyparameters. May be obtained from <code>fastCV2</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>XXblocks</code></td>
<td>

<p>List of <code>nxn</code> matrices. Usually output of <code>createXXblocks</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Y</code></td>
<td>

<p>Response vector: numeric, binary, factor or <code>survival</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pairing</code></td>
<td>

<p>Numerical vector of length 3 or <code>NULL</code> when pairs are absent. Represents the indices (in <code>XXblocks</code>) of the two data blocks involved in pairing,
plus the index of the paired block.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>outfold</code></td>
<td>

<p>Integer. Outer fold for test samples.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nrepeatout</code></td>
<td>

<p>Integer. Number of repeated splits for outer fold.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>balance</code></td>
<td>

<p>Boolean. Should the splits be balanced in terms of response labels?
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fixedfolds</code></td>
<td>

<p>Boolean. Should fixed splits be used for reproducibility?
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>intercept</code></td>
<td>

<p>Boolean. Should an intercept be included?
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>model</code></td>
<td>

<p>Character. Any of <code>c("linear", "logistic", "cox")</code>. Is inferred from
<code>Y</code> when <code>NULL</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>trace</code></td>
<td>

<p>Boolean. Should the output of the IWLS algorithm be traced?
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>reltol</code></td>
<td>

<p>Scalar. Relative tolerance for optimization methods.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>optmethod1</code></td>
<td>

<p>Character. First, global search method. Any of the methods <code>c("Brent", "Nelder-Mead", "Sann")</code> may be used, but
simulated annealing by <code>"Sann"</code> is recommended to search a wide landscape. Other unconstrained methods
offered by <code>optim</code> may also be used, but have not been tested.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>optmethod2</code></td>
<td>

<p>Character. Second, local search method. Any of the methods <code>c("Brent", "Nelder-Mead", "Sann")</code> may be used, but
<code>"Nelder-Mead"</code> is generally recommended. Other unconstrained methods
offered by <code>optim</code> may also be used, but have not been tested.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>maxItropt1</code></td>
<td>

<p>Integer. Maximum number of iterations for <code>optmethod1</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>maxItropt2</code></td>
<td>

<p>Integer. Maximum number of iterations for <code>optmethod2</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>parallel</code></td>
<td>

<p>Boolean. Should computation be done in parallel? If <code>TRUE</code>, requires to run <code>setupParallel</code> first.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pref</code></td>
<td>

<p>Integer vector or <code>NULL</code>. Contains indices of data types in <code>XXblocks</code> that are preferential.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fixedpen</code></td>
<td>

<p>Integer vector or <code>NULL</code>. Contains indices of data types of which penalty is fixed to the corresponding value in <code>penaltiesinit</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sigmasq</code></td>
<td>
<p>Default error variance.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>opt.sigma</code></td>
<td>
<p>Boolean. Should the error variance be optimized as well? Only relevant for <code>model="linear"</code>.
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>WARNING: this function may be very time-consuming. The number of evaluations may equal <code>nrepeatout*outerfold*(maxItropt1+maxItropt2)</code>. Computing time may be estimated by multiplying computing time of <code>optLambdas_mgcvWrap</code> by
<code>nrepeatout*outerfold</code>.
</p>


<h3>Value</h3>

<p>List with the following components:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>sampleindex</code></td>
<td>
<p>Numerical vector: sample indices</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>true</code></td>
<td>
<p>True responses</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>linpred</code></td>
<td>
<p>Cross-validated linear predictors</p>
</td>
</tr>
</table>
<h3>See Also</h3>

<p><code>optLambdas_mgcv</code>, <code>optLambdas_mgcvWrap</code> which optimize the penalties.
<code>Scoring</code> which may applied to output of this function to obtain overall cross-validated performance score.
<code>doubleCV</code> for double cross-validation counterpart. A full demo and data are available from:<br><a href="https://drive.google.com/open?id=1NUfeOtN8-KZ8A2HZzveG506nBwgW64e4">https://drive.google.com/open?id=1NUfeOtN8-KZ8A2HZzveG506nBwgW64e4</a>
</p>


<h3>Examples</h3>

<pre><code class="language-R">data(dataXXmirmeth)
resp &lt;- dataXXmirmeth[[1]]
XXmirmeth &lt;- dataXXmirmeth[[2]]

# Find initial lambdas: fast CV per data block separately.
cvperblock2 &lt;- fastCV2(XXblocks=XXmirmeth,Y=resp,kfold=10,fixedfolds = TRUE)
lambdas &lt;- cvperblock2$lambdas

# Outer cross-validation, inner marginal likelihood optimization
## Not run: 
perfmlik &lt;- mlikCV(penaltiesinit=lambdas,XXblocks=XXmirmeth,Y=resp,outfold=10,
nrepeatout=1)


# Performance metrics
Scoring(perfmlik$linpred,perfmlik$true,score="auc",print=TRUE)
Scoring(perfmlik$linpred,perfmlik$true,score="brier",print=TRUE)
Scoring(perfmlik$linpred,perfmlik$true,score="loglik",print=TRUE)

## End(Not run)
</code></pre>


</div>