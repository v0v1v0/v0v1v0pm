<div class="container">

<table style="width: 100%;"><tr>
<td>optLambdas</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Find optimal ridge penalties.
</h2>

<h3>Description</h3>

<p>Optimizes a cross-validated score w.r.t. ridge penalties for multiple data blocks.
</p>


<h3>Usage</h3>

<pre><code class="language-R">optLambdas(penaltiesinit = NULL, XXblocks, Y, X1 = NULL, pairing = NULL, folds,
  intercept = ifelse(is(Y, "Surv"), FALSE, TRUE), frac1 = NULL, score = "loglik",
  model = NULL, epsIWLS = 0.001, maxItrIWLS = 25, traceCV = TRUE, reltol = 1e-04,
  optmethod = ifelse(length(penaltiesinit) == 1, "Brent", "Nelder-Mead"), maxItropt = 500,
  save = FALSE, parallel = FALSE, fixedpen = NULL, fixedseed = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>penaltiesinit</code></td>
<td>

<p>Numeric vector. Initial values for penaltyparameters. May be obtained from <code>fastCV2</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>XXblocks</code></td>
<td>

<p>List of <code>nxn</code> matrices. Usually output of <code>createXXblocks</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Y</code></td>
<td>

<p>Response vector: numeric, binary, factor or <code>survival</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>X1</code></td>
<td>

<p>Matrix. Dimension <code>n x p_0, p_0 &lt; n</code>, representing unpenalized covariates </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pairing</code></td>
<td>

<p>Numerical vector of length 3 or <code>NULL</code> when pairs are absent. Represents the indices (in <code>XXblocks</code>) of the two data blocks involved in pairing,
plus the index of the paired block.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>folds</code></td>
<td>

<p>List, containing the splits of the samples. Usually obtained by <code>CVfolds</code>
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>intercept</code></td>
<td>

<p>Boolean. Should an intercept be included?
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>frac1</code></td>
<td>

<p>Scalar. Prior fraction of cases. Only relevant for <code>model=" logistic"</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>score</code></td>
<td>

<p>Character. See Details.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>model</code></td>
<td>

<p>Character. Any of <code>c("linear", "logistic", "cox")</code>. Is inferred from
<code>Y</code> when <code>NULL</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>epsIWLS</code></td>
<td>

<p>Scalar. Numerical bound for IWLS convergence.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>maxItrIWLS</code></td>
<td>

<p>Integer. Maximum number of iterations used in IWLS.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>traceCV</code></td>
<td>

<p>Boolean. Should the output of the IWLS algorithm be traced?
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>reltol</code></td>
<td>

<p>Scalar. Relative tolerance for optimization methods.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>optmethod</code></td>
<td>

<p>Character. Optimization method. Any of the methods <code>c("Brent", "Nelder-Mead", "Sann")</code> may be used, but
<code>"Nelder-Mead"</code> is generally recommended. Other unconstrained methods offered by <code>optim</code> may also be used, but have not been tested.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>maxItropt</code></td>
<td>

<p>Integer. Maximum number of iterations for <code>optmethod</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>save</code></td>
<td>

<p>Boolean. If TRUE appends the penalties and resulting CVscore to global variable <code>allscores</code>
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>parallel</code></td>
<td>

<p>Boolean. Should computation be done in parallel? If <code>TRUE</code>, requires to run <code>setupParallel</code> first.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fixedpen</code></td>
<td>

<p>Integer vector or <code>NULL</code>. Contains indices of data types of which penalty is fixed to the corresponding value in <code>penaltiesinit</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fixedseed</code></td>
<td>

<p>Boolean. Should the initialization be fixed? For reproducibility.
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>See <code>Scoring</code> for details on <code>score</code>.
We highly recommend to use smooth scoring functions, in particular <code>"loglik"</code>.
For ranking-based criteria like <code>auc</code> and <code>cindex</code> we advise to use repeated CV (see <code>CVfolds</code>) to avoid ending up in any of the many local optima.
</p>


<h3>Value</h3>

<p>List, with components:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>optres</code></td>
<td>
<p>Output of the optimizer</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>optpen</code></td>
<td>
<p>Vector with determined optimal penalties</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>allsc</code></td>
<td>
<p>Matrix with CV scores for all penalty parameter configurations used by the optimizer</p>
</td>
</tr>
</table>
<h3>See Also</h3>

<p><code>optLambdasWrap</code> for i) (recommended) optimization in two steps: first global, then local; and ii) sequential optimization
when some data types are preferred over others. <code>fastCV2</code> for initialization of penalties. A full demo and data are available from:<br><a href="https://drive.google.com/open?id=1NUfeOtN8-KZ8A2HZzveG506nBwgW64e4">https://drive.google.com/open?id=1NUfeOtN8-KZ8A2HZzveG506nBwgW64e4</a>
</p>


<h3>Examples</h3>

<pre><code class="language-R">data(dataXXmirmeth)
resp &lt;- dataXXmirmeth[[1]]
XXmirmeth &lt;- dataXXmirmeth[[2]]

# Find initial lambdas: fast CV per data block separately.
cvperblock2 &lt;- fastCV2(XXblocks=XXmirmeth,Y=resp,kfold=10,fixedfolds = TRUE)
lambdas &lt;- cvperblock2$lambdas

# Create (repeated) CV-splits of the data.
leftout &lt;- CVfolds(Y=resp,kfold=10,nrepeat=3,fixedfolds = TRUE)

# One-pass optimization
# Increase the number of iterations for optimal results
jointlambdas &lt;- optLambdas(penaltiesinit=lambdas, XXblocks=XXmirmeth,Y=resp,
folds=leftout,score="loglik",save=T,maxItropt=5)
</code></pre>


</div>