<div class="container">

<table style="width: 100%;"><tr>
<td>doubleCV</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Double cross-validation for estimating performance of <code>multiridge</code>
</h2>

<h3>Description</h3>

<p>Double cross-validation for estimating performance of <code>multiridge</code>. Outer fold is for testing, inner fold for penalty parameter tuning</p>


<h3>Usage</h3>

<pre><code class="language-R">doubleCV(penaltiesinit, XXblocks, Y, X1 = NULL, pairing = NULL, outfold = 5,
  infold = 10, nrepeatout =   1, nrepeatin = 1, balance = TRUE, fixedfolds =
  TRUE, intercept = ifelse(is(Y, "Surv"), FALSE,     TRUE), frac1 = NULL,
  score = "loglik",model = NULL, eps = 1e-07, maxItr = 10, trace = FALSE,
  printCV   = TRUE, reltol = 1e-04, optmethod1 = "SANN", optmethod2 =
  ifelse(length(penaltiesinit) == 1, "Brent", "Nelder-Mead"), maxItropt1 = 10,
  maxItropt2 = 25, save = FALSE, parallel = FALSE, pref = NULL, fixedpen = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>penaltiesinit</code></td>
<td>

<p>Numeric vector. Initial values for penaltyparameters. May be obtained from <code>fastCV2</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>XXblocks</code></td>
<td>

<p>List of <code>nxn</code> matrices. Usually output of <code>createXXblocks</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Y</code></td>
<td>

<p>Response vector: numeric, binary, factor or <code>survival</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>X1</code></td>
<td>

<p>Matrix. Dimension <code>n x p_0, p_0 &lt; n</code>, representing unpenalized covariates </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pairing</code></td>
<td>

<p>Numerical vector of length 3 or <code>NULL</code> when pairs are absent. Represents the indices (in <code>XXblocks</code>) of the two data blocks involved in pairing,
plus the index of the paired block.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>outfold</code></td>
<td>

<p>Integer. Outer fold for test samples.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>infold</code></td>
<td>

<p>Integer. Inner fold for tuning penalty parameters.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nrepeatout</code></td>
<td>

<p>Integer. Number of repeated splits for outer fold.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nrepeatin</code></td>
<td>

<p>Integer. Number of repeated splits for inner fold.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>balance</code></td>
<td>

<p>Boolean. Should the splits be balanced in terms of response labels?
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fixedfolds</code></td>
<td>

<p>Boolean. Should fixed splits be used for reproducibility?
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>intercept</code></td>
<td>

<p>Boolean. Should an intercept be included?
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>frac1</code></td>
<td>

<p>Scalar. Prior fraction of cases. Only relevant for <code>model=" logistic"</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>score</code></td>
<td>

<p>Character. See Details.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>model</code></td>
<td>

<p>Character. Any of <code>c("linear", "logistic", "cox")</code>. Is inferred from
<code>Y</code> when <code>NULL</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>eps</code></td>
<td>

<p>Scalar. Numerical bound for IWLS convergence.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>maxItr</code></td>
<td>

<p>Integer. Maximum number of iterations used in IWLS.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>trace</code></td>
<td>

<p>Boolean. Should the output of the IWLS algorithm be traced?
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>printCV</code></td>
<td>

<p>Boolean. Should the CV-score be printed on screen?
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>reltol</code></td>
<td>

<p>Scalar. Relative tolerance for optimization methods.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>optmethod1</code></td>
<td>

<p>Character. First, global search method. Any of the methods <code>c("Brent", "Nelder-Mead", "Sann")</code> may be used, but
simulated annealing by <code>"Sann"</code> is recommended to search a wide landscape. Other unconstrained methods
offered by <code>optim</code> may also be used, but have not been tested.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>optmethod2</code></td>
<td>

<p>Character. Second, local search method. Any of the methods <code>c("Brent", "Nelder-Mead", "Sann")</code> may be used, but
<code>"Nelder-Mead"</code> is generally recommended. Other unconstrained methods
offered by <code>optim</code> may also be used, but have not been tested.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>maxItropt1</code></td>
<td>

<p>Integer. Maximum number of iterations for <code>optmethod1</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>maxItropt2</code></td>
<td>

<p>Integer. Maximum number of iterations for <code>optmethod2</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>save</code></td>
<td>

<p>Boolean. If TRUE appends the penalties and resulting CVscore to global variable <code>allscores</code>
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>parallel</code></td>
<td>

<p>Boolean. Should computation be done in parallel? If <code>TRUE</code>, requires to run <code>setupParallel</code> first.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pref</code></td>
<td>

<p>Integer vector or <code>NULL</code>. Contains indices of data types in <code>XXblocks</code> that are preferential.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fixedpen</code></td>
<td>

<p>Integer vector or <code>NULL</code>. Contains indices of data types of which penalty is fixed to the corresponding value in <code>penaltiesinit</code>.
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>WARNING: this function may be very time-consuming. The number of evaluations may equal <code>nrepeatout*outerfold*nrepeatin*innerfold*maxItr*(maxItropt1+maxItropt2)</code>. Computing time may be estimated by multiplying computing time of <code>optLambdasWrap</code> by
<code>nrepeatout*outerfold</code>. See <code>Scoring</code> for details on <code>score</code>.
</p>


<h3>Value</h3>

<p>List with the following components:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>sampleindex</code></td>
<td>
<p>Numerical vector: sample indices</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>true</code></td>
<td>
<p>True responses</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>linpred</code></td>
<td>
<p>Cross-validated linear predictors</p>
</td>
</tr>
</table>
<h3>See Also</h3>

<p><code>optLambdas</code>, <code>optLambdasWrap</code> which optimize the penalties.
<code>Scoring</code> which may applied to output of this function to obtain overall cross-validated performance score. A full demo and data are available from:<br><a href="https://drive.google.com/open?id=1NUfeOtN8-KZ8A2HZzveG506nBwgW64e4">https://drive.google.com/open?id=1NUfeOtN8-KZ8A2HZzveG506nBwgW64e4</a>
</p>


<h3>Examples</h3>

<pre><code class="language-R">data(dataXXmirmeth)
resp &lt;- dataXXmirmeth[[1]]
XXmirmeth &lt;- dataXXmirmeth[[2]]

# Find initial lambdas: fast CV per data block separately.
cvperblock2 &lt;- fastCV2(XXblocks=XXmirmeth,Y=resp,kfold=10,fixedfolds = TRUE)
lambdas &lt;- cvperblock2$lambdas

# Double cross-validation
## Not run: 
perf &lt;- doubleCV(penaltiesinit=lambdas,XXblocks=XXmirmeth,Y=resp,
score="loglik",outfold=10, infold=10, nrepeatout=1, nrepeatin=3, parallel=TRUE)

# Performance metrics
Scoring(perf$linpred,perf$true,score="auc",print=TRUE)
Scoring(perf$linpred,perf$true,score="brier",print=TRUE)
Scoring(perf$linpred,perf$true,score="loglik",print=TRUE)

## End(Not run)
</code></pre>


</div>