<div class="container">

<table style="width: 100%;"><tr>
<td>multivariance-package</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>multivariance: Measuring Multivariate Dependence Using Distance Multivariance</h2>

<h3>Description</h3>

<p>The multivariance package provides basic functions to calculate distance multivariance and related quantities. To test independence use <code>multivariance.test</code>, it provides an interface (via its arguments) to all the tests based on distance (m-/total-)multivariance. The package offers also several other functions related to distance multivariance, e.g. a detection and visualization of dependence structures <code>dependence.structure</code>. See below for details on the full content of the package.
</p>


<h3>Details</h3>

<p>Distance multivariance is a multivariate dependence measure, which can be used to detect dependencies between an arbitrary number of random vectors each of which can have a distinct dimension. The necessary functions are implemented in this package, and examples are given. For the theoretic background we refer to the papers [1,2,3,4,5,6]. Paper [3] includes a summary of the first two. It is the recommended starting point for users with an applied interest. Paper [4] is concerned with new (faster) p-value estimates for the independence tests, [5] introduces the copula versions of distance multivariance, [6] discusses the quantification of dependence using distance multicorrelations.
</p>
<p>The (current) code is speed improved in comparison to the former releases. Certainly there is still room for improvement and development. Questions, comments and remarks are welcome: <a href="mailto:bjoern.boettcher@tu-dresden.de">bjoern.boettcher@tu-dresden.de</a>
</p>
<p>For infos on the latest changes and/or updates to the package use <code>news(package="multivariance")</code>.
</p>
<p>To cite this package use the standard citation for R packages, i.e., the output of <code>citation("multivariance")</code>.
</p>


<h3>Multivariance</h3>

<p><code>multivariance</code> computes the distance multivariance
</p>
<p><code>total.multivariance</code> computes the total distance multivariance
</p>
<p><code>m.multivariance</code> computes the m-multivariance (introduced in [3])
</p>
<p>It might be convenient to compute these simultaneously using <code>multivariances.all</code>.
</p>
<p><code>copula.multivariance</code> computes the copula versions of the above (introduced in [5])
</p>
<p><code>multicorrelation</code> computes the multicorrelations (discussed specifically in [6])
</p>


<h3>Functions to use and interpret multivariance</h3>

<p><code>rejection.level</code> computes a (conservative) rejection level for a given significance level. This can be used for a conservative interpretation of distance multivariance. The counterpart is <code>multivariance.pvalue</code>, which computes a conservative p-value for a given distance multivariance. Both methods are distribution-free.
</p>
<p><code>resample.rejection.level</code> and <code>resample.pvalue</code> are the distribution dependent versions of the above. They are approximately sharp, but computational more expensive. Any resampling is done by <code>resample.multivariance</code>.
</p>
<p>Using the methods developed in [4] approximate p-value estimates are provided by <code>pearson.pvalue</code>. This method is much faster than the resampling method.
</p>
<p><code>multivariance.test</code> provides the corresponding tests of independence. The former provides output as common for tests in R.
</p>
<p><code>cdm</code> and <code>cdms</code> compute the doubly centered distance matrix and matrices, respectively. These can be used to speed up repeated computations of distance multivariance.
</p>
<p>In [4] various methods to estimate the moments of the test statistic under H0 were developed, these are (implicitly) implemented in this package only for the moments used in <code>pearson.pvalue</code>. Further and explicit functions can be added upon request. Please feel free to contact the author.
</p>
<p><code>emp.transf</code> computes the Monte Carlo empirical transform of the data. This data yields the copula version of distance multivariance. Hereto note, that values become randomized due to the "Monte Carlo empirical transform", i.e., the copula versions yield in a finite sample setting not identical values for repeated runs.
</p>
<p>For planing of large projects or studies it might be convenient to estimate the computation time of multivariance via <code>multivariance.timing</code>.
</p>


<h3>Dependence structures</h3>

<p><code>dependence.structure</code> performs the dependence structure detection algorithm as described in [3].
</p>
<p><code>find.cluster</code> is the basic building block of <code>dependence.structure</code>. It is recommended to use <code>dependence.structure</code>.
</p>


<h3>Examples</h3>

<p><code>coins</code> and <code>tetrahedron</code> generate samples of pairwise independent random variables, with dependence of higher order.
</p>
<p><code>dep_struct_iterated_13_100</code>, <code>dep_struct_ring_15_100</code>, <code>dep_struct_several_26_100</code> and <code>dep_struct_star_9_100</code> are example data sets for the dependence structure detection. These might also serve as benchmark examples.
</p>
<p><code>anscombe.extended</code> provides an extension of Anscombe's Quartett. It illustrates that a large value of Pearson's correlation can occur for very different dependencies and that this is not a small-sample problem. These dependencies are at least partly differentiated by values of distance multicorrelation.
</p>


<h3>References</h3>

<p>[1] B. Böttcher, M. Keller-Ressel, R.L. Schilling, Detecting independence of random vectors: generalized distance covariance and Gaussian covariance. Modern Stochastics: Theory and Applications, Vol. 5, No. 3(2018) 353-383. <a href="https://www.vmsta.org/journal/VMSTA/article/127/info">https://www.vmsta.org/journal/VMSTA/article/127/info</a>
</p>
<p>[2] B. Böttcher, M. Keller-Ressel, R.L. Schilling, Distance multivariance: New dependence measures for random vectors. The Annals of Statistics, Vol. 47, No. 5 (2019) 2757-2789. doi: <a href="https://doi.org/10.1214/18-AOS1764">10.1214/18-AOS1764</a>
</p>
<p>[3] B. Böttcher, Dependence and Dependence Structures: Estimation and Visualization using the Unifying Concept of Distance Multivariance. Open Statistics, Vol. 1, No. 1 (2020) 1-46. doi: <a href="https://doi.org/10.1515/stat-2020-0001">10.1515/stat-2020-0001</a>
</p>
<p>[4] G. Berschneider, B. Böttcher, On complex Gaussian random fields, Gaussian quadratic forms and sample distance multivariance. Preprint. <a href="https://arxiv.org/abs/1808.07280">https://arxiv.org/abs/1808.07280</a>
</p>
<p>[5] B. Böttcher, Copula versions of distance multivariance and dHSIC via the distributional transform – a general approach to construct invariant dependence measures. Statistics, (2020) 1-18. doi: <a href="https://doi.org/10.1080/02331888.2020.1748029">10.1080/02331888.2020.1748029</a>
</p>
<p>[6] B. Böttcher, Notes on the interpretation of dependence measures – Pearson's correlation, distance correlation, distance multicorrelations and their copula versions. Preprint. <a href="https://arxiv.org/abs/2004.07649">https://arxiv.org/abs/2004.07649</a>
</p>


</div>