<div class="container">

<table style="width: 100%;"><tr>
<td>Hypothesis test for two high-dimensional mean vectors</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Hypothesis test for two high-dimensional mean vectors
</h2>

<h3>Description</h3>

<p>Hypothesis test for two high-dimensional mean vectors.
</p>


<h3>Usage</h3>

<pre><code class="language-R">sarabai(x1, x2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x1</code></td>
<td>

<p>A matrix containing the Euclidean data of the first group.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x2</code></td>
<td>

<p>A matrix containing the Euclidean data of the second group.
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>High dimensional data are the multivariate data which have many variables (<code class="reqn">p</code>) and usually a small number of observations (<code class="reqn">n</code>). It also happens that <code class="reqn">p&gt;n</code> and this is the case here in this Section. We will see a simple test for the case of <code class="reqn">p&gt;n</code>. In this case, the covariance matrix is not invertible and in addition it can have a lot of zero eigenvalues.
</p>
<p>The test we will see was proposed by Bai and Saranadasa (1996). Ever since, there have been some more suggestions but I chose this one for its simplicity. There are two datasets, <code class="reqn">{\bf X}_1</code> and <code class="reqn">{\bf X}_2</code> of sample sizes <code class="reqn">n_1</code> and <code class="reqn">n_2</code>, respectively. Their corresponding sample mean vectors and covariance matrices are <code class="reqn">\bar{{\bf X}}_1</code>, <code class="reqn">\bar{{\bf X}}_2</code> and <code class="reqn">{\bf S}_1</code>, <code class="reqn">{\bf S}_2</code> respectively. The assumption here is the same as that of the Hotelling's test we saw before.
</p>
<p>Let us define the pooled covariance matrix at first, calculated under the assumption of equal covariance matrices
<code class="reqn">
{\bf S}_n=\frac{\left(n_1-1\right){\bf S}_1+\left(n_2-1\right){\bf S}_2}{n}</code>,
where <code class="reqn">n=n_1+n_2</code>. Then define <code class="reqn">B_n=\sqrt{ \frac{n^2}{\left(n+2\right)\left(n-1\right)}\left\lbrace\text{tr}\left({\bf S}_n^2\right)-
\frac{1}{n}\left[\text{tr}\left({\bf S}_n\right)\right]^2 \right\rbrace }</code>.
The test statistic is
</p>
<p style="text-align: center;"><code class="reqn">
Z=\frac{\frac{n_1n_2}{n_1+n_2}\left(\bar{{\bf X}}_1-\bar{{\bf X}}_2\right)^T\left(\bar{{\bf X}}_1-\bar{{\bf X}}_2\right)
-\text{tr}\left({\bf S}_n\right)}{\sqrt{\frac{2\left(n+1\right)}{n}}B_n}.
</code>
</p>

<p>Under the null hypothesis (equality of the two mean vectors) the test statistic follows the standard normal distribution. Bai and Saranadasa (1996) established the asymptotic normality of the test statistics and showed that it has attractive power property when <code class="reqn">p/n \rightarrow c &lt; \infty</code> and under some restriction on the maximum eigenvalue of the common population covariance matrix. However, the requirement of <code class="reqn">p</code> and <code class="reqn">n</code> being of the same order is too restrictive to be used in the "large <code class="reqn">p</code> small <code class="reqn">n</code>" situation.
</p>


<h3>Value</h3>

<p>A vector with the test statistic and the p-value.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Bai Z. D. and Saranadasa H. (1996). Effect of high dimension: by an example of a two
sample problem. Statistica Sinica, 6(2): 311â€“329.
</p>


<h3>See Also</h3>

<p><code>hotel2T2, maov, el.test2, eel.test2
</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">x1 &lt;- matrix( rnorm(40 * 100), ncol = 100 )
x2 &lt;- matrix( rnorm(50 * 100), ncol = 100 )
sarabai(x1, x2)
</code></pre>


</div>