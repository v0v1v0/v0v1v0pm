<div class="container">

<table style="width: 100%;"><tr>
<td>Exponential empirical likelihood for a one sample mean vector hypothesis testing</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Exponential empirical likelihood for a one sample mean vector hypothesis testing
</h2>

<h3>Description</h3>

<p>Exponential empirical likelihood for a one sample mean vector hypothesis testing.
</p>


<h3>Usage</h3>

<pre><code class="language-R">eel.test1(x, mu, tol = 1e-06, R = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>

<p>A matrix containing Euclidean data.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mu</code></td>
<td>

<p>The hypothesized mean vector.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tol</code></td>
<td>

<p>The tolerance value used to stop the Newton-Raphson algorithm.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>R</code></td>
<td>

<p>The number of bootstrap samples used to calculate the p-value. If R = 1 (default value), no bootstrap calibration is performed
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Exponential empirical likelihood or exponential tilting was first introduced by Efron (1981) as a way to perform a "tilted" version of the bootstrap for the one sample mean hypothesis testing. Similarly to the empirical likelihood, positive weights <code class="reqn">p_i</code>, which sum to one, are allocated to the observations, such that the weighted sample mean <code class="reqn">{\bf \bar{x}}</code> is equal to some population mean <code class="reqn">\pmb{\mu}_0</code>, under the <code class="reqn">H_0</code>. Under <code class="reqn">H_1</code> the weights are equal to <code class="reqn">\frac{1}{n}</code>, where <code class="reqn">n</code> is the sample size. Following Efron (1981), the choice of <code class="reqn">p_is</code> will minimize the Kullback-Leibler distance from <code class="reqn">H_0</code> to <code class="reqn">H_1</code>
</p>
<p style="text-align: center;"><code class="reqn">
D\left(L_0,L_1\right)=\sum_{i=1}^np_i\log\left(np_i\right),
</code>
</p>

<p>subject to the constraint <code class="reqn">\sum_{i=1}^np_i{\bf x}_i=\pmb{\mu}_0</code>. The probabilities take the form
</p>
<p style="text-align: center;"><code class="reqn">
p_i=\frac{e^{\pmb{\lambda}^T{\bf x}_i}}{\sum_{j=1}^ne^{\pmb{\lambda}^T{\bf x}_j}}
</code>
</p>

<p>and the constraint becomes
</p>
<p style="text-align: center;"><code class="reqn">
\frac{\sum_{i=1}^ne^{\pmb{\lambda}^T{\bf x}_i}\left({\bf x}_i-\pmb{\mu}_0\right)}{\sum_{j=1}^ne^{\pmb{\lambda}^T{\bf x}_j}}=0 \Rightarrow \frac{\sum_{i=1}^n{\bf x}_ie^{\pmb{\lambda}^T{\bf x}_i}}{\sum_{j=1}^ne^{\pmb{\lambda}^T{\bf x}_j}}-\pmb{\mu}_0={\bf 0}.
</code>
</p>

<p>A numerical search over <code class="reqn">\pmb{\lambda}</code> is required. Under <code class="reqn">H_0</code> <code class="reqn">\Lambda \sim \chi^2_d</code>, where <code class="reqn">d</code> denotes the number of variables. Alternatively the bootstrap p-value may be computed.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>p</code></td>
<td>

<p>The estimated probabilities.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda</code></td>
<td>

<p>The value of the Lagrangian parameter <code class="reqn">\lambda</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>iter</code></td>
<td>

<p>The number of iterations required by the newton-Raphson algorithm.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>info</code></td>
<td>

<p>The value of the log-likelihood ratio test statistic along with its corresponding p-value.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>runtime</code></td>
<td>

<p>The runtime of the process.
</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Efron B. (1981) Nonparametric standard errors and confidence intervals. Canadian Journal of
Statistics, 9(2): 139–158.
</p>
<p>Jing B.Y. and Wood A.T.A. (1996). Exponential empirical likelihood is not
Bartlett correctable. Annals of Statistics, 24(1): 365–369.
</p>
<p>Owen A. B. (2001). Empirical likelihood. Chapman and Hall/CRC Press.
</p>


<h3>See Also</h3>

<p><code>el.test1, hotel1T2, james, hotel2T2, maov, el.test2
</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">x &lt;- as.matrix( iris[, 1:4] )
eel.test1(x, numeric(4) )
el.test1(x, numeric(4) )
</code></pre>


</div>