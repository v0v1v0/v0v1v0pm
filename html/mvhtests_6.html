<div class="container">

<table style="width: 100%;"><tr>
<td>Log-likelihood ratio test for equality of one covariance matrix</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Log-likelihood ratio test for equality of one covariance matrix
</h2>

<h3>Description</h3>

<p>Log-likelihood ratio test for equality of one covariance matrix.
</p>


<h3>Usage</h3>

<pre><code class="language-R">equal.cov(x, Sigma, a = 0.05)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>

<p>A matrix containing Euclidean data.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Sigma</code></td>
<td>

<p>The hypothesis covariance matrix.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>a</code></td>
<td>

<p>The significance level, set to 0.05 by default.
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The hypothesis test is that the the sample covariance is equal to some specified covariance matrix: <code class="reqn">H_0:\pmb{\Sigma}=\pmb{\Sigma}_0</code>, with <code class="reqn">\pmb{\mu}</code> unknown. The algorithm for this test is taken from Mardia, Bibby and Kent (1979, pg. 126-127).
The test is based upon the log-likelihood ratio test. The form of the test is
</p>
<p style="text-align: center;"><code class="reqn">
-2\log{\lambda}=n \text{tr}\left\lbrace \pmb{\Sigma}_0^{-1}{\bf S}\right\rbrace-n\log{\left|\pmb{\Sigma}_0^{-1}{\bf S} \right|}-np,
</code>
</p>

<p>where <code class="reqn">n</code> is the sample size, <code class="reqn">\pmb{\Sigma}_0</code> is the specified covariance matrix under the null hypothesis, <code class="reqn">{\bf S}</code> is the sample covariance matrix and <code class="reqn">p</code> is the dimensionality of the data (or the number of variables). Let <code class="reqn">\alpha</code> and <code class="reqn">g</code> denote the arithmetic mean and the geometric mean respectively of the eigenvalues of <code class="reqn">\pmb{\Sigma}_0^{-1}{\bf S}</code>, so that <code class="reqn">tr\left\lbrace \pmb{\Sigma}_0^{-1}{\bf S}\right\rbrace=p\alpha</code> and
<code class="reqn">\left|\pmb{\Sigma}_0^{-1}{\bf S} \right|=g^p</code>, then the test statistic becomes
</p>
<p style="text-align: center;"><code class="reqn">
-2\log{\lambda}=np\left(\alpha-log{(g)}-1 \right).
</code>
</p>

<p>The degrees of freedom of the <code class="reqn">\chi^2</code> distribution are <code class="reqn">\frac{1}{2}p\left(p+1\right)</code>.
</p>


<h3>Value</h3>

<p>A vector with the the test statistic, the p-value, the degrees of freedom and the critical value of the test.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Mardia K.V., Kent J.T. and Bibby J.M. (1979). Multivariate Analysis. London: Academic Press.
</p>


<h3>See Also</h3>

<p><code>likel.cov, Mtest.cov
</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">x &lt;- as.matrix( iris[, 1:4] )
s &lt;- cov(x) * 1.5
equal.cov(x, s)
</code></pre>


</div>