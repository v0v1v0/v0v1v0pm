<div class="container">

<table style="width: 100%;"><tr>
<td>James multivariate version of the t-test</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
James multivariate version of the t-test
</h2>

<h3>Description</h3>

<p>James test for testing the equality of two population mean vectors without assuming equality of the covariance matrices.
</p>


<h3>Usage</h3>

<pre><code class="language-R">james(y1, y2, a = 0.05, R = 999, graph = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>y1</code></td>
<td>

<p>A matrix containing the Euclidean data of the first group.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y2</code></td>
<td>

<p>A matrix containing the Euclidean data of the second group.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>a</code></td>
<td>

<p>The significance level, set to 0.05 by default.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>R</code></td>
<td>

<p>If R is 1 no bootstrap calibration is performed and the classical p-value via the
F distribution is returned. If R is greater than 1, the bootstrap p-value is returned.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>graph</code></td>
<td>

<p>A boolean variable which is taken into consideration only when bootstrap calibration is performed.
If TRUE the histogram of the bootstrap test statistic values is plotted.
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Here we show the modified version of the two-sample <code class="reqn">T^2</code> test (function <code>hotel2T2</code>) in the case where the two covariances matrices cannot be assumed to be equal.
</p>
<p>James (1954) proposed a test for linear hypotheses of the population means when the variances (or the covariance matrices) are not known. Its form for two <code class="reqn">p</code>-dimensional samples is:
</p>
<p style="text-align: center;"><code class="reqn">
T^2_u=\left(\bar{{\bf X}}_1-\bar{{\bf X}}_2\right)^T\tilde{{\bf S}}^{-1}\left(\bar{{\bf X}}_1-\bar{{\bf X}}_2\right),
</code>
</p>

<p>where
<code class="reqn">\tilde{{\bf S}}=\tilde{{\bf S}_1}+\tilde{{\bf S}_2}=\frac{{\bf S}_1}{n_1}+\frac{{\bf S}_2}{n_2}
</code>.
</p>
<p>James (1954) suggested that the test statistic is compared with <code class="reqn">2h\left(\alpha\right)</code>, a corrected <code class="reqn">\chi^2</code> distribution whose form is
</p>
<p style="text-align: center;"><code class="reqn">
2h\left(\alpha\right)=\chi^2\left(A+B\chi^2\right),
</code>
</p>

<p>where
<code class="reqn">A=1+\frac{1}{2p}\sum_{i=1}^2\frac{\left(tr \tilde{{\bf S}}^{-1}\tilde{{\bf S}_i}\right)^2}{n_i-1}</code> and
<code class="reqn">B=\frac{1}{p\left(p+2\right)}\left[\sum_{i=1}^2\frac{tr\left(\tilde{{\bf S}}^{-1}\tilde{{\bf S}_i}\right)^2}{n_i-1}+\frac{1}{2}\sum_{i=1}^2\frac{\left(\text{tr} \tilde{{\bf S}}^{-1}\tilde{{\bf S}_i}\right)^2}{n_i-1} \right]</code>.
</p>
<p>If you want to do bootstrap to get the p-value, then you must transform the data under the null hypothesis. The estimate of the common mean is given by Aitchison (1986)
</p>
<p style="text-align: center;"><code class="reqn">
\hat{\pmb{\mu}}_c =
\left(n_1{\bf S}_1^{-1}+n_2{\bf S}_2^{-1}\right)^{-1}\left(n_1{\bf S}_1^{-1}\bar{{\bf X}}_1+n_2{\bf S}_2^{-1}\bar{{\bf X}}_2\right)=
\left(\tilde{{\bf S}}_1^{-1}+\tilde{{\bf S}}_2^{-1}\right)^{-1}\left(\tilde{{\bf S}}_1^{-1}\bar{{\bf X}}_1+\tilde{{\bf S}}_2^{-1}\bar{{\bf X}}_2\right).
</code>
</p>

<p>The modified Nel and van der Merwe (1986) test is based on the same quadratic form as that of James (1954) but the distribution used to compare the value of the test statistic is different.
It is shown in Krishnamoorthy and Yanping (2006) that <code class="reqn">T^2_u \sim \frac{\nu p}{\nu-p+1}F_{p,\nu-p+1}</code> approximately, where
<code class="reqn">
\nu=\frac{p+p^2}{\frac{1}{n_1}\left\lbrace \text{tr}\left[ \left( {\bf S}_1\tilde{{\bf S}} \right)^2\right]+
\text{tr}\left[ \left( {\bf S}_1\tilde{{\bf S}} \right)\right]^2 \right\rbrace +
\frac{1}{n_2}\left\lbrace \text{tr}\left[ \left( {\bf S}_2\tilde{{\bf S}}\right)^2\right]+
\text{tr}\left[ \left( {\bf S}_2\tilde{{\bf S}} \right)\right]^2 \right\rbrace }.
</code>
</p>
<p>The algorithm is taken by Krishnamoorthy and Yu (2004).
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>note</code></td>
<td>

<p>A message informing the user about the test used.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mesoi</code></td>
<td>

<p>The two mean vectors.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>info</code></td>
<td>

<p>The test statistic, the p-value, the correction factor and the corrected critical value
of the chi-square distribution if the James test has been used or, the test statistic,
the p-value, the critical value and the degrees of freedom (numerator and denominator)
of the F distribution if the modified James test has been used.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pvalue</code></td>
<td>

<p>The bootstrap p-value if bootstrap is employed.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>runtime</code></td>
<td>

<p>The runtime of the bootstrap calibration.
</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Aitchison J. (1986). The statistical analysis of compositional data. Chapman &amp; Hall.
</p>
<p>James G.S. (1954). Tests of Linear Hypothese in Univariate and Multivariate Analysis
when the Ratios of the Population Variances are Unknown. Biometrika, 41(1/2): 19–43.
</p>
<p>Krishnamoorthy K. and Yu J. (2004). Modified Nel and Van der Merwe test for the multivariate
Behrens-Fisher problem. Statistics &amp; Probability Letters, 66(2): 161–169.
</p>
<p>Krishnamoorthy K. and Yanping Xia (2006). On Selecting Tests for Equality of Two Normal Mean Vectors.
Multivariate Behavioral Research, 41(4): 533–548.
</p>
<p>Tsagris M., Preston S. and Wood A.T.A. (2017). Nonparametric hypothesis testing for
equality of means on the simplex. Journal of Statistical Computation and Simulation, 87(2): 406–422.
</p>


<h3>See Also</h3>

<p><code>hotel2T2, maovjames, el.test2, eel.test2
</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">james( as.matrix(iris[1:25, 1:4]), as.matrix(iris[26:50, 1:4]), R = 1 )
james( as.matrix(iris[1:25, 1:4]), as.matrix(iris[26:50, 1:4]), R = 2 )
james( as.matrix(iris[1:25, 1:4]), as.matrix(iris[26:50, 1:4]) )
</code></pre>


</div>